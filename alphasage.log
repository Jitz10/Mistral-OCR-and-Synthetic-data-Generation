2025-06-07 23:25:25,765 - INFO - MongoDB indexes created successfully
2025-06-07 23:25:30,209 - INFO - Created new ChromaDB collection: alphasage_chunks
2025-06-07 23:25:30,210 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-07 23:25:30,267 - INFO - Starting batch embedding of 4394 chunks
2025-06-07 23:25:30,271 - INFO - Processing batch 1, chunks 1-50
2025-06-07 23:26:21,117 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:26:21,122 - INFO - Processing batch 2, chunks 51-100
2025-06-07 23:27:11,126 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:27:11,131 - INFO - Processing batch 3, chunks 101-150
2025-06-07 23:28:00,822 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:28:00,828 - INFO - Processing batch 4, chunks 151-200
2025-06-07 23:28:50,909 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:28:50,913 - INFO - Processing batch 5, chunks 201-250
2025-06-07 23:29:41,095 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:29:41,097 - INFO - Progress: 250/4394 chunks processed
2025-06-07 23:29:41,100 - INFO - Processing batch 6, chunks 251-300
2025-06-07 23:30:30,990 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:30:30,995 - INFO - Processing batch 7, chunks 301-350
2025-06-07 23:31:23,620 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:31:23,626 - INFO - Processing batch 8, chunks 351-400
2025-06-07 23:32:16,607 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:32:16,612 - INFO - Processing batch 9, chunks 401-450
2025-06-07 23:33:07,706 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:33:07,711 - INFO - Processing batch 10, chunks 451-500
2025-06-07 23:33:58,585 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:33:58,586 - INFO - Progress: 500/4394 chunks processed
2025-06-07 23:33:58,591 - INFO - Processing batch 11, chunks 501-550
2025-06-07 23:34:48,622 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:34:48,627 - INFO - Processing batch 12, chunks 551-600
2025-06-07 23:35:38,654 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:35:38,660 - INFO - Processing batch 13, chunks 601-650
2025-06-07 23:36:28,727 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:36:28,732 - INFO - Processing batch 14, chunks 651-700
2025-06-07 23:37:18,760 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:37:18,766 - INFO - Processing batch 15, chunks 701-750
2025-06-07 23:38:08,780 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:38:08,780 - INFO - Progress: 750/4394 chunks processed
2025-06-07 23:38:08,785 - INFO - Processing batch 16, chunks 751-800
2025-06-07 23:38:58,822 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:38:58,826 - INFO - Processing batch 17, chunks 801-850
2025-06-07 23:39:48,905 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:39:48,909 - INFO - Processing batch 18, chunks 851-900
2025-06-07 23:40:38,957 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:40:38,961 - INFO - Processing batch 19, chunks 901-950
2025-06-07 23:41:28,995 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:41:29,001 - INFO - Processing batch 20, chunks 951-1000
2025-06-07 23:42:19,547 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:42:19,548 - INFO - Progress: 1000/4394 chunks processed
2025-06-07 23:42:19,551 - INFO - Processing batch 21, chunks 1001-1050
2025-06-07 23:43:09,541 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:43:09,545 - INFO - Processing batch 22, chunks 1051-1100
2025-06-07 23:43:59,797 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:43:59,804 - INFO - Processing batch 23, chunks 1101-1150
2025-06-07 23:44:49,805 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:44:49,810 - INFO - Processing batch 24, chunks 1151-1200
2025-06-07 23:45:39,849 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:45:39,857 - INFO - Processing batch 25, chunks 1201-1250
2025-06-07 23:46:29,971 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:46:29,971 - INFO - Progress: 1250/4394 chunks processed
2025-06-07 23:46:29,978 - INFO - Processing batch 26, chunks 1251-1300
2025-06-07 23:47:20,025 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:47:20,031 - INFO - Processing batch 27, chunks 1301-1350
2025-06-07 23:48:10,016 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:48:10,022 - INFO - Processing batch 28, chunks 1351-1400
2025-06-07 23:49:00,063 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:49:00,068 - INFO - Processing batch 29, chunks 1401-1450
2025-06-07 23:49:50,107 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:49:50,114 - INFO - Processing batch 30, chunks 1451-1500
2025-06-07 23:50:40,108 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:50:40,109 - INFO - Progress: 1500/4394 chunks processed
2025-06-07 23:50:40,116 - INFO - Processing batch 31, chunks 1501-1550
2025-06-07 23:51:30,185 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:51:30,190 - INFO - Processing batch 32, chunks 1551-1600
2025-06-07 23:52:21,318 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:52:21,325 - INFO - Processing batch 33, chunks 1601-1650
2025-06-07 23:53:11,389 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:53:11,392 - INFO - Processing batch 34, chunks 1651-1700
2025-06-07 23:54:01,704 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:54:01,709 - INFO - Processing batch 35, chunks 1701-1750
2025-06-07 23:54:51,703 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:54:51,703 - INFO - Progress: 1750/4394 chunks processed
2025-06-07 23:54:51,709 - INFO - Processing batch 36, chunks 1751-1800
2025-06-07 23:55:41,798 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:55:41,804 - INFO - Processing batch 37, chunks 1801-1850
2025-06-07 23:56:31,846 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:56:31,852 - INFO - Processing batch 38, chunks 1851-1900
2025-06-07 23:57:21,839 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:57:21,847 - INFO - Processing batch 39, chunks 1901-1950
2025-06-07 23:58:11,867 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:58:11,873 - INFO - Processing batch 40, chunks 1951-2000
2025-06-07 23:59:01,965 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:59:01,966 - INFO - Progress: 2000/4394 chunks processed
2025-06-07 23:59:01,971 - INFO - Processing batch 41, chunks 2001-2050
2025-06-07 23:59:51,918 - INFO - Added 50 embeddings to ChromaDB
2025-06-07 23:59:51,924 - INFO - Processing batch 42, chunks 2051-2100
2025-06-08 00:00:41,935 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:00:41,941 - INFO - Processing batch 43, chunks 2101-2150
2025-06-08 00:01:31,989 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:01:31,995 - INFO - Processing batch 44, chunks 2151-2200
2025-06-08 00:02:24,575 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:02:24,580 - INFO - Processing batch 45, chunks 2201-2250
2025-06-08 00:03:14,693 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:03:14,693 - INFO - Progress: 2250/4394 chunks processed
2025-06-08 00:03:14,698 - INFO - Processing batch 46, chunks 2251-2300
2025-06-08 00:04:05,641 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:04:05,650 - INFO - Processing batch 47, chunks 2301-2350
2025-06-08 00:04:55,760 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:04:55,769 - INFO - Processing batch 48, chunks 2351-2400
2025-06-08 00:05:45,755 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:05:45,763 - INFO - Processing batch 49, chunks 2401-2450
2025-06-08 00:06:35,771 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:06:35,778 - INFO - Processing batch 50, chunks 2451-2500
2025-06-08 00:07:25,924 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:07:25,925 - INFO - Progress: 2500/4394 chunks processed
2025-06-08 00:07:25,932 - INFO - Processing batch 51, chunks 2501-2550
2025-06-08 00:08:15,999 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:08:16,008 - INFO - Processing batch 52, chunks 2551-2600
2025-06-08 00:09:05,911 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:09:05,919 - INFO - Processing batch 53, chunks 2601-2650
2025-06-08 00:09:56,118 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:09:56,128 - INFO - Processing batch 54, chunks 2651-2700
2025-06-08 00:10:46,044 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:10:46,051 - INFO - Processing batch 55, chunks 2701-2750
2025-06-08 00:11:35,984 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:11:35,984 - INFO - Progress: 2750/4394 chunks processed
2025-06-08 00:11:35,991 - INFO - Processing batch 56, chunks 2751-2800
2025-06-08 00:12:28,327 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:12:28,334 - INFO - Processing batch 57, chunks 2801-2850
2025-06-08 00:13:18,408 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:13:18,418 - INFO - Processing batch 58, chunks 2851-2900
2025-06-08 00:14:10,753 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:14:10,756 - INFO - Processing batch 59, chunks 2901-2950
2025-06-08 00:15:03,739 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:15:03,743 - INFO - Processing batch 60, chunks 2951-3000
2025-06-08 00:15:53,778 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:15:53,779 - INFO - Progress: 3000/4394 chunks processed
2025-06-08 00:15:53,785 - INFO - Processing batch 61, chunks 3001-3050
2025-06-08 00:16:43,755 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:16:43,762 - INFO - Processing batch 62, chunks 3051-3100
2025-06-08 00:17:33,709 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:17:33,716 - INFO - Processing batch 63, chunks 3101-3150
2025-06-08 00:18:23,794 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:18:23,802 - INFO - Processing batch 64, chunks 3151-3200
2025-06-08 00:19:13,812 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:19:13,819 - INFO - Processing batch 65, chunks 3201-3250
2025-06-08 00:20:03,930 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:20:03,931 - INFO - Progress: 3250/4394 chunks processed
2025-06-08 00:20:03,935 - INFO - Processing batch 66, chunks 3251-3300
2025-06-08 00:20:54,233 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:20:54,238 - INFO - Processing batch 67, chunks 3301-3350
2025-06-08 00:21:44,267 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:21:44,272 - INFO - Processing batch 68, chunks 3351-3400
2025-06-08 00:22:34,402 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:22:34,407 - INFO - Processing batch 69, chunks 3401-3450
2025-06-08 00:23:27,496 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:23:27,501 - INFO - Processing batch 70, chunks 3451-3500
2025-06-08 00:24:17,515 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:24:17,516 - INFO - Progress: 3500/4394 chunks processed
2025-06-08 00:24:17,520 - INFO - Processing batch 71, chunks 3501-3550
2025-06-08 00:25:14,231 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:25:14,236 - INFO - Processing batch 72, chunks 3551-3600
2025-06-08 00:26:05,486 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:26:05,491 - INFO - Processing batch 73, chunks 3601-3650
2025-06-08 00:26:55,269 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:26:55,274 - INFO - Processing batch 74, chunks 3651-3700
2025-06-08 00:27:45,317 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:27:45,320 - INFO - Processing batch 75, chunks 3701-3750
2025-06-08 00:28:37,043 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:28:37,043 - INFO - Progress: 3750/4394 chunks processed
2025-06-08 00:28:37,050 - INFO - Processing batch 76, chunks 3751-3800
2025-06-08 00:29:28,025 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:29:28,029 - INFO - Processing batch 77, chunks 3801-3850
2025-06-08 00:30:18,062 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:30:18,067 - INFO - Processing batch 78, chunks 3851-3900
2025-06-08 00:31:08,093 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:31:08,096 - INFO - Processing batch 79, chunks 3901-3950
2025-06-08 00:31:58,146 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:31:58,152 - INFO - Processing batch 80, chunks 3951-4000
2025-06-08 00:32:48,275 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:32:48,275 - INFO - Progress: 4000/4394 chunks processed
2025-06-08 00:32:48,280 - INFO - Processing batch 81, chunks 4001-4050
2025-06-08 00:33:42,211 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:33:42,216 - INFO - Processing batch 82, chunks 4051-4100
2025-06-08 00:34:32,241 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:34:32,244 - INFO - Processing batch 83, chunks 4101-4150
2025-06-08 00:35:24,774 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:35:24,779 - INFO - Processing batch 84, chunks 4151-4200
2025-06-08 00:36:14,782 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:36:14,786 - INFO - Processing batch 85, chunks 4201-4250
2025-06-08 00:37:04,873 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:37:04,873 - INFO - Progress: 4250/4394 chunks processed
2025-06-08 00:37:04,876 - INFO - Processing batch 86, chunks 4251-4300
2025-06-08 00:37:54,895 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:37:54,899 - INFO - Processing batch 87, chunks 4301-4350
2025-06-08 00:38:44,990 - INFO - Added 50 embeddings to ChromaDB
2025-06-08 00:38:44,994 - INFO - Processing batch 88, chunks 4351-4394
2025-06-08 00:39:29,056 - INFO - Added 44 embeddings to ChromaDB
2025-06-08 00:39:29,059 - INFO - Batch embedding completed. Stats: {'processed': 4394, 'embedded': 4394, 'skipped': 0, 'errors': 0}
2025-06-08 00:39:29,344 - ERROR - Error in retrieve_chunks: Expected where to have exactly one operator, got {'company_name': 'Tata Motors', 'category': 'Future Insights'} in get.
2025-06-08 00:39:29,372 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\vector.py", line 382, in retrieve_chunks
    results = self.chroma_collection.get(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 124, in get
    get_request = self._validate_and_prepare_get_request(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 253, in _validate_and_prepare_get_request
    validate_filter_set(filter_set=filters)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 354, in validate_filter_set
    validate_where(filter_set["where"])
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 739, in validate_where
    raise ValueError(f"Expected where to have exactly one operator, got {where}")
ValueError: Expected where to have exactly one operator, got {'company_name': 'Tata Motors', 'category': 'Future Insights'} in get.

2025-06-08 00:39:30,010 - ERROR - Error in retrieve_chunks: 'list' object has no attribute 'get'
2025-06-08 00:39:30,011 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\vector.py", line 394, in retrieve_chunks
    mongodb_id = metadata.get('mongodb_id')
                 ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'get'

2025-06-08 00:39:30,072 - INFO - Retrieved 3 chunks matching criteria
2025-06-08 00:39:30,081 - INFO - Database connections closed
2025-06-08 00:57:32,186 - INFO - MongoDB indexes created successfully
2025-06-08 00:57:32,296 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 00:57:32,296 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 00:57:32,598 - INFO - Starting batch embedding of 4394 chunks
2025-06-08 00:57:32,598 - INFO - Processing batch 1, chunks 1-50
2025-06-08 00:57:32,644 - INFO - Processing batch 2, chunks 51-100
2025-06-08 00:57:32,678 - INFO - Processing batch 3, chunks 101-150
2025-06-08 00:57:32,770 - INFO - Processing batch 4, chunks 151-200
2025-06-08 00:57:32,805 - INFO - Processing batch 5, chunks 201-250
2025-06-08 00:57:32,848 - INFO - Progress: 250/4394 chunks processed
2025-06-08 00:57:32,849 - INFO - Processing batch 6, chunks 251-300
2025-06-08 00:57:32,886 - INFO - Processing batch 7, chunks 301-350
2025-06-08 00:57:32,933 - INFO - Processing batch 8, chunks 351-400
2025-06-08 00:57:32,969 - INFO - Processing batch 9, chunks 401-450
2025-06-08 00:57:33,014 - INFO - Processing batch 10, chunks 451-500
2025-06-08 00:57:33,048 - INFO - Progress: 500/4394 chunks processed
2025-06-08 00:57:33,050 - INFO - Processing batch 11, chunks 501-550
2025-06-08 00:57:33,093 - INFO - Processing batch 12, chunks 551-600
2025-06-08 00:57:33,130 - INFO - Processing batch 13, chunks 601-650
2025-06-08 00:57:33,175 - INFO - Processing batch 14, chunks 651-700
2025-06-08 00:57:33,211 - INFO - Processing batch 15, chunks 701-750
2025-06-08 00:57:33,258 - INFO - Progress: 750/4394 chunks processed
2025-06-08 00:57:33,260 - INFO - Processing batch 16, chunks 751-800
2025-06-08 00:57:33,296 - INFO - Processing batch 17, chunks 801-850
2025-06-08 00:57:33,340 - INFO - Processing batch 18, chunks 851-900
2025-06-08 00:57:33,375 - INFO - Processing batch 19, chunks 901-950
2025-06-08 00:57:33,420 - INFO - Processing batch 20, chunks 951-1000
2025-06-08 00:57:33,455 - INFO - Progress: 1000/4394 chunks processed
2025-06-08 00:57:33,456 - INFO - Processing batch 21, chunks 1001-1050
2025-06-08 00:57:33,504 - INFO - Processing batch 22, chunks 1051-1100
2025-06-08 00:57:33,543 - INFO - Processing batch 23, chunks 1101-1150
2025-06-08 00:57:33,592 - INFO - Processing batch 24, chunks 1151-1200
2025-06-08 00:57:33,632 - INFO - Processing batch 25, chunks 1201-1250
2025-06-08 00:57:33,675 - INFO - Progress: 1250/4394 chunks processed
2025-06-08 00:57:33,677 - INFO - Processing batch 26, chunks 1251-1300
2025-06-08 00:57:33,716 - INFO - Processing batch 27, chunks 1301-1350
2025-06-08 00:57:33,761 - INFO - Processing batch 28, chunks 1351-1400
2025-06-08 00:57:33,798 - INFO - Processing batch 29, chunks 1401-1450
2025-06-08 00:57:33,843 - INFO - Processing batch 30, chunks 1451-1500
2025-06-08 00:57:33,878 - INFO - Progress: 1500/4394 chunks processed
2025-06-08 00:57:33,880 - INFO - Processing batch 31, chunks 1501-1550
2025-06-08 00:57:33,925 - INFO - Processing batch 32, chunks 1551-1600
2025-06-08 00:57:33,963 - INFO - Processing batch 33, chunks 1601-1650
2025-06-08 00:57:34,016 - INFO - Processing batch 34, chunks 1651-1700
2025-06-08 00:57:34,053 - INFO - Processing batch 35, chunks 1701-1750
2025-06-08 00:57:34,097 - INFO - Progress: 1750/4394 chunks processed
2025-06-08 00:57:34,100 - INFO - Processing batch 36, chunks 1751-1800
2025-06-08 00:57:34,138 - INFO - Processing batch 37, chunks 1801-1850
2025-06-08 00:57:34,184 - INFO - Processing batch 38, chunks 1851-1900
2025-06-08 00:57:34,221 - INFO - Processing batch 39, chunks 1901-1950
2025-06-08 00:57:34,269 - INFO - Processing batch 40, chunks 1951-2000
2025-06-08 00:57:34,302 - INFO - Progress: 2000/4394 chunks processed
2025-06-08 00:57:34,305 - INFO - Processing batch 41, chunks 2001-2050
2025-06-08 00:57:34,353 - INFO - Processing batch 42, chunks 2051-2100
2025-06-08 00:57:34,389 - INFO - Processing batch 43, chunks 2101-2150
2025-06-08 00:57:34,436 - INFO - Processing batch 44, chunks 2151-2200
2025-06-08 00:57:34,474 - INFO - Processing batch 45, chunks 2201-2250
2025-06-08 00:57:34,518 - INFO - Progress: 2250/4394 chunks processed
2025-06-08 00:57:34,520 - INFO - Processing batch 46, chunks 2251-2300
2025-06-08 00:57:34,558 - INFO - Processing batch 47, chunks 2301-2350
2025-06-08 00:57:34,604 - INFO - Processing batch 48, chunks 2351-2400
2025-06-08 00:57:34,643 - INFO - Processing batch 49, chunks 2401-2450
2025-06-08 00:57:34,688 - INFO - Processing batch 50, chunks 2451-2500
2025-06-08 00:57:34,724 - INFO - Progress: 2500/4394 chunks processed
2025-06-08 00:57:34,726 - INFO - Processing batch 51, chunks 2501-2550
2025-06-08 00:57:34,773 - INFO - Processing batch 52, chunks 2551-2600
2025-06-08 00:57:34,811 - INFO - Processing batch 53, chunks 2601-2650
2025-06-08 00:57:34,858 - INFO - Processing batch 54, chunks 2651-2700
2025-06-08 00:57:34,895 - INFO - Processing batch 55, chunks 2701-2750
2025-06-08 00:57:34,939 - INFO - Progress: 2750/4394 chunks processed
2025-06-08 00:57:34,942 - INFO - Processing batch 56, chunks 2751-2800
2025-06-08 00:57:34,980 - INFO - Processing batch 57, chunks 2801-2850
2025-06-08 00:57:35,028 - INFO - Processing batch 58, chunks 2851-2900
2025-06-08 00:57:35,066 - INFO - Processing batch 59, chunks 2901-2950
2025-06-08 00:57:35,114 - INFO - Processing batch 60, chunks 2951-3000
2025-06-08 00:57:35,150 - INFO - Progress: 3000/4394 chunks processed
2025-06-08 00:57:35,153 - INFO - Processing batch 61, chunks 3001-3050
2025-06-08 00:57:35,200 - INFO - Processing batch 62, chunks 3051-3100
2025-06-08 00:57:35,238 - INFO - Processing batch 63, chunks 3101-3150
2025-06-08 00:57:35,286 - INFO - Processing batch 64, chunks 3151-3200
2025-06-08 00:57:35,326 - INFO - Processing batch 65, chunks 3201-3250
2025-06-08 00:57:35,371 - INFO - Progress: 3250/4394 chunks processed
2025-06-08 00:57:35,374 - INFO - Processing batch 66, chunks 3251-3300
2025-06-08 00:57:35,414 - INFO - Processing batch 67, chunks 3301-3350
2025-06-08 00:57:35,460 - INFO - Processing batch 68, chunks 3351-3400
2025-06-08 00:57:35,500 - INFO - Processing batch 69, chunks 3401-3450
2025-06-08 00:57:35,547 - INFO - Processing batch 70, chunks 3451-3500
2025-06-08 00:57:35,591 - INFO - Progress: 3500/4394 chunks processed
2025-06-08 00:57:35,596 - INFO - Processing batch 71, chunks 3501-3550
2025-06-08 00:57:35,646 - INFO - Processing batch 72, chunks 3551-3600
2025-06-08 00:57:35,683 - INFO - Processing batch 73, chunks 3601-3650
2025-06-08 00:57:35,728 - INFO - Processing batch 74, chunks 3651-3700
2025-06-08 00:57:35,767 - INFO - Processing batch 75, chunks 3701-3750
2025-06-08 00:57:35,811 - INFO - Progress: 3750/4394 chunks processed
2025-06-08 00:57:35,814 - INFO - Processing batch 76, chunks 3751-3800
2025-06-08 00:57:35,853 - INFO - Processing batch 77, chunks 3801-3850
2025-06-08 00:57:35,901 - INFO - Processing batch 78, chunks 3851-3900
2025-06-08 00:57:35,940 - INFO - Processing batch 79, chunks 3901-3950
2025-06-08 00:57:35,986 - INFO - Processing batch 80, chunks 3951-4000
2025-06-08 00:57:36,024 - INFO - Progress: 4000/4394 chunks processed
2025-06-08 00:57:36,028 - INFO - Processing batch 81, chunks 4001-4050
2025-06-08 00:57:36,073 - INFO - Processing batch 82, chunks 4051-4100
2025-06-08 00:57:36,112 - INFO - Processing batch 83, chunks 4101-4150
2025-06-08 00:57:36,161 - INFO - Processing batch 84, chunks 4151-4200
2025-06-08 00:57:36,201 - INFO - Processing batch 85, chunks 4201-4250
2025-06-08 00:57:36,245 - INFO - Progress: 4250/4394 chunks processed
2025-06-08 00:57:36,249 - INFO - Processing batch 86, chunks 4251-4300
2025-06-08 00:57:36,287 - INFO - Processing batch 87, chunks 4301-4350
2025-06-08 00:57:36,335 - INFO - Processing batch 88, chunks 4351-4394
2025-06-08 00:57:36,365 - INFO - Batch embedding completed. Stats: {'processed': 4394, 'embedded': 0, 'skipped': 4394, 'errors': 0}
2025-06-08 00:57:36,576 - INFO - Retrieved 3 chunks matching criteria
2025-06-08 00:57:38,786 - INFO - Retrieved 5 chunks matching criteria
2025-06-08 00:57:38,802 - INFO - Retrieved 3 chunks matching criteria
2025-06-08 00:57:38,807 - INFO - Retrieved 3 chunks matching criteria
2025-06-08 00:57:38,814 - INFO - Retrieved 3 chunks matching criteria
2025-06-08 00:57:38,815 - INFO - Database connections closed
2025-06-08 10:05:24,110 - INFO - MongoDB indexes created successfully
2025-06-08 10:05:25,942 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 10:05:25,943 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 10:05:26,671 - INFO - Starting batch embedding of 4394 chunks
2025-06-08 10:05:26,673 - INFO - Processing batch 1, chunks 1-50
2025-06-08 10:05:26,798 - INFO - Processing batch 2, chunks 51-100
2025-06-08 10:05:26,844 - INFO - Processing batch 3, chunks 101-150
2025-06-08 10:05:26,901 - INFO - Processing batch 4, chunks 151-200
2025-06-08 10:05:26,947 - INFO - Processing batch 5, chunks 201-250
2025-06-08 10:05:27,003 - INFO - Progress: 250/4394 chunks processed
2025-06-08 10:05:27,006 - INFO - Processing batch 6, chunks 251-300
2025-06-08 10:05:27,066 - INFO - Processing batch 7, chunks 301-350
2025-06-08 10:05:27,135 - INFO - Processing batch 8, chunks 351-400
2025-06-08 10:05:27,209 - INFO - Processing batch 9, chunks 401-450
2025-06-08 10:05:27,276 - INFO - Processing batch 10, chunks 451-500
2025-06-08 10:05:27,326 - INFO - Progress: 500/4394 chunks processed
2025-06-08 10:05:27,329 - INFO - Processing batch 11, chunks 501-550
2025-06-08 10:05:27,387 - INFO - Processing batch 12, chunks 551-600
2025-06-08 10:05:27,440 - INFO - Processing batch 13, chunks 601-650
2025-06-08 10:05:27,502 - INFO - Processing batch 14, chunks 651-700
2025-06-08 10:05:27,555 - INFO - Processing batch 15, chunks 701-750
2025-06-08 10:05:27,613 - INFO - Progress: 750/4394 chunks processed
2025-06-08 10:05:27,615 - INFO - Processing batch 16, chunks 751-800
2025-06-08 10:05:27,664 - INFO - Processing batch 17, chunks 801-850
2025-06-08 10:05:27,723 - INFO - Processing batch 18, chunks 851-900
2025-06-08 10:05:27,772 - INFO - Processing batch 19, chunks 901-950
2025-06-08 10:05:27,833 - INFO - Processing batch 20, chunks 951-1000
2025-06-08 10:05:27,882 - INFO - Progress: 1000/4394 chunks processed
2025-06-08 10:05:27,885 - INFO - Processing batch 21, chunks 1001-1050
2025-06-08 10:05:27,944 - INFO - Processing batch 22, chunks 1051-1100
2025-06-08 10:05:27,996 - INFO - Processing batch 23, chunks 1101-1150
2025-06-08 10:05:28,057 - INFO - Processing batch 24, chunks 1151-1200
2025-06-08 10:05:28,109 - INFO - Processing batch 25, chunks 1201-1250
2025-06-08 10:05:28,168 - INFO - Progress: 1250/4394 chunks processed
2025-06-08 10:05:28,171 - INFO - Processing batch 26, chunks 1251-1300
2025-06-08 10:05:28,224 - INFO - Processing batch 27, chunks 1301-1350
2025-06-08 10:05:28,285 - INFO - Processing batch 28, chunks 1351-1400
2025-06-08 10:05:28,335 - INFO - Processing batch 29, chunks 1401-1450
2025-06-08 10:05:28,392 - INFO - Processing batch 30, chunks 1451-1500
2025-06-08 10:05:28,440 - INFO - Progress: 1500/4394 chunks processed
2025-06-08 10:05:28,443 - INFO - Processing batch 31, chunks 1501-1550
2025-06-08 10:05:28,501 - INFO - Processing batch 32, chunks 1551-1600
2025-06-08 10:05:28,551 - INFO - Processing batch 33, chunks 1601-1650
2025-06-08 10:05:28,608 - INFO - Processing batch 34, chunks 1651-1700
2025-06-08 10:05:28,662 - INFO - Processing batch 35, chunks 1701-1750
2025-06-08 10:05:28,721 - INFO - Progress: 1750/4394 chunks processed
2025-06-08 10:05:28,724 - INFO - Processing batch 36, chunks 1751-1800
2025-06-08 10:05:28,774 - INFO - Processing batch 37, chunks 1801-1850
2025-06-08 10:05:28,833 - INFO - Processing batch 38, chunks 1851-1900
2025-06-08 10:05:28,885 - INFO - Processing batch 39, chunks 1901-1950
2025-06-08 10:05:28,943 - INFO - Processing batch 40, chunks 1951-2000
2025-06-08 10:05:28,991 - INFO - Progress: 2000/4394 chunks processed
2025-06-08 10:05:28,994 - INFO - Processing batch 41, chunks 2001-2050
2025-06-08 10:05:29,053 - INFO - Processing batch 42, chunks 2051-2100
2025-06-08 10:05:29,105 - INFO - Processing batch 43, chunks 2101-2150
2025-06-08 10:05:29,165 - INFO - Processing batch 44, chunks 2151-2200
2025-06-08 10:05:29,215 - INFO - Processing batch 45, chunks 2201-2250
2025-06-08 10:05:29,271 - INFO - Progress: 2250/4394 chunks processed
2025-06-08 10:05:29,274 - INFO - Processing batch 46, chunks 2251-2300
2025-06-08 10:05:29,326 - INFO - Processing batch 47, chunks 2301-2350
2025-06-08 10:05:29,381 - INFO - Processing batch 48, chunks 2351-2400
2025-06-08 10:05:29,429 - INFO - Processing batch 49, chunks 2401-2450
2025-06-08 10:05:29,488 - INFO - Processing batch 50, chunks 2451-2500
2025-06-08 10:05:29,536 - INFO - Progress: 2500/4394 chunks processed
2025-06-08 10:05:29,539 - INFO - Processing batch 51, chunks 2501-2550
2025-06-08 10:05:29,599 - INFO - Processing batch 52, chunks 2551-2600
2025-06-08 10:05:29,651 - INFO - Processing batch 53, chunks 2601-2650
2025-06-08 10:05:29,711 - INFO - Processing batch 54, chunks 2651-2700
2025-06-08 10:05:29,762 - INFO - Processing batch 55, chunks 2701-2750
2025-06-08 10:05:29,834 - INFO - Progress: 2750/4394 chunks processed
2025-06-08 10:05:29,839 - INFO - Processing batch 56, chunks 2751-2800
2025-06-08 10:05:29,939 - INFO - Processing batch 57, chunks 2801-2850
2025-06-08 10:05:30,093 - INFO - Processing batch 58, chunks 2851-2900
2025-06-08 10:05:30,190 - INFO - Processing batch 59, chunks 2901-2950
2025-06-08 10:05:30,344 - INFO - Processing batch 60, chunks 2951-3000
2025-06-08 10:05:30,441 - INFO - Progress: 3000/4394 chunks processed
2025-06-08 10:05:30,446 - INFO - Processing batch 61, chunks 3001-3050
2025-06-08 10:05:30,616 - INFO - Processing batch 62, chunks 3051-3100
2025-06-08 10:05:30,709 - INFO - Processing batch 63, chunks 3101-3150
2025-06-08 10:05:30,825 - INFO - Processing batch 64, chunks 3151-3200
2025-06-08 10:05:30,967 - INFO - Processing batch 65, chunks 3201-3250
2025-06-08 10:05:31,077 - INFO - Progress: 3250/4394 chunks processed
2025-06-08 10:05:31,083 - INFO - Processing batch 66, chunks 3251-3300
2025-06-08 10:05:31,183 - INFO - Processing batch 67, chunks 3301-3350
2025-06-08 10:05:31,340 - INFO - Processing batch 68, chunks 3351-3400
2025-06-08 10:05:31,440 - INFO - Processing batch 69, chunks 3401-3450
2025-06-08 10:05:31,559 - INFO - Processing batch 70, chunks 3451-3500
2025-06-08 10:05:31,701 - INFO - Progress: 3500/4394 chunks processed
2025-06-08 10:05:31,707 - INFO - Processing batch 71, chunks 3501-3550
2025-06-08 10:05:31,828 - INFO - Processing batch 72, chunks 3551-3600
2025-06-08 10:05:31,975 - INFO - Processing batch 73, chunks 3601-3650
2025-06-08 10:05:32,095 - INFO - Processing batch 74, chunks 3651-3700
2025-06-08 10:05:32,234 - INFO - Processing batch 75, chunks 3701-3750
2025-06-08 10:05:32,386 - INFO - Progress: 3750/4394 chunks processed
2025-06-08 10:05:32,392 - INFO - Processing batch 76, chunks 3751-3800
2025-06-08 10:05:32,493 - INFO - Processing batch 77, chunks 3801-3850
2025-06-08 10:05:32,642 - INFO - Processing batch 78, chunks 3851-3900
2025-06-08 10:05:32,738 - INFO - Processing batch 79, chunks 3901-3950
2025-06-08 10:05:32,883 - INFO - Processing batch 80, chunks 3951-4000
2025-06-08 10:05:33,021 - INFO - Progress: 4000/4394 chunks processed
2025-06-08 10:05:33,027 - INFO - Processing batch 81, chunks 4001-4050
2025-06-08 10:05:33,136 - INFO - Processing batch 82, chunks 4051-4100
2025-06-08 10:05:33,275 - INFO - Processing batch 83, chunks 4101-4150
2025-06-08 10:05:33,389 - INFO - Processing batch 84, chunks 4151-4200
2025-06-08 10:05:33,524 - INFO - Processing batch 85, chunks 4201-4250
2025-06-08 10:05:33,672 - INFO - Progress: 4250/4394 chunks processed
2025-06-08 10:05:33,677 - INFO - Processing batch 86, chunks 4251-4300
2025-06-08 10:05:33,775 - INFO - Processing batch 87, chunks 4301-4350
2025-06-08 10:05:33,930 - INFO - Processing batch 88, chunks 4351-4394
2025-06-08 10:05:34,013 - INFO - Batch embedding completed. Stats: {'processed': 4394, 'embedded': 0, 'skipped': 4394, 'errors': 0}
2025-06-08 10:05:34,398 - INFO - Retrieved 3 chunks matching criteria
2025-06-08 10:05:36,462 - INFO - Retrieved 5 chunks matching criteria
2025-06-08 10:05:36,490 - INFO - Retrieved 3 chunks matching criteria
2025-06-08 10:05:36,525 - INFO - Retrieved 3 chunks matching criteria
2025-06-08 10:05:36,542 - INFO - Retrieved 3 chunks matching criteria
2025-06-08 10:05:36,547 - INFO - Database connections closed
2025-06-08 10:42:56,892 - INFO - MongoDB connection established
2025-06-08 10:42:56,893 - INFO - Redis connection established
2025-06-08 10:42:57,174 - INFO - ChromaDB connection established
2025-06-08 10:42:57,189 - INFO - Testing tool: financial_data
2025-06-08 10:43:01,259 - ERROR - Error: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it., Context: {"action": "get_cached_result", "key": "yfinance_data:290f61e252cf3aa3e10bc0dfdf6207f0"}
2025-06-08 10:43:01,477 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 385, in connect_check_health
    sock = self.retry.call_with_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\retry.py", line 87, in call_with_retry
    return do()
           ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 386, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
            ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 797, in _connect
    raise err
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 781, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 161, in get_cached_result
    cached_value = redis_client.get(key)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\commands\core.py", line 1829, in get
    return self.execute_command("GET", name, keys=[name])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 623, in execute_command
    return self._execute_command(*args, **options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 629, in _execute_command
    conn = self.connection or pool.get_connection()
                              ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\utils.py", line 191, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 1530, in get_connection
    connection.connect()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 379, in connect
    self.connect_check_health(check_health=True)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 391, in connect_check_health
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.

2025-06-08 10:43:06,712 - ERROR - Error: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it., Context: {"action": "cache_result", "key": "yfinance_data:290f61e252cf3aa3e10bc0dfdf6207f0"}
2025-06-08 10:43:06,715 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 385, in connect_check_health
    sock = self.retry.call_with_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\retry.py", line 87, in call_with_retry
    return do()
           ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 386, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
            ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 797, in _connect
    raise err
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 781, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 141, in cache_result
    redis_client.setex(key, ttl, serialized_value)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\commands\core.py", line 2330, in setex
    return self.execute_command("SETEX", name, time, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 623, in execute_command
    return self._execute_command(*args, **options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 629, in _execute_command
    conn = self.connection or pool.get_connection()
                              ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\utils.py", line 191, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 1530, in get_connection
    connection.connect()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 379, in connect
    self.connect_check_health(check_health=True)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 391, in connect_check_health
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.

2025-06-08 10:43:06,718 - INFO - Test complete: financial_data, Success: True
2025-06-08 10:43:06,718 - INFO - Testing tool: financial_data
2025-06-08 10:43:10,794 - ERROR - Error: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it., Context: {"action": "get_cached_result", "key": "yfinance_data:c8c48ea964612083bd3aad53ec674be9"}
2025-06-08 10:43:10,796 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 385, in connect_check_health
    sock = self.retry.call_with_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\retry.py", line 87, in call_with_retry
    return do()
           ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 386, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
            ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 797, in _connect
    raise err
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 781, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 161, in get_cached_result
    cached_value = redis_client.get(key)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\commands\core.py", line 1829, in get
    return self.execute_command("GET", name, keys=[name])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 623, in execute_command
    return self._execute_command(*args, **options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 629, in _execute_command
    conn = self.connection or pool.get_connection()
                              ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\utils.py", line 191, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 1530, in get_connection
    connection.connect()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 379, in connect
    self.connect_check_health(check_health=True)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 391, in connect_check_health
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.

2025-06-08 10:43:20,782 - ERROR - Error: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it., Context: {"action": "cache_result", "key": "yfinance_data:c8c48ea964612083bd3aad53ec674be9"}
2025-06-08 10:43:20,785 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 385, in connect_check_health
    sock = self.retry.call_with_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\retry.py", line 87, in call_with_retry
    return do()
           ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 386, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
            ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 797, in _connect
    raise err
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 781, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 141, in cache_result
    redis_client.setex(key, ttl, serialized_value)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\commands\core.py", line 2330, in setex
    return self.execute_command("SETEX", name, time, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 623, in execute_command
    return self._execute_command(*args, **options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 629, in _execute_command
    conn = self.connection or pool.get_connection()
                              ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\utils.py", line 191, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 1530, in get_connection
    connection.connect()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 379, in connect
    self.connect_check_health(check_health=True)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 391, in connect_check_health
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.

2025-06-08 10:43:20,789 - INFO - Test complete: financial_data, Success: True
2025-06-08 10:43:20,790 - INFO - Testing tool: company_news
2025-06-08 10:43:24,892 - ERROR - Error: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it., Context: {"action": "get_cached_result", "key": "yfinance_news:212440e71e6ab09e45050bf36e6be1fb"}
2025-06-08 10:43:24,895 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 385, in connect_check_health
    sock = self.retry.call_with_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\retry.py", line 87, in call_with_retry
    return do()
           ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 386, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
            ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 797, in _connect
    raise err
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 781, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 161, in get_cached_result
    cached_value = redis_client.get(key)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\commands\core.py", line 1829, in get
    return self.execute_command("GET", name, keys=[name])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 623, in execute_command
    return self._execute_command(*args, **options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 629, in _execute_command
    conn = self.connection or pool.get_connection()
                              ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\utils.py", line 191, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 1530, in get_connection
    connection.connect()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 379, in connect
    self.connect_check_health(check_health=True)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 391, in connect_check_health
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.

2025-06-08 10:43:25,417 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_company_news", "ticker": "TATAMOTORS.NS"}
2025-06-08 10:43:25,498 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 691, in fetch_company_news
    if store_in_mongodb and collection and len(articles) > 0:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-08 10:43:25,499 - INFO - Test complete: company_news, Success: True
2025-06-08 10:43:25,499 - INFO - Testing tool: calculate_metrics
2025-06-08 10:43:25,500 - INFO - Test complete: calculate_metrics, Success: True
2025-06-08 10:43:25,500 - INFO - Testing tool: reasoning
2025-06-08 10:43:29,589 - ERROR - Error: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it., Context: {"action": "get_cached_result", "key": "reasoning:e065918dfaeca1df136ccd03f140e22e"}
2025-06-08 10:43:29,592 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 385, in connect_check_health
    sock = self.retry.call_with_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\retry.py", line 87, in call_with_retry
    return do()
           ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 386, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
            ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 797, in _connect
    raise err
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 781, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 161, in get_cached_result
    cached_value = redis_client.get(key)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\commands\core.py", line 1829, in get
    return self.execute_command("GET", name, keys=[name])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 623, in execute_command
    return self._execute_command(*args, **options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 629, in _execute_command
    conn = self.connection or pool.get_connection()
                              ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\utils.py", line 191, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 1530, in get_connection
    connection.connect()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 379, in connect
    self.connect_check_health(check_health=True)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 391, in connect_check_health
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.

2025-06-08 10:43:31,594 - ERROR - Error: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
], Context: {"action": "reason_on_data", "query": "Is Tata Motors showing strong financial performance based on these metrics?"}
2025-06-08 10:43:31,827 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 367, in reason_on_data
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jsh Agarwal\AppData\Local\Programs\Python\Python311\Lib\asyncio\threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jsh Agarwal\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]

2025-06-08 10:43:31,832 - INFO - Test complete: reasoning, Success: True
2025-06-08 10:43:31,832 - INFO - Testing tool: search_knowledge_base
2025-06-08 10:43:35,881 - ERROR - Error: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it., Context: {"action": "get_cached_result", "key": "vector_search:cfd6e512000902152494f983917084ae"}
2025-06-08 10:43:35,883 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 385, in connect_check_health
    sock = self.retry.call_with_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\retry.py", line 87, in call_with_retry
    return do()
           ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 386, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
            ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 797, in _connect
    raise err
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 781, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 161, in get_cached_result
    cached_value = redis_client.get(key)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\commands\core.py", line 1829, in get
    return self.execute_command("GET", name, keys=[name])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 623, in execute_command
    return self._execute_command(*args, **options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 629, in _execute_command
    conn = self.connection or pool.get_connection()
                              ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\utils.py", line 191, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 1530, in get_connection
    connection.connect()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 379, in connect
    self.connect_check_health(check_health=True)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 391, in connect_check_health
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.

2025-06-08 10:43:36,081 - INFO - MongoDB indexes created successfully
2025-06-08 10:43:36,131 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 10:43:36,133 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 10:43:38,706 - INFO - Retrieved 5 chunks matching criteria
2025-06-08 10:43:42,793 - ERROR - Error: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it., Context: {"action": "cache_result", "key": "vector_search:cfd6e512000902152494f983917084ae"}
2025-06-08 10:43:42,796 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 385, in connect_check_health
    sock = self.retry.call_with_retry(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\retry.py", line 87, in call_with_retry
    return do()
           ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 386, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
            ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 797, in _connect
    raise err
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 781, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 141, in cache_result
    redis_client.setex(key, ttl, serialized_value)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\commands\core.py", line 2330, in setex
    return self.execute_command("SETEX", name, time, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 623, in execute_command
    return self._execute_command(*args, **options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\client.py", line 629, in _execute_command
    conn = self.connection or pool.get_connection()
                              ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\utils.py", line 191, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 1530, in get_connection
    connection.connect()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 379, in connect
    self.connect_check_health(check_health=True)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\redis\connection.py", line 391, in connect_check_health
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.

2025-06-08 10:43:42,798 - INFO - Test complete: search_knowledge_base, Success: True
2025-06-08 11:28:48,113 - INFO - MongoDB connection established
2025-06-08 11:28:48,138 - INFO - Redis connection established
2025-06-08 11:28:51,588 - INFO - ChromaDB connection established
2025-06-08 11:28:51,917 - INFO - Testing tool: financial_data
2025-06-08 11:28:53,639 - INFO - Test complete: financial_data, Success: True
2025-06-08 11:28:53,640 - INFO - Testing tool: financial_data
2025-06-08 11:28:58,773 - INFO - Test complete: financial_data, Success: True
2025-06-08 11:28:58,773 - INFO - Testing tool: company_news
2025-06-08 11:28:59,762 - INFO - Stored 5 news articles for Tata Motors in MongoDB
2025-06-08 11:28:59,764 - INFO - Test complete: company_news, Success: True
2025-06-08 11:28:59,764 - INFO - Testing tool: calculate_metrics
2025-06-08 11:28:59,765 - INFO - Test complete: calculate_metrics, Success: True
2025-06-08 11:28:59,765 - INFO - Testing tool: reasoning
2025-06-08 11:29:01,487 - ERROR - Error: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
], Context: {"action": "reason_on_data", "query": "Is Tata Motors showing strong financial performance based on these metrics?"}
2025-06-08 11:29:01,675 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 453, in reason_on_data
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jsh Agarwal\AppData\Local\Programs\Python\Python311\Lib\asyncio\threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jsh Agarwal\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]

2025-06-08 11:29:01,678 - INFO - Test complete: reasoning, Success: True
2025-06-08 11:29:01,679 - INFO - Testing tool: search_knowledge_base
2025-06-08 11:29:01,805 - INFO - MongoDB indexes created successfully
2025-06-08 11:29:01,824 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 11:29:01,826 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 11:29:04,089 - INFO - Retrieved 5 chunks matching criteria
2025-06-08 11:29:04,092 - INFO - Database connections closed
2025-06-08 11:29:04,093 - INFO - Test complete: search_knowledge_base, Success: True
2025-06-08 11:49:01,234 - INFO - MongoDB connection established
2025-06-08 11:49:01,239 - INFO - Redis connection established
2025-06-08 11:49:01,400 - INFO - ChromaDB connection established
2025-06-08 11:49:01,586 - INFO - Testing tool: financial_data
2025-06-08 11:49:01,587 - INFO - Using cached financial data for TATAMOTORS.NS, metric: P/E
2025-06-08 11:49:01,588 - INFO - Test complete: financial_data, Success: True
2025-06-08 11:49:01,588 - INFO - Testing tool: financial_data
2025-06-08 11:49:01,589 - INFO - Using cached financial data for GANECOS.NS, metric: price
2025-06-08 11:49:01,589 - INFO - Test complete: financial_data, Success: True
2025-06-08 11:49:01,589 - INFO - Testing tool: company_news
2025-06-08 11:49:01,589 - INFO - Using cached news for TATAMOTORS.NS
2025-06-08 11:49:01,590 - INFO - Test complete: company_news, Success: True
2025-06-08 11:49:01,590 - INFO - Testing tool: calculate_metrics
2025-06-08 11:49:01,590 - INFO - Test complete: calculate_metrics, Success: True
2025-06-08 11:49:03,605 - INFO - Testing tool: reasoning
2025-06-08 11:49:04,025 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-08 11:49:04,025 - INFO - Test complete: reasoning, Success: True
2025-06-08 11:49:04,025 - INFO - Testing tool: search_knowledge_base
2025-06-08 11:49:04,027 - INFO - Using cached vector search result for query: future growth prospects...
2025-06-08 11:49:04,027 - INFO - Test complete: search_knowledge_base, Success: True
2025-06-08 18:45:20,633 - INFO - MongoDB connection established
2025-06-08 18:45:20,676 - INFO - Redis connection established
2025-06-08 18:45:22,170 - INFO - ChromaDB connection established
2025-06-08 18:45:23,523 - INFO - Starting AlphaSage test suite...
2025-06-08 18:45:23,523 - INFO - Testing vector database...
2025-06-08 18:45:48,370 - INFO - MongoDB connection established
2025-06-08 18:45:48,417 - INFO - Redis connection established
2025-06-08 18:45:48,501 - INFO - ChromaDB connection established
2025-06-08 18:45:49,604 - INFO - Starting AlphaSage test suite...
2025-06-08 18:45:49,604 - INFO - Testing vector database...
2025-06-08 19:03:14,709 - INFO - MongoDB connection established
2025-06-08 19:03:14,720 - INFO - Redis connection established
2025-06-08 19:03:14,914 - INFO - ChromaDB connection established
2025-06-08 19:03:16,216 - INFO - Starting AlphaSage test suite...
2025-06-08 19:03:16,252 - INFO - MongoDB indexes created successfully
2025-06-08 19:03:16,264 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 19:03:16,264 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 19:03:16,271 - INFO - Redis connection established for micro agents
2025-06-08 19:03:16,278 - INFO - MongoDB connection established for micro agents
2025-06-08 19:05:08,246 - INFO - MongoDB connection established
2025-06-08 19:05:08,339 - INFO - Redis connection established
2025-06-08 19:05:08,449 - INFO - ChromaDB connection established
2025-06-08 19:05:13,684 - INFO - Starting AlphaSage test suite...
2025-06-08 19:05:13,697 - INFO - MongoDB indexes created successfully
2025-06-08 19:05:13,723 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 19:05:13,723 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 19:05:13,731 - INFO - Redis connection established for micro agents
2025-06-08 19:05:13,750 - INFO - MongoDB connection established for micro agents
2025-06-08 19:05:41,676 - INFO - MongoDB connection established
2025-06-08 19:05:41,703 - INFO - Redis connection established
2025-06-08 19:05:41,785 - INFO - ChromaDB connection established
2025-06-08 19:05:45,298 - INFO - Starting AlphaSage test suite...
2025-06-08 19:05:45,322 - INFO - MongoDB indexes created successfully
2025-06-08 19:05:45,333 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 19:05:45,333 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 19:05:45,340 - INFO - Redis connection established for micro agents
2025-06-08 19:05:45,368 - INFO - MongoDB connection established for micro agents
2025-06-08 19:05:45,475 - INFO - Configured 10 micro agents
2025-06-08 19:05:45,698 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 19:05:45,704 - INFO - Redis connection established for macro agents
2025-06-08 19:05:45,725 - INFO - MongoDB connection established for macro agents
2025-06-08 19:05:45,734 - INFO - Redis connection established for micro agents
2025-06-08 19:05:45,739 - INFO - MongoDB connection established for micro agents
2025-06-08 19:05:45,837 - INFO - Configured 10 micro agents
2025-06-08 19:05:45,839 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 19:22:10,757 - INFO - MongoDB connection established
2025-06-08 19:22:10,767 - INFO - Redis connection established
2025-06-08 19:22:10,955 - INFO - ChromaDB connection established
2025-06-08 19:22:15,192 - INFO - Starting AlphaSage test suite...
2025-06-08 19:22:15,218 - INFO - MongoDB indexes created successfully
2025-06-08 19:22:15,231 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 19:22:15,231 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 19:22:15,237 - INFO - Redis connection established for micro agents
2025-06-08 19:22:15,262 - INFO - MongoDB connection established for micro agents
2025-06-08 19:22:15,390 - INFO - Configured 10 micro agents
2025-06-08 19:22:15,602 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 19:22:15,607 - INFO - Redis connection established for macro agents
2025-06-08 19:22:15,635 - INFO - MongoDB connection established for macro agents
2025-06-08 19:22:15,642 - INFO - Redis connection established for micro agents
2025-06-08 19:22:15,665 - INFO - MongoDB connection established for micro agents
2025-06-08 19:22:15,803 - INFO - Configured 10 micro agents
2025-06-08 19:22:15,810 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 19:22:15,891 - INFO - Configured 8 macro agents
2025-06-08 19:22:15,895 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 19:22:15,897 - INFO - MongoDB connection established
2025-06-08 19:22:15,901 - INFO - Redis connection established
2025-06-08 19:22:15,903 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 19:22:15,903 - INFO - ChromaDB connection established
2025-06-08 19:22:15,923 - INFO - No results found in ChromaDB
2025-06-08 19:22:15,924 - ERROR - Setup failed: Expected at least 20 chunks for Ganesha Ecosphere Limited
2025-06-08 19:22:15,924 - ERROR - Test setup failed
2025-06-08 19:22:44,567 - INFO - Starting test data load...
2025-06-08 19:22:44,591 - INFO - MongoDB indexes created successfully
2025-06-08 19:22:44,801 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 19:22:44,802 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 19:22:50,919 - INFO - Inserted 4 chunks into MongoDB
2025-06-08 19:22:50,963 - INFO - Starting batch embedding of 4399 chunks
2025-06-08 19:22:50,966 - INFO - Processing batch 1, chunks 1-100
2025-06-08 19:24:31,476 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:24:31,480 - INFO - Processing batch 2, chunks 101-200
2025-06-08 19:26:11,325 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:26:11,328 - INFO - Processing batch 3, chunks 201-300
2025-06-08 19:27:52,506 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:27:52,509 - INFO - Processing batch 4, chunks 301-400
2025-06-08 19:29:36,670 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:29:36,673 - INFO - Processing batch 5, chunks 401-500
2025-06-08 19:31:17,376 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:31:17,376 - INFO - Progress: 500/4399 chunks processed
2025-06-08 19:31:17,380 - INFO - Processing batch 6, chunks 501-600
2025-06-08 19:32:57,450 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:32:57,453 - INFO - Processing batch 7, chunks 601-700
2025-06-08 19:34:37,548 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:34:37,550 - INFO - Processing batch 8, chunks 701-800
2025-06-08 19:36:17,790 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:36:17,794 - INFO - Processing batch 9, chunks 801-900
2025-06-08 19:37:57,868 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:37:57,872 - INFO - Processing batch 10, chunks 901-1000
2025-06-08 19:39:41,846 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:39:41,846 - INFO - Progress: 1000/4399 chunks processed
2025-06-08 19:39:41,850 - INFO - Processing batch 11, chunks 1001-1100
2025-06-08 19:41:29,638 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:41:29,641 - INFO - Processing batch 12, chunks 1101-1200
2025-06-08 19:43:09,698 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:43:09,703 - INFO - Processing batch 13, chunks 1201-1300
2025-06-08 19:44:49,775 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:44:49,780 - INFO - Processing batch 14, chunks 1301-1400
2025-06-08 19:46:29,831 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:46:29,836 - INFO - Processing batch 15, chunks 1401-1500
2025-06-08 19:48:09,953 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:48:09,953 - INFO - Progress: 1500/4399 chunks processed
2025-06-08 19:48:09,956 - INFO - Processing batch 16, chunks 1501-1600
2025-06-08 19:49:53,059 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:49:53,064 - INFO - Processing batch 17, chunks 1601-1700
2025-06-08 19:51:34,419 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:51:34,423 - INFO - Processing batch 18, chunks 1701-1800
2025-06-08 19:53:14,463 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:53:14,466 - INFO - Processing batch 19, chunks 1801-1900
2025-06-08 19:54:54,557 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:54:54,563 - INFO - Processing batch 20, chunks 1901-2000
2025-06-08 19:56:34,655 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:56:34,655 - INFO - Progress: 2000/4399 chunks processed
2025-06-08 19:56:34,659 - INFO - Processing batch 21, chunks 2001-2100
2025-06-08 19:58:14,853 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:58:14,857 - INFO - Processing batch 22, chunks 2101-2200
2025-06-08 19:59:56,951 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 19:59:56,954 - INFO - Processing batch 23, chunks 2201-2300
2025-06-08 20:01:37,032 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:01:37,036 - INFO - Processing batch 24, chunks 2301-2400
2025-06-08 20:03:17,100 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:03:17,103 - INFO - Processing batch 25, chunks 2401-2500
2025-06-08 20:04:57,204 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:04:57,204 - INFO - Progress: 2500/4399 chunks processed
2025-06-08 20:04:57,208 - INFO - Processing batch 26, chunks 2501-2600
2025-06-08 20:06:37,258 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:06:37,264 - INFO - Processing batch 27, chunks 2601-2700
2025-06-08 20:08:17,390 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:08:17,394 - INFO - Processing batch 28, chunks 2701-2800
2025-06-08 20:09:58,153 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:09:58,158 - INFO - Processing batch 29, chunks 2801-2900
2025-06-08 20:11:39,279 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:11:39,283 - INFO - Processing batch 30, chunks 2901-3000
2025-06-08 20:13:19,343 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:13:19,345 - INFO - Progress: 3000/4399 chunks processed
2025-06-08 20:13:19,349 - INFO - Processing batch 31, chunks 3001-3100
2025-06-08 20:14:59,388 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:14:59,396 - INFO - Processing batch 32, chunks 3101-3200
2025-06-08 20:16:39,474 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:16:39,480 - INFO - Processing batch 33, chunks 3201-3300
2025-06-08 20:18:19,580 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:18:19,585 - INFO - Processing batch 34, chunks 3301-3400
2025-06-08 20:20:00,828 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:20:00,834 - INFO - Processing batch 35, chunks 3401-3500
2025-06-08 20:21:42,794 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:21:42,794 - INFO - Progress: 3500/4399 chunks processed
2025-06-08 20:21:42,798 - INFO - Processing batch 36, chunks 3501-3600
2025-06-08 20:23:23,998 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:23:24,004 - INFO - Processing batch 37, chunks 3601-3700
2025-06-08 20:25:03,792 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:25:03,797 - INFO - Processing batch 38, chunks 3701-3800
2025-06-08 20:26:43,919 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:26:43,924 - INFO - Processing batch 39, chunks 3801-3900
2025-06-08 20:28:23,989 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:28:23,994 - INFO - Processing batch 40, chunks 3901-4000
2025-06-08 20:30:04,515 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:30:04,515 - INFO - Progress: 4000/4399 chunks processed
2025-06-08 20:30:04,522 - INFO - Processing batch 41, chunks 4001-4100
2025-06-08 20:31:46,216 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:31:46,223 - INFO - Processing batch 42, chunks 4101-4200
2025-06-08 20:33:29,323 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:33:29,332 - INFO - Processing batch 43, chunks 4201-4300
2025-06-08 20:35:09,401 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:35:09,413 - INFO - Processing batch 44, chunks 4301-4399
2025-06-08 20:36:48,560 - INFO - Added 99 embeddings to ChromaDB
2025-06-08 20:36:48,562 - INFO - Batch embedding completed. Stats: {'processed': 4399, 'embedded': 4399, 'skipped': 0, 'errors': 0}
2025-06-08 20:36:48,638 - INFO - No results found in ChromaDB
2025-06-08 20:36:48,641 - INFO - Retrieved 0 chunks from ChromaDB
2025-06-08 20:36:48,641 - WARNING - Only 0 chunks found, expected at least 20
2025-06-08 20:36:48,646 - INFO - Database connections closed
2025-06-08 20:36:56,014 - INFO - MongoDB connection established
2025-06-08 20:36:56,032 - INFO - Redis connection established
2025-06-08 20:36:56,125 - INFO - ChromaDB connection established
2025-06-08 20:37:00,418 - INFO - Starting AlphaSage test suite...
2025-06-08 20:37:00,470 - INFO - MongoDB indexes created successfully
2025-06-08 20:37:00,482 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 20:37:00,482 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 20:37:00,492 - INFO - Redis connection established for micro agents
2025-06-08 20:37:00,514 - INFO - MongoDB connection established for micro agents
2025-06-08 20:37:00,650 - INFO - Configured 10 micro agents
2025-06-08 20:37:00,796 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 20:37:00,803 - INFO - Redis connection established for macro agents
2025-06-08 20:37:00,812 - INFO - MongoDB connection established for macro agents
2025-06-08 20:37:00,817 - INFO - Redis connection established for micro agents
2025-06-08 20:37:00,840 - INFO - MongoDB connection established for micro agents
2025-06-08 20:37:00,951 - INFO - Configured 10 micro agents
2025-06-08 20:37:00,954 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 20:37:01,044 - INFO - Configured 8 macro agents
2025-06-08 20:37:01,047 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 20:37:01,129 - INFO - MongoDB connection established
2025-06-08 20:37:01,136 - INFO - Redis connection established
2025-06-08 20:37:01,137 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 20:37:01,137 - INFO - ChromaDB connection established
2025-06-08 20:37:01,167 - INFO - No results found in ChromaDB
2025-06-08 20:37:01,167 - ERROR - Setup failed: Expected at least 20 chunks for Ganesha Ecosphere Limited
2025-06-08 20:37:01,168 - ERROR - Test setup failed
2025-06-08 20:38:21,625 - INFO - MongoDB connection established
2025-06-08 20:38:21,639 - INFO - Redis connection established
2025-06-08 20:38:21,753 - INFO - ChromaDB connection established
2025-06-08 20:38:26,764 - INFO - Starting AlphaSage test suite...
2025-06-08 20:38:26,784 - INFO - MongoDB indexes created successfully
2025-06-08 20:38:26,799 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 20:38:26,800 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 20:38:26,807 - INFO - Redis connection established for micro agents
2025-06-08 20:38:26,813 - INFO - MongoDB connection established for micro agents
2025-06-08 20:38:27,052 - INFO - Configured 10 micro agents
2025-06-08 20:38:27,212 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 20:38:27,218 - INFO - Redis connection established for macro agents
2025-06-08 20:38:27,232 - INFO - MongoDB connection established for macro agents
2025-06-08 20:38:27,252 - INFO - Redis connection established for micro agents
2025-06-08 20:38:27,273 - INFO - MongoDB connection established for micro agents
2025-06-08 20:38:27,411 - INFO - Configured 10 micro agents
2025-06-08 20:38:27,413 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 20:38:27,534 - INFO - Configured 8 macro agents
2025-06-08 20:38:27,537 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 20:38:27,564 - INFO - MongoDB connection established
2025-06-08 20:38:27,575 - INFO - Redis connection established
2025-06-08 20:38:27,577 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 20:38:27,577 - INFO - ChromaDB connection established
2025-06-08 20:38:27,587 - INFO - No results found in ChromaDB
2025-06-08 20:38:27,587 - ERROR - Setup failed: Expected at least 20 chunks for Ganesha Ecosphere Limited
2025-06-08 20:38:27,588 - ERROR - Test setup failed
2025-06-08 20:39:02,058 - INFO - Starting test data load...
2025-06-08 20:39:02,074 - INFO - MongoDB indexes created successfully
2025-06-08 20:39:02,181 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 20:39:02,182 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 20:39:04,421 - INFO - Inserted 4 chunks into MongoDB
2025-06-08 20:39:04,429 - INFO - Starting batch embedding of 4399 chunks
2025-06-08 20:39:04,432 - INFO - Processing batch 1, chunks 1-100
2025-06-08 20:40:46,080 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:40:46,086 - INFO - Processing batch 2, chunks 101-200
2025-06-08 20:42:26,609 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:42:26,614 - INFO - Processing batch 3, chunks 201-300
2025-06-08 20:44:06,700 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:44:06,705 - INFO - Processing batch 4, chunks 301-400
2025-06-08 20:45:46,784 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:45:46,788 - INFO - Processing batch 5, chunks 401-500
2025-06-08 20:47:26,818 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:47:26,818 - INFO - Progress: 500/4399 chunks processed
2025-06-08 20:47:26,823 - INFO - Processing batch 6, chunks 501-600
2025-06-08 20:49:06,865 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:49:06,870 - INFO - Processing batch 7, chunks 601-700
2025-06-08 20:50:47,121 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:50:47,124 - INFO - Processing batch 8, chunks 701-800
2025-06-08 20:52:27,964 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:52:27,968 - INFO - Processing batch 9, chunks 801-900
2025-06-08 20:54:08,041 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:54:08,044 - INFO - Processing batch 10, chunks 901-1000
2025-06-08 20:55:48,107 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:55:48,107 - INFO - Progress: 1000/4399 chunks processed
2025-06-08 20:55:48,112 - INFO - Processing batch 11, chunks 1001-1100
2025-06-08 20:57:28,182 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:57:28,188 - INFO - Processing batch 12, chunks 1101-1200
2025-06-08 20:59:08,268 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 20:59:08,273 - INFO - Processing batch 13, chunks 1201-1300
2025-06-08 21:00:49,148 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:00:49,152 - INFO - Processing batch 14, chunks 1301-1400
2025-06-08 21:02:29,508 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:02:29,512 - INFO - Processing batch 15, chunks 1401-1500
2025-06-08 21:04:09,586 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:04:09,586 - INFO - Progress: 1500/4399 chunks processed
2025-06-08 21:04:09,590 - INFO - Processing batch 16, chunks 1501-1600
2025-06-08 21:05:49,618 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:05:49,624 - INFO - Processing batch 17, chunks 1601-1700
2025-06-08 21:07:29,754 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:07:29,760 - INFO - Processing batch 18, chunks 1701-1800
2025-06-08 21:09:09,823 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:09:09,828 - INFO - Processing batch 19, chunks 1801-1900
2025-06-08 21:10:51,135 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:10:51,144 - INFO - Processing batch 20, chunks 1901-2000
2025-06-08 21:12:32,085 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:12:32,085 - INFO - Progress: 2000/4399 chunks processed
2025-06-08 21:12:32,090 - INFO - Processing batch 21, chunks 2001-2100
2025-06-08 21:14:12,172 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:14:12,178 - INFO - Processing batch 22, chunks 2101-2200
2025-06-08 21:15:52,264 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:15:52,274 - INFO - Processing batch 23, chunks 2201-2300
2025-06-08 21:17:32,336 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:17:32,342 - INFO - Processing batch 24, chunks 2301-2400
2025-06-08 21:19:12,443 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:19:12,449 - INFO - Processing batch 25, chunks 2401-2500
2025-06-08 21:20:54,175 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:20:54,176 - INFO - Progress: 2500/4399 chunks processed
2025-06-08 21:20:54,182 - INFO - Processing batch 26, chunks 2501-2600
2025-06-08 21:22:34,651 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:22:34,657 - INFO - Processing batch 27, chunks 2601-2700
2025-06-08 21:24:14,737 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:24:14,743 - INFO - Processing batch 28, chunks 2701-2800
2025-06-08 21:25:54,771 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:25:54,776 - INFO - Processing batch 29, chunks 2801-2900
2025-06-08 21:27:34,991 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:27:35,004 - INFO - Processing batch 30, chunks 2901-3000
2025-06-08 21:29:14,985 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:29:14,985 - INFO - Progress: 3000/4399 chunks processed
2025-06-08 21:29:14,992 - INFO - Processing batch 31, chunks 3001-3100
2025-06-08 21:30:55,202 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:30:55,209 - INFO - Processing batch 32, chunks 3101-3200
2025-06-08 21:32:35,431 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:32:35,448 - INFO - Processing batch 33, chunks 3201-3300
2025-06-08 21:34:15,222 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:34:15,228 - INFO - Processing batch 34, chunks 3301-3400
2025-06-08 21:35:55,438 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:35:55,449 - INFO - Processing batch 35, chunks 3401-3500
2025-06-08 21:37:35,414 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:37:35,414 - INFO - Progress: 3500/4399 chunks processed
2025-06-08 21:37:35,422 - INFO - Processing batch 36, chunks 3501-3600
2025-06-08 21:39:16,577 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:39:16,585 - INFO - Processing batch 37, chunks 3601-3700
2025-06-08 21:40:56,474 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:40:56,481 - INFO - Processing batch 38, chunks 3701-3800
2025-06-08 21:42:36,663 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:42:36,669 - INFO - Processing batch 39, chunks 3801-3900
2025-06-08 21:45:00,139 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:45:00,144 - INFO - Processing batch 40, chunks 3901-4000
2025-06-08 21:46:39,741 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:46:39,742 - INFO - Progress: 4000/4399 chunks processed
2025-06-08 21:46:39,747 - INFO - Processing batch 41, chunks 4001-4100
2025-06-08 21:48:21,462 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:48:21,471 - INFO - Processing batch 42, chunks 4101-4200
2025-06-08 21:50:01,512 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:50:01,518 - INFO - Processing batch 43, chunks 4201-4300
2025-06-08 21:51:42,152 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 21:51:42,158 - INFO - Processing batch 44, chunks 4301-4399
2025-06-08 21:53:21,218 - INFO - Added 99 embeddings to ChromaDB
2025-06-08 21:53:21,219 - INFO - Batch embedding completed. Stats: {'processed': 4399, 'embedded': 4399, 'skipped': 0, 'errors': 0}
2025-06-08 21:53:21,309 - INFO - No results found in ChromaDB
2025-06-08 21:53:21,310 - INFO - Retrieved 0 chunks from ChromaDB
2025-06-08 21:53:21,311 - WARNING - Only 0 chunks found, expected at least 20
2025-06-08 21:53:21,315 - INFO - Database connections closed
2025-06-08 22:52:33,206 - INFO - MongoDB connection established
2025-06-08 22:52:33,235 - INFO - Redis connection established
2025-06-08 22:52:33,625 - INFO - ChromaDB connection established
2025-06-08 22:52:38,828 - INFO - Starting AlphaSage test suite...
2025-06-08 22:52:38,919 - INFO - MongoDB indexes created successfully
2025-06-08 22:52:38,931 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 22:52:38,932 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 22:52:38,939 - INFO - Redis connection established for micro agents
2025-06-08 22:52:38,963 - INFO - MongoDB connection established for micro agents
2025-06-08 22:52:39,078 - INFO - Configured 10 micro agents
2025-06-08 22:52:39,360 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 22:52:39,364 - INFO - Redis connection established for macro agents
2025-06-08 22:52:39,372 - INFO - MongoDB connection established for macro agents
2025-06-08 22:52:39,377 - INFO - Redis connection established for micro agents
2025-06-08 22:52:39,382 - INFO - MongoDB connection established for micro agents
2025-06-08 22:52:39,490 - INFO - Configured 10 micro agents
2025-06-08 22:52:39,495 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 22:52:39,578 - INFO - Configured 8 macro agents
2025-06-08 22:52:39,582 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 22:52:39,585 - INFO - MongoDB connection established
2025-06-08 22:52:39,592 - INFO - Redis connection established
2025-06-08 22:52:39,593 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 22:52:39,594 - INFO - ChromaDB connection established
2025-06-08 22:52:39,609 - INFO - No results found in ChromaDB
2025-06-08 22:52:39,611 - ERROR - Setup failed: Expected at least 20 chunks for Ganesha Ecosphere Limited
2025-06-08 22:52:39,611 - ERROR - Test setup failed
2025-06-08 22:53:09,801 - INFO - MongoDB connection established
2025-06-08 22:53:09,812 - INFO - Redis connection established
2025-06-08 22:53:09,893 - INFO - ChromaDB connection established
2025-06-08 22:53:13,854 - INFO - Starting AlphaSage test suite...
2025-06-08 22:53:13,865 - INFO - MongoDB indexes created successfully
2025-06-08 22:53:13,877 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 22:53:13,878 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 22:53:13,892 - INFO - Redis connection established for micro agents
2025-06-08 22:53:13,897 - INFO - MongoDB connection established for micro agents
2025-06-08 22:53:14,008 - INFO - Configured 10 micro agents
2025-06-08 22:53:14,073 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 22:53:14,079 - INFO - Redis connection established for macro agents
2025-06-08 22:53:14,106 - INFO - MongoDB connection established for macro agents
2025-06-08 22:53:14,111 - INFO - Redis connection established for micro agents
2025-06-08 22:53:14,115 - INFO - MongoDB connection established for micro agents
2025-06-08 22:53:14,219 - INFO - Configured 10 micro agents
2025-06-08 22:53:14,223 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 22:53:14,302 - INFO - Configured 8 macro agents
2025-06-08 22:53:14,304 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 22:53:14,306 - INFO - MongoDB connection established
2025-06-08 22:53:14,310 - INFO - Redis connection established
2025-06-08 22:53:14,311 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 22:53:14,311 - INFO - ChromaDB connection established
2025-06-08 22:53:14,321 - INFO - No results found in ChromaDB
2025-06-08 22:53:14,321 - ERROR - Setup failed: Expected at least 20 chunks for Ganesha Ecosphere Limited
2025-06-08 22:53:14,321 - ERROR - Test setup failed
2025-06-08 22:53:30,798 - INFO - Starting test data load...
2025-06-08 22:53:30,849 - INFO - MongoDB indexes created successfully
2025-06-08 22:53:30,947 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 22:53:30,948 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 22:53:35,592 - INFO - Inserted 4 chunks into MongoDB
2025-06-08 22:53:35,607 - INFO - Starting batch embedding of 4403 chunks
2025-06-08 22:53:35,609 - INFO - Processing batch 1, chunks 1-100
2025-06-08 22:55:25,415 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 22:55:25,417 - INFO - Processing batch 2, chunks 101-200
2025-06-08 22:57:05,405 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 22:57:05,408 - INFO - Processing batch 3, chunks 201-300
2025-06-08 22:58:45,508 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 22:58:45,510 - INFO - Processing batch 4, chunks 301-400
2025-06-08 23:00:25,567 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:00:25,571 - INFO - Processing batch 5, chunks 401-500
2025-06-08 23:02:05,649 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:02:05,649 - INFO - Progress: 500/4403 chunks processed
2025-06-08 23:02:05,652 - INFO - Processing batch 6, chunks 501-600
2025-06-08 23:03:46,654 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:03:46,657 - INFO - Processing batch 7, chunks 601-700
2025-06-08 23:05:28,019 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:05:28,022 - INFO - Processing batch 8, chunks 701-800
2025-06-08 23:07:08,118 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:07:08,121 - INFO - Processing batch 9, chunks 801-900
2025-06-08 23:08:48,216 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:08:48,219 - INFO - Processing batch 10, chunks 901-1000
2025-06-08 23:10:28,247 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:10:28,247 - INFO - Progress: 1000/4403 chunks processed
2025-06-08 23:10:28,251 - INFO - Processing batch 11, chunks 1001-1100
2025-06-08 23:12:08,339 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:12:08,342 - INFO - Processing batch 12, chunks 1101-1200
2025-06-08 23:13:48,744 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:13:48,748 - INFO - Processing batch 13, chunks 1201-1300
2025-06-08 23:15:29,965 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:15:29,968 - INFO - Processing batch 14, chunks 1301-1400
2025-06-08 23:17:10,040 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:17:10,043 - INFO - Processing batch 15, chunks 1401-1500
2025-06-08 23:18:37,742 - INFO - MongoDB connection established
2025-06-08 23:18:37,790 - INFO - Redis connection established
2025-06-08 23:18:37,879 - INFO - ChromaDB connection established
2025-06-08 23:18:41,824 - INFO - Starting AlphaSage test suite...
2025-06-08 23:18:41,880 - INFO - MongoDB indexes created successfully
2025-06-08 23:18:41,899 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 23:18:41,899 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 23:18:41,905 - INFO - Redis connection established for micro agents
2025-06-08 23:18:41,934 - INFO - MongoDB connection established for micro agents
2025-06-08 23:18:42,053 - INFO - Configured 10 micro agents
2025-06-08 23:18:42,110 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 23:18:42,119 - INFO - Redis connection established for macro agents
2025-06-08 23:18:42,130 - INFO - MongoDB connection established for macro agents
2025-06-08 23:18:42,138 - INFO - Redis connection established for micro agents
2025-06-08 23:18:42,148 - INFO - MongoDB connection established for micro agents
2025-06-08 23:18:42,269 - INFO - Configured 10 micro agents
2025-06-08 23:18:42,271 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 23:18:42,349 - INFO - Configured 8 macro agents
2025-06-08 23:18:42,353 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-08 23:18:42,355 - INFO - MongoDB connection established
2025-06-08 23:18:42,359 - INFO - Redis connection established
2025-06-08 23:18:42,361 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 23:18:42,361 - INFO - ChromaDB connection established
2025-06-08 23:18:42,382 - INFO - No results found in ChromaDB
2025-06-08 23:18:42,383 - ERROR - Setup failed: Expected at least 20 chunks for Ganesha Ecosphere Limited
2025-06-08 23:18:42,383 - ERROR - Test setup failed
2025-06-08 23:18:50,225 - INFO - Added 100 embeddings to ChromaDB
2025-06-08 23:18:50,226 - INFO - Progress: 1500/4403 chunks processed
2025-06-08 23:18:50,229 - INFO - Processing batch 16, chunks 1501-1600
2025-06-08 23:19:15,941 - INFO - Starting test data load...
2025-06-08 23:19:15,947 - INFO - MongoDB connection established
2025-06-08 23:19:15,995 - INFO - MongoDB indexes created successfully
2025-06-08 23:19:16,105 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-08 23:19:16,105 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-08 23:19:16,105 - INFO - Vector DB initialized
2025-06-08 23:19:16,105 - INFO - Fetching data for GANECOS.NS from Yahoo Finance
2025-06-08 23:19:16,106 - INFO - Fetching company info
2025-06-08 23:19:17,278 - INFO - Creating financial ratios chunk
2025-06-08 23:19:17,278 - INFO - Fetching historical data
2025-06-08 23:19:17,474 - INFO - Fetching news articles
2025-06-08 23:19:17,698 - WARNING - No news articles found for GANECOS.NS
2025-06-08 23:19:17,699 - INFO - Fetching financial statements
2025-06-08 23:19:17,880 - INFO - Loading 4 chunks into MongoDB
2025-06-08 23:19:17,895 - INFO - Deleted 4 existing chunks
2025-06-08 23:19:17,897 - INFO - Inserted 4 chunks into MongoDB
2025-06-08 23:19:17,898 - INFO - Starting batch embedding
2025-06-08 23:19:17,902 - INFO - Starting batch embedding of 4403 chunks
2025-06-08 23:19:17,904 - INFO - Processing batch 1, chunks 1-100
2025-06-09 10:16:51,005 - INFO - MongoDB connection established
2025-06-09 10:16:51,012 - INFO - Redis connection established
2025-06-09 10:16:51,168 - INFO - ChromaDB connection established
2025-06-09 10:16:51,334 - INFO - Testing tool: financial_data
2025-06-09 10:16:52,187 - INFO - Test complete: financial_data, Success: True
2025-06-09 10:16:52,187 - INFO - Testing tool: financial_data
2025-06-09 10:16:52,461 - INFO - Test complete: financial_data, Success: True
2025-06-09 10:16:52,462 - INFO - Testing tool: company_news
2025-06-09 10:16:52,840 - INFO - Stored 5 news articles for Tata Motors in MongoDB
2025-06-09 10:16:52,841 - INFO - Test complete: company_news, Success: True
2025-06-09 10:16:52,842 - INFO - Testing tool: calculate_metrics
2025-06-09 10:16:52,842 - INFO - Test complete: calculate_metrics, Success: True
2025-06-09 10:16:54,859 - INFO - Testing tool: reasoning
2025-06-09 10:16:55,348 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 10:16:55,359 - INFO - Test complete: reasoning, Success: True
2025-06-09 10:16:55,361 - INFO - Testing tool: search_knowledge_base
2025-06-09 10:16:55,378 - INFO - MongoDB indexes created successfully
2025-06-09 10:16:55,401 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-09 10:16:55,401 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-09 10:16:55,853 - ERROR - Error in retrieve_chunks: Expected where to have exactly one operator, got {'company_name': {'$eq': 'Ganesha Ecosphere'}, 'category': {'$eq': 'Future Insights'}} in query.
2025-06-09 10:16:55,928 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\vector.py", line 374, in retrieve_chunks
    results = self.chroma_collection.query(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 209, in query
    query_request = self._validate_and_prepare_query_request(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 309, in _validate_and_prepare_query_request
    validate_filter_set(filter_set=filters)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 354, in validate_filter_set
    validate_where(filter_set["where"])
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 739, in validate_where
    raise ValueError(f"Expected where to have exactly one operator, got {where}")
ValueError: Expected where to have exactly one operator, got {'company_name': {'$eq': 'Ganesha Ecosphere'}, 'category': {'$eq': 'Future Insights'}} in query.

2025-06-09 10:16:55,929 - INFO - Database connections closed
2025-06-09 10:16:55,929 - INFO - Test complete: search_knowledge_base, Success: True
2025-06-09 10:21:47,557 - INFO - MongoDB connection established
2025-06-09 10:21:47,562 - INFO - Redis connection established
2025-06-09 10:21:47,635 - INFO - ChromaDB connection established
2025-06-09 10:21:47,641 - INFO - Redis connection established for micro agents
2025-06-09 10:21:47,663 - INFO - MongoDB connection established for micro agents
2025-06-09 10:21:47,768 - INFO - Configured 10 micro agents
2025-06-09 10:21:47,916 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 10:21:47,916 - INFO - Testing micro agent: valuation
2025-06-09 10:21:47,917 - ERROR - Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"ticker": "TATAMOTORS.NS", "company_name": "Tata Motors"}
2025-06-09 10:21:47,929 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 315, in calculate_valuation_ratios
    pe_data = await self.retry_tool_call(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 265, in retry_tool_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 10:21:47,929 - INFO - Test complete for valuation: Success=False, Time=0.01s
2025-06-09 10:21:47,930 - INFO - Testing micro agent: profitability
2025-06-09 10:21:47,931 - ERROR - Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"ticker": "TATAMOTORS.NS", "company_name": "Tata Motors"}
2025-06-09 10:21:47,932 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 404, in calculate_profitability_ratios
    roe_data = await self.retry_tool_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 265, in retry_tool_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 10:21:47,932 - INFO - Test complete for profitability: Success=False, Time=0.00s
2025-06-09 10:21:47,932 - INFO - Testing micro agent: news
2025-06-09 10:21:47,933 - ERROR - Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"ticker": "TATAMOTORS.NS", "date_range": null}
2025-06-09 10:21:47,934 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 751, in analyze_news
    news_articles = await self.retry_tool_call(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 265, in retry_tool_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 10:21:47,934 - INFO - Test complete for news: Success=False, Time=0.00s
2025-06-09 10:21:47,934 - INFO - Testing micro agent: historical
2025-06-09 10:21:47,935 - ERROR - Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"ticker": "TATAMOTORS.NS", "company_name": "Tata Motors", "years": 3}
2025-06-09 10:21:47,936 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 827, in fetch_historical_data
    price_data = await self.retry_tool_call(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 265, in retry_tool_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 10:21:47,936 - INFO - Test complete for historical: Success=False, Time=0.00s
2025-06-09 10:21:47,936 - INFO - Testing micro agent: guidance
2025-06-09 10:21:47,949 - INFO - MongoDB indexes created successfully
2025-06-09 10:21:47,960 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-09 10:21:47,960 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-09 10:21:48,433 - ERROR - Error in retrieve_chunks: Expected where to have exactly one operator, got {'company_name': {'$eq': 'Tata Motors'}, 'category': {'$eq': 'Future Insights'}} in query.
2025-06-09 10:21:48,436 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\vector.py", line 374, in retrieve_chunks
    results = self.chroma_collection.query(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 209, in query
    query_request = self._validate_and_prepare_query_request(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 309, in _validate_and_prepare_query_request
    validate_filter_set(filter_set=filters)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 354, in validate_filter_set
    validate_where(filter_set["where"])
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 739, in validate_where
    raise ValueError(f"Expected where to have exactly one operator, got {where}")
ValueError: Expected where to have exactly one operator, got {'company_name': {'$eq': 'Tata Motors'}, 'category': {'$eq': 'Future Insights'}} in query.

2025-06-09 10:21:48,438 - INFO - Database connections closed
2025-06-09 10:21:48,440 - INFO - Test complete for guidance: Success=True, Time=0.50s
2025-06-09 10:21:48,440 - INFO - Testing micro agent: scenario
2025-06-09 10:21:48,441 - ERROR - Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"company_name": "Tata Motors", "metrics": {"P/E": 15.5, "ROE": 0.12, "Debt_Equity": 0.8}}
2025-06-09 10:21:48,442 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1101, in generate_scenarios
    scenario_reasoning = await self.retry_tool_call(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 265, in retry_tool_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 10:21:48,442 - INFO - Test complete for scenario: Success=False, Time=0.00s
2025-06-09 10:34:28,612 - INFO - MongoDB connection established
2025-06-09 10:34:28,618 - INFO - Redis connection established
2025-06-09 10:34:28,975 - INFO - ChromaDB connection established
2025-06-09 10:34:29,171 - INFO - Testing tool: financial_data_basic_pe_ratio
2025-06-09 10:34:29,174 - INFO - Using cached financial data for TATAMOTORS.NS, metric: P/E
2025-06-09 10:34:29,174 - INFO - Test complete: financial_data_basic_pe_ratio, Success: True, Time: 0.002s
2025-06-09 10:34:29,175 - INFO - Testing tool: financial_data_historical_price
2025-06-09 10:34:31,572 - INFO - Test complete: financial_data_historical_price, Success: True, Time: 2.397s
2025-06-09 10:34:31,573 - INFO - Testing tool: financial_data_invalid_ticker
2025-06-09 10:34:31,919 - ERROR - Error: HTTP Error 404: , Context: {"action": "fetch_financial_data", "ticker": "INVALIDTICKER.NS", "metric": "P/E"}
2025-06-09 10:34:32,013 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 864, in fetch_financial_data
    info = ticker_obj.info
           ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\ticker.py", line 159, in info
    return self.get_info()
           ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\base.py", line 293, in get_info
    data = self._quote.info
           ^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\scrapers\quote.py", line 511, in info
    self._fetch_info()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\scrapers\quote.py", line 610, in _fetch_info
    result = self._fetch(modules=modules)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\scrapers\quote.py", line 590, in _fetch
    result = self._data.get_raw_json(_QUOTE_SUMMARY_URL_ + f"/{self._symbol}", params=params_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\data.py", line 425, in get_raw_json
    response.raise_for_status()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\curl_cffi\requests\models.py", line 167, in raise_for_status
    raise HTTPError(f"HTTP Error {self.status_code}: {self.reason}", 0, self)
curl_cffi.requests.exceptions.HTTPError: HTTP Error 404: 

2025-06-09 10:34:32,014 - INFO - Test complete: financial_data_invalid_ticker, Success: True, Time: 0.440s
2025-06-09 10:34:32,015 - INFO - Testing tool: financial_data_ratio_by_date
2025-06-09 10:34:33,447 - INFO - Test complete: financial_data_ratio_by_date, Success: True, Time: 1.432s
2025-06-09 10:34:33,448 - INFO - Testing tool: financial_data_future_date_error
2025-06-09 10:34:33,449 - INFO - Test complete: financial_data_future_date_error, Success: True, Time: 0.001s
2025-06-09 10:34:33,449 - INFO - Testing tool: financial_ratio_by_date_pe_ratio_past_date
2025-06-09 10:34:34,638 - INFO - Test complete: financial_ratio_by_date_pe_ratio_past_date, Success: True, Time: 1.189s
2025-06-09 10:34:34,639 - INFO - Testing tool: financial_ratio_by_date_stock_price_weekend
2025-06-09 10:34:35,829 - INFO - Test complete: financial_ratio_by_date_stock_price_weekend, Success: True, Time: 1.190s
2025-06-09 10:34:35,830 - INFO - Testing tool: financial_ratio_by_date_invalid_ratio_name
2025-06-09 10:34:35,831 - INFO - Test complete: financial_ratio_by_date_invalid_ratio_name, Success: True, Time: 0.001s
2025-06-09 10:34:35,831 - INFO - Testing tool: financial_ratio_by_date_missing_ticker
2025-06-09 10:34:35,832 - INFO - Test complete: financial_ratio_by_date_missing_ticker, Success: True, Time: 0.001s
2025-06-09 10:34:35,832 - INFO - Testing tool: company_news_basic_news_fetch
2025-06-09 10:34:35,868 - INFO - Using cached news for TATAMOTORS.NS
2025-06-09 10:34:35,868 - INFO - Test complete: company_news_basic_news_fetch, Success: True, Time: 0.037s
2025-06-09 10:34:35,869 - INFO - Testing tool: company_news_large_news_fetch
2025-06-09 10:34:36,273 - INFO - Test complete: company_news_large_news_fetch, Success: True, Time: 0.403s
2025-06-09 10:34:36,274 - INFO - Testing tool: company_news_invalid_ticker_news
2025-06-09 10:34:36,427 - INFO - Test complete: company_news_invalid_ticker_news, Success: True, Time: 0.153s
2025-06-09 10:34:36,428 - INFO - Testing tool: company_news_zero_results
2025-06-09 10:34:36,616 - INFO - Test complete: company_news_zero_results, Success: True, Time: 0.188s
2025-06-09 10:34:36,616 - INFO - Testing tool: calculate_metrics_simple_roe_calculation
2025-06-09 10:34:36,617 - INFO - Test complete: calculate_metrics_simple_roe_calculation, Success: True, Time: 0.000s
2025-06-09 10:34:36,618 - INFO - Testing tool: calculate_metrics_complex_calculation
2025-06-09 10:34:36,618 - INFO - Test complete: calculate_metrics_complex_calculation, Success: True, Time: 0.000s
2025-06-09 10:34:36,618 - INFO - Testing tool: calculate_metrics_time_series_calculation
2025-06-09 10:34:36,619 - INFO - Test complete: calculate_metrics_time_series_calculation, Success: True, Time: 0.001s
2025-06-09 10:34:36,619 - INFO - Testing tool: calculate_metrics_invalid_formula
2025-06-09 10:34:36,620 - INFO - Test complete: calculate_metrics_invalid_formula, Success: True, Time: 0.001s
2025-06-09 10:34:36,620 - INFO - Testing tool: calculate_metrics_missing_variables
2025-06-09 10:34:36,620 - INFO - Test complete: calculate_metrics_missing_variables, Success: True, Time: 0.000s
2025-06-09 10:34:36,621 - INFO - Testing tool: calculate_metrics_division_by_zero
2025-06-09 10:34:36,621 - ERROR - Error: division by zero, Context: {"action": "calculate_metrics", "formula": "Result = A / B"}
2025-06-09 10:34:36,622 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 1173, in calculate_metrics
    result = eval(formula_to_eval, {"__builtins__": {}}, eval_env)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 1, in <module>
ZeroDivisionError: division by zero

2025-06-09 10:34:36,622 - INFO - Test complete: calculate_metrics_division_by_zero, Success: True, Time: 0.001s
2025-06-09 10:34:37,631 - INFO - Testing tool: reasoning_financial_analysis
2025-06-09 10:34:39,584 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 10:34:39,584 - INFO - Test complete: reasoning_financial_analysis, Success: True, Time: 1.953s
2025-06-09 10:34:40,594 - INFO - Testing tool: reasoning_investment_recommendation
2025-06-09 10:34:40,882 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 10:34:40,882 - INFO - Test complete: reasoning_investment_recommendation, Success: True, Time: 0.289s
2025-06-09 10:34:41,886 - INFO - Testing tool: reasoning_large_data_input
2025-06-09 10:34:42,174 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 10:34:42,174 - INFO - Test complete: reasoning_large_data_input, Success: True, Time: 0.287s
2025-06-09 10:34:43,188 - INFO - Testing tool: reasoning_empty_data
2025-06-09 10:34:43,475 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 10:34:43,475 - INFO - Test complete: reasoning_empty_data, Success: True, Time: 0.287s
2025-06-09 10:34:43,476 - INFO - Testing tool: search_knowledge_base_basic_search
2025-06-09 10:34:45,191 - INFO - HTTP Request: GET https://chroma-onnx-models.s3.amazonaws.com/all-MiniLM-L6-v2/onnx.tar.gz "HTTP/1.1 200 OK"
2025-06-09 10:36:14,082 - ERROR - ChromaDB direct query failed: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:36:14,148 - INFO - MongoDB indexes created successfully
2025-06-09 10:36:14,157 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-09 10:36:14,158 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-09 10:36:14,608 - ERROR - Error in retrieve_chunks: Expected where to have exactly one operator, got {} in query.
2025-06-09 10:36:14,686 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 1258, in search_knowledge_base
    chroma_results = chroma_collection.query(**query_params)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 221, in query
    query_results = self._client._query(
                    ^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\rust.py", line 505, in _query
    rust_response = self.bindings.query(
                    ^^^^^^^^^^^^^^^^^^^^
chromadb.errors.InvalidArgumentError: Collection expecting embedding with dimension of 768, got 384

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\vector.py", line 374, in retrieve_chunks
    results = self.chroma_collection.query(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 209, in query
    query_request = self._validate_and_prepare_query_request(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 309, in _validate_and_prepare_query_request
    validate_filter_set(filter_set=filters)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 354, in validate_filter_set
    validate_where(filter_set["where"])
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 739, in validate_where
    raise ValueError(f"Expected where to have exactly one operator, got {where}")
ValueError: Expected where to have exactly one operator, got {} in query.

2025-06-09 10:36:14,688 - INFO - Database connections closed
2025-06-09 10:36:14,688 - INFO - Test complete: search_knowledge_base_basic_search, Success: True, Time: 91.212s
2025-06-09 10:36:14,689 - INFO - Testing tool: search_knowledge_base_company_filtered_search
2025-06-09 10:36:14,844 - ERROR - ChromaDB direct query failed: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:36:14,851 - INFO - MongoDB indexes created successfully
2025-06-09 10:36:14,863 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-09 10:36:14,863 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-09 10:36:16,564 - ERROR - Error in retrieve_chunks: Expected where to have exactly one operator, got {} in query.
2025-06-09 10:36:16,565 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 1258, in search_knowledge_base
    chroma_results = chroma_collection.query(**query_params)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 221, in query
    query_results = self._client._query(
                    ^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\rust.py", line 505, in _query
    rust_response = self.bindings.query(
                    ^^^^^^^^^^^^^^^^^^^^
chromadb.errors.InvalidArgumentError: Collection expecting embedding with dimension of 768, got 384

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\vector.py", line 374, in retrieve_chunks
    results = self.chroma_collection.query(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 209, in query
    query_request = self._validate_and_prepare_query_request(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 309, in _validate_and_prepare_query_request
    validate_filter_set(filter_set=filters)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 354, in validate_filter_set
    validate_where(filter_set["where"])
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 739, in validate_where
    raise ValueError(f"Expected where to have exactly one operator, got {where}")
ValueError: Expected where to have exactly one operator, got {} in query.

2025-06-09 10:36:16,568 - INFO - Database connections closed
2025-06-09 10:36:16,568 - INFO - Test complete: search_knowledge_base_company_filtered_search, Success: True, Time: 1.878s
2025-06-09 10:36:16,569 - INFO - Testing tool: search_knowledge_base_category_filtered_search
2025-06-09 10:36:16,737 - ERROR - ChromaDB direct query failed: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:36:16,744 - INFO - MongoDB indexes created successfully
2025-06-09 10:36:16,755 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-09 10:36:16,755 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-09 10:36:17,177 - ERROR - Error in retrieve_chunks: Expected where to have exactly one operator, got {} in query.
2025-06-09 10:36:17,177 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 1258, in search_knowledge_base
    chroma_results = chroma_collection.query(**query_params)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 221, in query
    query_results = self._client._query(
                    ^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\rust.py", line 505, in _query
    rust_response = self.bindings.query(
                    ^^^^^^^^^^^^^^^^^^^^
chromadb.errors.InvalidArgumentError: Collection expecting embedding with dimension of 768, got 384

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\vector.py", line 374, in retrieve_chunks
    results = self.chroma_collection.query(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 209, in query
    query_request = self._validate_and_prepare_query_request(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 309, in _validate_and_prepare_query_request
    validate_filter_set(filter_set=filters)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 354, in validate_filter_set
    validate_where(filter_set["where"])
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 739, in validate_where
    raise ValueError(f"Expected where to have exactly one operator, got {where}")
ValueError: Expected where to have exactly one operator, got {} in query.

2025-06-09 10:36:17,180 - INFO - Database connections closed
2025-06-09 10:36:17,180 - INFO - Test complete: search_knowledge_base_category_filtered_search, Success: True, Time: 0.611s
2025-06-09 10:36:17,180 - INFO - Testing tool: search_knowledge_base_empty_query
2025-06-09 10:36:17,361 - ERROR - ChromaDB direct query failed: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:36:17,380 - INFO - MongoDB indexes created successfully
2025-06-09 10:36:17,389 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-09 10:36:17,389 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-09 10:36:17,390 - ERROR - Error in retrieve_chunks: Expected where to have exactly one operator, got {} in get.
2025-06-09 10:36:17,390 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 1258, in search_knowledge_base
    chroma_results = chroma_collection.query(**query_params)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 221, in query
    query_results = self._client._query(
                    ^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\rust.py", line 505, in _query
    rust_response = self.bindings.query(
                    ^^^^^^^^^^^^^^^^^^^^
chromadb.errors.InvalidArgumentError: Collection expecting embedding with dimension of 768, got 384

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\vector.py", line 381, in retrieve_chunks
    results = self.chroma_collection.get(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 124, in get
    get_request = self._validate_and_prepare_get_request(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 253, in _validate_and_prepare_get_request
    validate_filter_set(filter_set=filters)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 354, in validate_filter_set
    validate_where(filter_set["where"])
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 739, in validate_where
    raise ValueError(f"Expected where to have exactly one operator, got {where}")
ValueError: Expected where to have exactly one operator, got {} in get.

2025-06-09 10:36:17,391 - INFO - Database connections closed
2025-06-09 10:36:17,392 - INFO - Test complete: search_knowledge_base_empty_query, Success: True, Time: 0.212s
2025-06-09 10:36:17,392 - INFO - Testing tool: search_knowledge_base_no_results_query
2025-06-09 10:36:17,557 - ERROR - ChromaDB direct query failed: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:36:17,582 - INFO - MongoDB indexes created successfully
2025-06-09 10:36:17,592 - INFO - Loaded existing ChromaDB collection: alphasage_chunks
2025-06-09 10:36:17,592 - INFO - AlphaSageVectorDB initialized with ChromaDB at ./chromadb_data
2025-06-09 10:36:18,034 - ERROR - Error in retrieve_chunks: Expected where to have exactly one operator, got {} in query.
2025-06-09 10:36:18,035 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 1258, in search_knowledge_base
    chroma_results = chroma_collection.query(**query_params)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 221, in query
    query_results = self._client._query(
                    ^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\rust.py", line 505, in _query
    rust_response = self.bindings.query(
                    ^^^^^^^^^^^^^^^^^^^^
chromadb.errors.InvalidArgumentError: Collection expecting embedding with dimension of 768, got 384

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\vector.py", line 374, in retrieve_chunks
    results = self.chroma_collection.query(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\Collection.py", line 209, in query
    query_request = self._validate_and_prepare_query_request(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 95, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\models\CollectionCommon.py", line 309, in _validate_and_prepare_query_request
    validate_filter_set(filter_set=filters)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 354, in validate_filter_set
    validate_where(filter_set["where"])
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\chromadb\api\types.py", line 739, in validate_where
    raise ValueError(f"Expected where to have exactly one operator, got {where}")
ValueError: Expected where to have exactly one operator, got {} in query.

2025-06-09 10:36:18,037 - INFO - Database connections closed
2025-06-09 10:36:18,037 - INFO - Test complete: search_knowledge_base_no_results_query, Success: True, Time: 0.645s
2025-06-09 10:41:37,706 - INFO - MongoDB connection established
2025-06-09 10:41:37,713 - INFO - Redis connection established
2025-06-09 10:41:37,877 - INFO - ChromaDB connection established
2025-06-09 10:41:38,041 - INFO - Testing tool: financial_data_basic_pe_ratio
2025-06-09 10:41:38,044 - INFO - Using cached financial data for TATAMOTORS.NS, metric: P/E
2025-06-09 10:41:38,044 - INFO - Test complete: financial_data_basic_pe_ratio, Success: True, Time: 0.003s
2025-06-09 10:41:38,044 - INFO - Testing tool: financial_data_historical_price
2025-06-09 10:41:38,047 - INFO - Using cached financial data for RELIANCE.NS, metric: price
2025-06-09 10:41:38,047 - INFO - Test complete: financial_data_historical_price, Success: True, Time: 0.003s
2025-06-09 10:41:38,047 - INFO - Testing tool: financial_data_invalid_ticker
2025-06-09 10:41:41,164 - WARNING - yfinance .info failed for INVALIDTICKER.NS: HTTP Error 404: 
2025-06-09 10:41:41,164 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "INVALIDTICKER.NS", "metric": "P/E"}
2025-06-09 10:41:41,226 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 887, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 10:41:41,226 - INFO - Test complete: financial_data_invalid_ticker, Success: True, Time: 3.179s
2025-06-09 10:41:41,226 - INFO - Testing tool: financial_data_ratio_by_date
2025-06-09 10:41:42,627 - INFO - Test complete: financial_data_ratio_by_date, Success: True, Time: 1.399s
2025-06-09 10:41:42,627 - INFO - Testing tool: financial_data_future_date_error
2025-06-09 10:41:42,629 - INFO - Test complete: financial_data_future_date_error, Success: True, Time: 0.001s
2025-06-09 10:41:42,629 - INFO - Testing tool: financial_ratio_by_date_pe_ratio_past_date
2025-06-09 10:41:42,878 - INFO - Test complete: financial_ratio_by_date_pe_ratio_past_date, Success: True, Time: 0.249s
2025-06-09 10:41:42,879 - INFO - Testing tool: financial_ratio_by_date_stock_price_weekend
2025-06-09 10:41:44,001 - INFO - Test complete: financial_ratio_by_date_stock_price_weekend, Success: True, Time: 1.122s
2025-06-09 10:41:44,002 - INFO - Testing tool: financial_ratio_by_date_invalid_ratio_name
2025-06-09 10:41:44,003 - INFO - Test complete: financial_ratio_by_date_invalid_ratio_name, Success: True, Time: 0.001s
2025-06-09 10:41:44,003 - INFO - Testing tool: financial_ratio_by_date_missing_ticker
2025-06-09 10:41:44,004 - INFO - Test complete: financial_ratio_by_date_missing_ticker, Success: True, Time: 0.001s
2025-06-09 10:41:44,004 - INFO - Testing tool: company_news_basic_news_fetch
2025-06-09 10:41:44,006 - INFO - Using cached news for TATAMOTORS.NS
2025-06-09 10:41:44,006 - INFO - Test complete: company_news_basic_news_fetch, Success: True, Time: 0.002s
2025-06-09 10:41:44,006 - INFO - Testing tool: company_news_large_news_fetch
2025-06-09 10:41:44,046 - INFO - Using cached news for RELIANCE.NS
2025-06-09 10:41:44,046 - INFO - Test complete: company_news_large_news_fetch, Success: True, Time: 0.040s
2025-06-09 10:41:44,046 - INFO - Testing tool: company_news_invalid_ticker_news
2025-06-09 10:41:44,429 - INFO - Test complete: company_news_invalid_ticker_news, Success: True, Time: 0.381s
2025-06-09 10:41:44,430 - INFO - Testing tool: company_news_zero_results
2025-06-09 10:41:44,690 - INFO - Test complete: company_news_zero_results, Success: True, Time: 0.260s
2025-06-09 10:41:44,691 - INFO - Testing tool: calculate_metrics_simple_roe_calculation
2025-06-09 10:41:44,692 - INFO - Test complete: calculate_metrics_simple_roe_calculation, Success: True, Time: 0.001s
2025-06-09 10:41:44,692 - INFO - Testing tool: calculate_metrics_complex_calculation
2025-06-09 10:41:44,693 - INFO - Test complete: calculate_metrics_complex_calculation, Success: True, Time: 0.000s
2025-06-09 10:41:44,694 - INFO - Testing tool: calculate_metrics_time_series_calculation
2025-06-09 10:41:44,694 - INFO - Test complete: calculate_metrics_time_series_calculation, Success: True, Time: 0.000s
2025-06-09 10:41:44,695 - INFO - Testing tool: calculate_metrics_invalid_formula
2025-06-09 10:41:44,695 - INFO - Test complete: calculate_metrics_invalid_formula, Success: True, Time: 0.000s
2025-06-09 10:41:44,696 - INFO - Testing tool: calculate_metrics_missing_variables
2025-06-09 10:41:44,697 - INFO - Test complete: calculate_metrics_missing_variables, Success: True, Time: 0.001s
2025-06-09 10:41:44,697 - INFO - Testing tool: calculate_metrics_division_by_zero
2025-06-09 10:41:44,698 - ERROR - Error: division by zero, Context: {"action": "calculate_metrics", "formula": "Result = A / B"}
2025-06-09 10:41:44,699 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 1182, in calculate_metrics
    result = eval(formula_to_eval, {"__builtins__": {}}, eval_env)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 1, in <module>
ZeroDivisionError: division by zero

2025-06-09 10:41:44,699 - INFO - Test complete: calculate_metrics_division_by_zero, Success: True, Time: 0.001s
2025-06-09 10:41:45,712 - INFO - Testing tool: reasoning_financial_analysis
2025-06-09 10:41:47,395 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 10:41:47,396 - INFO - Test complete: reasoning_financial_analysis, Success: True, Time: 1.684s
2025-06-09 10:41:48,407 - INFO - Testing tool: reasoning_investment_recommendation
2025-06-09 10:41:48,689 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 10:41:48,689 - INFO - Test complete: reasoning_investment_recommendation, Success: True, Time: 0.281s
2025-06-09 10:41:49,700 - INFO - Testing tool: reasoning_large_data_input
2025-06-09 10:41:49,983 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 10:41:49,984 - INFO - Test complete: reasoning_large_data_input, Success: True, Time: 0.284s
2025-06-09 10:41:50,985 - INFO - Testing tool: reasoning_empty_data
2025-06-09 10:41:51,276 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 10:41:51,276 - INFO - Test complete: reasoning_empty_data, Success: True, Time: 0.290s
2025-06-09 10:41:51,277 - INFO - Testing tool: search_knowledge_base_basic_search
2025-06-09 10:41:51,741 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:41:51,741 - INFO - Test complete: search_knowledge_base_basic_search, Success: True, Time: 0.465s
2025-06-09 10:41:51,741 - INFO - Testing tool: search_knowledge_base_company_filtered_search
2025-06-09 10:41:51,912 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:41:51,912 - INFO - Test complete: search_knowledge_base_company_filtered_search, Success: True, Time: 0.171s
2025-06-09 10:41:51,913 - INFO - Testing tool: search_knowledge_base_category_filtered_search
2025-06-09 10:41:52,067 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:41:52,068 - INFO - Test complete: search_knowledge_base_category_filtered_search, Success: True, Time: 0.156s
2025-06-09 10:41:52,068 - INFO - Testing tool: search_knowledge_base_empty_query
2025-06-09 10:41:52,232 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:41:52,233 - INFO - Test complete: search_knowledge_base_empty_query, Success: True, Time: 0.164s
2025-06-09 10:41:52,233 - INFO - Testing tool: search_knowledge_base_no_results_query
2025-06-09 10:41:52,389 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:41:52,389 - INFO - Test complete: search_knowledge_base_no_results_query, Success: True, Time: 0.156s
2025-06-09 10:42:32,014 - INFO - MongoDB connection established
2025-06-09 10:42:32,022 - INFO - Redis connection established
2025-06-09 10:42:32,098 - INFO - ChromaDB connection established
2025-06-09 10:42:32,106 - INFO - Redis connection established for micro agents
2025-06-09 10:42:32,115 - INFO - MongoDB connection established for micro agents
2025-06-09 10:42:32,222 - INFO - Configured 10 micro agents
2025-06-09 10:42:32,268 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 10:42:32,268 - INFO - Testing micro agent: valuation
2025-06-09 10:42:32,269 - ERROR - Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"ticker": "TATAMOTORS.NS", "company_name": "Tata Motors"}
2025-06-09 10:42:32,270 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 315, in calculate_valuation_ratios
    pe_data = await self.retry_tool_call(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 265, in retry_tool_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 10:42:32,270 - INFO - Test complete for valuation: Success=False, Time=0.00s
2025-06-09 10:42:32,270 - INFO - Testing micro agent: profitability
2025-06-09 10:42:32,272 - ERROR - Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"ticker": "TATAMOTORS.NS", "company_name": "Tata Motors"}
2025-06-09 10:42:32,272 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 404, in calculate_profitability_ratios
    roe_data = await self.retry_tool_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 265, in retry_tool_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 10:42:32,272 - INFO - Test complete for profitability: Success=False, Time=0.00s
2025-06-09 10:42:32,272 - INFO - Testing micro agent: news
2025-06-09 10:42:32,273 - ERROR - Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"ticker": "TATAMOTORS.NS", "date_range": null}
2025-06-09 10:42:32,273 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 751, in analyze_news
    news_articles = await self.retry_tool_call(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 265, in retry_tool_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 10:42:32,273 - INFO - Test complete for news: Success=False, Time=0.00s
2025-06-09 10:42:32,273 - INFO - Testing micro agent: historical
2025-06-09 10:42:32,274 - ERROR - Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"ticker": "TATAMOTORS.NS", "company_name": "Tata Motors", "years": 3}
2025-06-09 10:42:32,274 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 827, in fetch_historical_data
    price_data = await self.retry_tool_call(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 265, in retry_tool_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 10:42:32,274 - INFO - Test complete for historical: Success=False, Time=0.00s
2025-06-09 10:42:32,275 - INFO - Testing micro agent: guidance
2025-06-09 10:42:32,275 - INFO - Test complete for guidance: Success=True, Time=0.00s
2025-06-09 10:42:32,276 - INFO - Testing micro agent: scenario
2025-06-09 10:42:32,276 - ERROR - Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"company_name": "Tata Motors", "metrics": {"P/E": 15.5, "ROE": 0.12, "Debt_Equity": 0.8}}
2025-06-09 10:42:32,277 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1101, in generate_scenarios
    scenario_reasoning = await self.retry_tool_call(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 265, in retry_tool_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 10:42:32,277 - INFO - Test complete for scenario: Success=False, Time=0.00s
2025-06-09 10:45:56,389 - INFO - MongoDB connection established
2025-06-09 10:45:56,456 - INFO - Redis connection established
2025-06-09 10:45:56,533 - INFO - ChromaDB connection established
2025-06-09 10:45:56,541 - INFO - Redis connection established for micro agents
2025-06-09 10:45:56,546 - INFO - MongoDB connection established for micro agents
2025-06-09 10:45:56,649 - INFO - Configured 10 micro agents
2025-06-09 10:45:56,695 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 10:45:56,696 - INFO - Testing micro agent: valuation
2025-06-09 10:45:56,697 - WARNING - Tool call attempt 1 failed, retrying in 2.1s: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:45:58,800 - WARNING - Tool call attempt 2 failed, retrying in 4.1s: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:02,912 - ERROR - Tool call failed after 3 attempts: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:02,913 - ERROR - Agent Error: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric', Context: {"ticker": "TATAMOTORS.NS", "company_name": "Tata Motors"}
2025-06-09 10:46:02,913 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 317, in calculate_valuation_ratios
    pe_data = await self.retry_tool_call(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 285, in retry_tool_call
    raise last_exception
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 273, in retry_tool_call
    return await func(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^
TypeError: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'

2025-06-09 10:46:02,914 - INFO - Test complete for valuation: Success=False, Time=6.22s
2025-06-09 10:46:02,914 - INFO - Testing micro agent: profitability
2025-06-09 10:46:02,916 - WARNING - Tool call attempt 1 failed, retrying in 2.1s: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:05,021 - WARNING - Tool call attempt 2 failed, retrying in 4.1s: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:09,127 - ERROR - Tool call failed after 3 attempts: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:09,127 - ERROR - Agent Error: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric', Context: {"ticker": "TATAMOTORS.NS", "company_name": "Tata Motors"}
2025-06-09 10:46:09,128 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 406, in calculate_profitability_ratios
    roe_data = await self.retry_tool_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 285, in retry_tool_call
    raise last_exception
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 273, in retry_tool_call
    return await func(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^
TypeError: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'

2025-06-09 10:46:09,128 - INFO - Test complete for profitability: Success=False, Time=6.21s
2025-06-09 10:46:09,129 - INFO - Testing micro agent: liquidity
2025-06-09 10:46:09,412 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:46:09,453 - INFO - Test complete for liquidity: Success=True, Time=0.32s
2025-06-09 10:46:09,454 - INFO - Testing micro agent: leverage
2025-06-09 10:46:09,454 - WARNING - Tool call attempt 1 failed, retrying in 2.1s: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:11,562 - WARNING - Tool call attempt 2 failed, retrying in 4.1s: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:15,676 - ERROR - Tool call failed after 3 attempts: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:15,676 - ERROR - Agent Error: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric', Context: {"ticker": "TATAMOTORS.NS", "company_name": "Tata Motors"}
2025-06-09 10:46:15,677 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 618, in calculate_leverage_ratios
    de_data = await self.retry_tool_call(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 285, in retry_tool_call
    raise last_exception
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 273, in retry_tool_call
    return await func(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^
TypeError: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'

2025-06-09 10:46:15,677 - INFO - Test complete for leverage: Success=False, Time=6.22s
2025-06-09 10:46:15,677 - INFO - Testing micro agent: efficiency
2025-06-09 10:46:15,877 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:46:15,878 - INFO - Test complete for efficiency: Success=True, Time=0.20s
2025-06-09 10:46:15,878 - INFO - Testing micro agent: news
2025-06-09 10:46:15,879 - WARNING - Tool call attempt 1 failed, retrying in 2.1s: YFinanceNewsTool.fetch_company_news() missing 1 required positional argument: 'ticker'
2025-06-09 10:46:17,980 - WARNING - Tool call attempt 2 failed, retrying in 4.1s: YFinanceNewsTool.fetch_company_news() missing 1 required positional argument: 'ticker'
2025-06-09 10:46:22,082 - ERROR - Tool call failed after 3 attempts: YFinanceNewsTool.fetch_company_news() missing 1 required positional argument: 'ticker'
2025-06-09 10:46:22,083 - ERROR - Agent Error: YFinanceNewsTool.fetch_company_news() missing 1 required positional argument: 'ticker', Context: {"ticker": "TATAMOTORS.NS", "date_range": null}
2025-06-09 10:46:22,083 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 753, in analyze_news
    news_articles = await self.retry_tool_call(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 285, in retry_tool_call
    raise last_exception
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 273, in retry_tool_call
    return await func(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^
TypeError: YFinanceNewsTool.fetch_company_news() missing 1 required positional argument: 'ticker'

2025-06-09 10:46:22,083 - INFO - Test complete for news: Success=False, Time=6.20s
2025-06-09 10:46:22,084 - INFO - Testing micro agent: historical
2025-06-09 10:46:22,085 - WARNING - Tool call attempt 1 failed, retrying in 2.1s: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:24,198 - WARNING - Tool call attempt 2 failed, retrying in 4.1s: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:28,306 - ERROR - Tool call failed after 3 attempts: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'
2025-06-09 10:46:28,306 - ERROR - Agent Error: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric', Context: {"ticker": "TATAMOTORS.NS", "company_name": "Tata Motors", "years": 3}
2025-06-09 10:46:28,306 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 829, in fetch_historical_data
    price_data = await self.retry_tool_call(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 285, in retry_tool_call
    raise last_exception
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 273, in retry_tool_call
    return await func(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^
TypeError: YFinanceNumberTool.fetch_financial_data() missing 1 required positional argument: 'metric'

2025-06-09 10:46:28,307 - INFO - Test complete for historical: Success=False, Time=6.22s
2025-06-09 10:46:28,307 - INFO - Testing micro agent: guidance
2025-06-09 10:46:28,310 - INFO - Test complete for guidance: Success=True, Time=0.00s
2025-06-09 10:46:28,310 - INFO - Testing micro agent: sentiment
2025-06-09 10:46:28,484 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 10:46:28,485 - WARNING - Tool call attempt 1 failed, retrying in 2.1s: ReasoningTool.reason_on_data() missing 1 required positional argument: 'query'
2025-06-09 10:46:30,592 - WARNING - Tool call attempt 2 failed, retrying in 4.1s: ReasoningTool.reason_on_data() missing 1 required positional argument: 'query'
2025-06-09 10:46:34,703 - ERROR - Tool call failed after 3 attempts: ReasoningTool.reason_on_data() missing 1 required positional argument: 'query'
2025-06-09 10:46:34,703 - ERROR - Agent Error: ReasoningTool.reason_on_data() missing 1 required positional argument: 'query', Context: {"company_name": "Tata Motors"}
2025-06-09 10:46:34,704 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1018, in analyze_sentiment
    sentiment_analysis = await self.retry_tool_call(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 285, in retry_tool_call
    raise last_exception
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 273, in retry_tool_call
    return await func(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^
TypeError: ReasoningTool.reason_on_data() missing 1 required positional argument: 'query'

2025-06-09 10:46:34,705 - INFO - Test complete for sentiment: Success=False, Time=6.40s
2025-06-09 10:46:34,705 - INFO - Testing micro agent: scenario
2025-06-09 10:46:34,707 - WARNING - Tool call attempt 1 failed, retrying in 2.1s: ReasoningTool.reason_on_data() missing 1 required positional argument: 'query'
2025-06-09 10:46:36,817 - WARNING - Tool call attempt 2 failed, retrying in 4.1s: ReasoningTool.reason_on_data() missing 1 required positional argument: 'query'
2025-06-09 10:46:40,931 - ERROR - Tool call failed after 3 attempts: ReasoningTool.reason_on_data() missing 1 required positional argument: 'query'
2025-06-09 10:46:40,932 - ERROR - Agent Error: ReasoningTool.reason_on_data() missing 1 required positional argument: 'query', Context: {"company_name": "Tata Motors", "metrics": {"P/E": 15.5, "ROE": 0.12, "Debt_Equity": 0.8}}
2025-06-09 10:46:40,932 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1103, in generate_scenarios
    scenario_reasoning = await self.retry_tool_call(
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 285, in retry_tool_call
    raise last_exception
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 273, in retry_tool_call
    return await func(*args, **kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^
TypeError: ReasoningTool.reason_on_data() missing 1 required positional argument: 'query'

2025-06-09 10:46:40,933 - INFO - Test complete for scenario: Success=False, Time=6.23s
2025-06-09 11:28:00,647 - INFO - MongoDB connection established
2025-06-09 11:28:00,664 - INFO - Redis connection established
2025-06-09 11:28:00,851 - INFO - ChromaDB connection established
2025-06-09 11:28:00,862 - INFO - Redis connection established for micro agents
2025-06-09 11:28:00,929 - INFO - MongoDB connection established for micro agents
2025-06-09 11:28:01,081 - INFO - Configured 10 micro agents
2025-06-09 11:28:01,403 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 11:28:01,404 - INFO - Testing micro agent: valuation
2025-06-09 11:28:04,448 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 11:28:04,842 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:04,844 - INFO - Test complete for valuation: Success=True, Time=3.44s
2025-06-09 11:28:04,846 - INFO - Testing micro agent: profitability
2025-06-09 11:28:05,532 - INFO - Using cached financial data for TATAMOTORS.NS, metric: revenue
2025-06-09 11:28:05,773 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 11:28:06,037 - ERROR - Error: 'str' object has no attribute 'strftime', Context: {"action": "fetch_financial_data", "ticker": "TATAMOTORS.NS", "metric": "quarterly income statement"}
2025-06-09 11:28:06,038 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 830, in fetch_financial_data
    "date": index.strftime("%Y-%m-%d"),
            ^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'strftime'

2025-06-09 11:28:06,040 - INFO - Test complete for profitability: Success=True, Time=1.19s
2025-06-09 11:28:06,041 - INFO - Testing micro agent: liquidity
2025-06-09 11:28:06,041 - INFO - Test complete for liquidity: Success=True, Time=0.00s
2025-06-09 11:28:06,042 - INFO - Testing micro agent: leverage
2025-06-09 11:28:06,635 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 11:28:06,917 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:06,919 - INFO - Test complete for leverage: Success=True, Time=0.88s
2025-06-09 11:28:06,919 - INFO - Testing micro agent: efficiency
2025-06-09 11:28:06,921 - INFO - Test complete for efficiency: Success=True, Time=0.00s
2025-06-09 11:28:06,921 - INFO - Testing micro agent: news
2025-06-09 11:28:07,215 - INFO - Stored 10 news articles for Tata Motors in MongoDB
2025-06-09 11:28:08,165 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:08,750 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:09,738 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:10,272 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:11,290 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:11,800 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:12,825 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:13,410 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:14,344 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:14,938 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:14,939 - INFO - Test complete for news: Success=True, Time=8.02s
2025-06-09 11:28:14,940 - INFO - Testing micro agent: historical
2025-06-09 11:28:15,630 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 11:28:15,632 - INFO - Test complete for historical: Success=True, Time=0.69s
2025-06-09 11:28:15,633 - INFO - Testing micro agent: guidance
2025-06-09 11:28:15,837 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 11:28:15,837 - INFO - Test complete for guidance: Success=True, Time=0.20s
2025-06-09 11:28:15,838 - INFO - Testing micro agent: sentiment
2025-06-09 11:28:16,050 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 11:28:16,335 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:16,337 - INFO - Test complete for sentiment: Success=True, Time=0.50s
2025-06-09 11:28:16,339 - INFO - Testing micro agent: scenario
2025-06-09 11:28:17,582 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 11:28:17,584 - INFO - Test complete for scenario: Success=True, Time=1.25s
2025-06-09 11:49:01,196 - INFO - MongoDB connection established
2025-06-09 11:49:01,205 - INFO - Redis connection established
2025-06-09 11:49:01,350 - INFO - ChromaDB connection established
2025-06-09 11:49:01,359 - INFO - Redis connection established for micro agents
2025-06-09 11:49:01,388 - INFO - MongoDB connection established for micro agents
2025-06-09 11:49:01,532 - INFO - Configured 10 micro agents
2025-06-09 11:49:01,698 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 11:49:01,698 - INFO - Testing micro agent: valuation
2025-06-09 11:49:01,700 - INFO - Test complete for valuation: Success=True, Time=0.00s
2025-06-09 11:49:01,701 - INFO - Testing micro agent: profitability
2025-06-09 11:49:01,701 - INFO - Test complete for profitability: Success=True, Time=0.00s
2025-06-09 11:49:01,702 - INFO - Testing micro agent: liquidity
2025-06-09 11:49:02,193 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 11:49:02,195 - INFO - Test complete for liquidity: Success=True, Time=0.49s
2025-06-09 11:49:02,196 - INFO - Testing micro agent: leverage
2025-06-09 11:49:02,196 - INFO - Test complete for leverage: Success=True, Time=0.00s
2025-06-09 11:49:02,198 - INFO - Testing micro agent: efficiency
2025-06-09 11:49:02,401 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 11:49:02,402 - INFO - Test complete for efficiency: Success=True, Time=0.20s
2025-06-09 11:49:02,403 - INFO - Testing micro agent: news
2025-06-09 11:49:02,404 - INFO - Test complete for news: Success=True, Time=0.00s
2025-06-09 11:49:02,404 - INFO - Testing micro agent: historical
2025-06-09 11:49:02,405 - INFO - Test complete for historical: Success=True, Time=0.00s
2025-06-09 11:49:02,406 - INFO - Testing micro agent: guidance
2025-06-09 11:49:02,406 - INFO - Test complete for guidance: Success=True, Time=0.00s
2025-06-09 11:49:02,407 - INFO - Testing micro agent: sentiment
2025-06-09 11:49:02,409 - INFO - Test complete for sentiment: Success=True, Time=0.00s
2025-06-09 11:49:02,410 - INFO - Testing micro agent: scenario
2025-06-09 11:49:02,411 - INFO - Test complete for scenario: Success=True, Time=0.00s
2025-06-09 12:07:09,815 - INFO - MongoDB connection established
2025-06-09 12:07:09,824 - INFO - Redis connection established
2025-06-09 12:07:09,980 - INFO - ChromaDB connection established
2025-06-09 12:07:10,005 - INFO - Redis connection established for macro agents
2025-06-09 12:07:10,012 - INFO - MongoDB connection established for macro agents
2025-06-09 12:07:10,019 - INFO - Redis connection established for micro agents
2025-06-09 12:07:10,025 - INFO - MongoDB connection established for micro agents
2025-06-09 12:07:10,137 - INFO - Configured 10 micro agents
2025-06-09 12:07:10,306 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 12:07:10,383 - INFO - Configured 8 macro agents
2025-06-09 12:07:10,386 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 12:07:10,398 - ERROR - Macro Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 12:07:10,398 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 310, in analyze_business
    historical_result = await self.retry_micro_call(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 257, in retry_micro_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 12:07:11,406 - ERROR - Macro Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"sector": "Environmental Services", "company_name": "Ganesha Ecosphere Limited"}
2025-06-09 12:07:11,443 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 433, in analyze_sector
    news_result = await self.retry_micro_call(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 257, in retry_micro_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 12:07:12,448 - ERROR - Macro Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 12:07:12,448 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 554, in deep_dive_company
    historical_result = await self.retry_micro_call(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 257, in retry_micro_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 12:07:13,459 - ERROR - Macro Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 12:07:13,460 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 675, in analyze_debt_wc
    leverage_result = await self.retry_micro_call(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 257, in retry_micro_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 12:07:14,467 - ERROR - Macro Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 12:07:14,468 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 777, in analyze_current_affairs
    news_result = await self.retry_micro_call(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 257, in retry_micro_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 12:07:15,481 - ERROR - Macro Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"company_name": "Ganesha Ecosphere Limited", "years": 3}
2025-06-09 12:07:15,482 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 919, in predict_future
    guidance_result = await self.retry_micro_call(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 257, in retry_micro_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 12:07:16,493 - ERROR - Macro Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 12:07:16,494 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 1066, in analyze_concall
    guidance_result = await self.retry_micro_call(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 257, in retry_micro_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 12:07:17,548 - ERROR - Macro Agent Error: '<' not supported between instances of 'int' and 'str', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 12:07:17,549 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 1168, in analyze_risks
    news_result = await self.retry_micro_call(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 257, in retry_micro_call
    while attempt < max_attempts:
          ^^^^^^^^^^^^^^^^^^^^^^
TypeError: '<' not supported between instances of 'int' and 'str'

2025-06-09 12:10:55,074 - INFO - MongoDB connection established
2025-06-09 12:10:55,126 - INFO - Redis connection established
2025-06-09 12:10:55,227 - INFO - ChromaDB connection established
2025-06-09 12:10:55,241 - INFO - Redis connection established for macro agents
2025-06-09 12:10:55,248 - INFO - MongoDB connection established for macro agents
2025-06-09 12:10:55,253 - INFO - Redis connection established for micro agents
2025-06-09 12:10:55,260 - INFO - MongoDB connection established for micro agents
2025-06-09 12:10:55,369 - INFO - Configured 10 micro agents
2025-06-09 12:10:55,425 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 12:10:55,508 - INFO - Configured 8 macro agents
2025-06-09 12:10:55,512 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 12:10:55,514 - ERROR - Macro Agent Error: 'AlphaSageMacroAgents' object has no attribute '_get_ticker_for_company', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 12:10:55,514 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 343, in analyze_business
    ticker = self._get_ticker_for_company(company_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMacroAgents' object has no attribute '_get_ticker_for_company'

2025-06-09 12:10:55,515 - ERROR - Macro Agent Error: 'AlphaSageMacroAgents' object has no attribute '_get_ticker_for_company', Context: {"sector": "Environmental Services", "company_name": "Ganesha Ecosphere Limited"}
2025-06-09 12:10:55,516 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 508, in analyze_sector
    ticker = self._get_ticker_for_company(company_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMacroAgents' object has no attribute '_get_ticker_for_company'

2025-06-09 12:10:57,408 - ERROR - Error: HTTP Error 404: , Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "price"}
2025-06-09 12:10:57,412 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 869, in fetch_financial_data
    hist_data = ticker_obj.history(period=period)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\utils.py", line 99, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\base.py", line 96, in history
    return self._lazy_load_price_history().history(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\base.py", line 102, in _lazy_load_price_history
    self._price_history = PriceHistory(self._data, self.ticker, self._get_ticker_tz(timeout=10))
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\base.py", line 127, in _get_ticker_tz
    if k in self.info:
            ^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\ticker.py", line 159, in info
    return self.get_info()
           ^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\base.py", line 293, in get_info
    data = self._quote.info
           ^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\scrapers\quote.py", line 511, in info
    self._fetch_info()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\scrapers\quote.py", line 610, in _fetch_info
    result = self._fetch(modules=modules)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\scrapers\quote.py", line 590, in _fetch
    result = self._data.get_raw_json(_QUOTE_SUMMARY_URL_ + f"/{self._symbol}", params=params_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\data.py", line 425, in get_raw_json
    response.raise_for_status()
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\curl_cffi\requests\models.py", line 167, in raise_for_status
    raise HTTPError(f"HTTP Error {self.status_code}: {self.reason}", 0, self)
curl_cffi.requests.exceptions.HTTPError: HTTP Error 404: 

2025-06-09 12:10:57,874 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 12:10:58,358 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 12:10:58,538 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 12:10:59,592 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 12:11:00,885 - WARNING - yfinance .info failed for GANESHA ECOSPHERE LIMITED.NS: HTTP Error 404: 
2025-06-09 12:11:00,886 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "debt to equity"}
2025-06-09 12:11:00,887 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 12:11:00,890 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "total debt"}
2025-06-09 12:11:00,890 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 12:11:00,891 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "total equity"}
2025-06-09 12:11:00,892 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 12:11:00,893 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "total debt"}
2025-06-09 12:11:00,893 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 12:11:00,895 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "total assets"}
2025-06-09 12:11:00,895 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 12:11:01,225 - WARNING - yfinance .info failed for GANESHA ECOSPHERE LIMITED.NS: HTTP Error 404: 
2025-06-09 12:11:01,225 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "ebitda"}
2025-06-09 12:11:01,226 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 12:11:01,228 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "interest expense"}
2025-06-09 12:11:01,229 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 12:11:01,388 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 12:11:01,556 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 12:11:01,840 - WARNING - yfinance .info failed for GANESHA ECOSPHERE LIMITED.NS: HTTP Error 404: 
2025-06-09 12:11:01,840 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "debt to equity"}
2025-06-09 12:11:01,841 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 12:11:02,850 - ERROR - Macro Agent Error: 'AlphaSageMacroAgents' object has no attribute '_get_ticker_for_company', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 12:11:02,852 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 884, in analyze_current_affairs
    ticker = self._get_ticker_for_company(company_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMacroAgents' object has no attribute '_get_ticker_for_company'

2025-06-09 12:11:02,853 - ERROR - Macro Agent Error: 'AlphaSageMacroAgents' object has no attribute '_get_ticker_for_company', Context: {"company_name": "Ganesha Ecosphere Limited", "years": 3}
2025-06-09 12:11:02,853 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 1028, in predict_future
    ticker = self._get_ticker_for_company(company_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMacroAgents' object has no attribute '_get_ticker_for_company'

2025-06-09 12:11:03,022 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 12:11:03,311 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 12:11:03,475 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 12:11:05,151 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 13:41:45,818 - INFO - MongoDB connection established
2025-06-09 13:41:45,834 - INFO - Redis connection established
2025-06-09 13:41:46,225 - INFO - ChromaDB connection established
2025-06-09 13:41:46,259 - INFO - Redis connection established for macro agents
2025-06-09 13:41:46,299 - INFO - MongoDB connection established for macro agents
2025-06-09 13:41:46,305 - INFO - Redis connection established for micro agents
2025-06-09 13:41:46,310 - INFO - MongoDB connection established for micro agents
2025-06-09 13:41:46,419 - INFO - Configured 10 micro agents
2025-06-09 13:41:46,593 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 13:41:46,669 - INFO - Configured 8 macro agents
2025-06-09 13:41:46,673 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 13:41:46,675 - INFO - Starting demo analysis for Ganesha Ecosphere Limited
2025-06-09 13:41:46,675 - INFO - Starting comprehensive analysis for Ganesha Ecosphere Limited
2025-06-09 13:41:49,348 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 13:41:49,649 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 13:41:50,158 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 13:41:50,158 - WARNING - ArithmeticCalculationTool failed: 'list' object has no attribute 'get'
2025-06-09 13:41:51,063 - WARNING - yfinance .info failed for GANESHA ECOSPHERE LIMITED.NS: HTTP Error 404: 
2025-06-09 13:41:51,065 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "debt to equity"}
2025-06-09 13:41:51,128 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 13:41:51,129 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "total debt"}
2025-06-09 13:41:51,130 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 13:41:51,130 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "total equity"}
2025-06-09 13:41:51,132 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 13:41:51,133 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "total debt"}
2025-06-09 13:41:51,133 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 13:41:51,134 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "total assets"}
2025-06-09 13:41:51,134 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 13:41:51,504 - WARNING - yfinance .info failed for GANESHA ECOSPHERE LIMITED.NS: HTTP Error 404: 
2025-06-09 13:41:51,504 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "ebitda"}
2025-06-09 13:41:51,505 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 13:41:51,507 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "interest expense"}
2025-06-09 13:41:51,508 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 13:41:51,723 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 13:41:51,925 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 13:41:52,189 - WARNING - yfinance .info failed for GANESHA ECOSPHERE LIMITED.NS: HTTP Error 404: 
2025-06-09 13:41:52,189 - ERROR - Error: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None, Context: {"action": "fetch_financial_data", "ticker": "GANESHA ECOSPHERE LIMITED.NS", "metric": "debt to equity"}
2025-06-09 13:41:52,190 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 911, in fetch_financial_data
    company_name = get_company_name_from_ticker(ticker)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 362, in get_company_name_from_ticker
    if collection:
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\pymongo\synchronous\collection.py", line 311, in __bool__
    raise NotImplementedError(
NotImplementedError: Collection objects do not implement truth value testing or bool(). Please compare with None instead: collection is not None

2025-06-09 13:41:52,197 - WARNING - ScenarioAnalysisAgent failed: 'AlphaSageMicroAgents' object has no attribute 'perform_scenario_analysis'
2025-06-09 13:41:52,198 - INFO - Using cached financial data for GANECOS.NS, metric: revenue
2025-06-09 13:41:52,198 - ERROR - Macro Agent Error: 'list' object has no attribute 'get', Context: {"company_name": "Ganesha Ecosphere Limited", "years": 3}
2025-06-09 13:41:52,198 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 1211, in predict_future
    if current_revenue and current_revenue.get('data', {}).get('revenue'):
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'get'

2025-06-09 13:41:52,229 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 13:41:52,241 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 13:41:52,453 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 13:41:52,477 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 13:41:52,842 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 13:41:53,799 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 13:41:54,249 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 13:41:54,250 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 13:41:54,450 - ERROR - ChromaDB query error: Collection expecting embedding with dimension of 768, got 384
2025-06-09 13:41:54,524 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 13:41:55,814 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 13:41:55,815 - INFO - Comprehensive analysis completed in 9.14 seconds
2025-06-09 13:41:55,831 - INFO - Demo analysis completed successfully for Ganesha Ecosphere Limited
2025-06-09 13:54:50,351 - INFO - MongoDB connection established
2025-06-09 13:54:50,398 - INFO - Redis connection established
2025-06-09 13:54:50,480 - INFO - ChromaDB connection established
2025-06-09 13:54:50,503 - INFO - Redis connection established for macro agents
2025-06-09 13:54:50,509 - INFO - MongoDB connection established for macro agents
2025-06-09 13:54:50,514 - INFO - Redis connection established for micro agents
2025-06-09 13:54:50,538 - INFO - MongoDB connection established for micro agents
2025-06-09 13:54:50,644 - INFO - Configured 10 micro agents
2025-06-09 13:54:50,691 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 13:54:50,766 - INFO - Configured 8 macro agents
2025-06-09 13:54:50,769 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 13:54:50,770 - INFO - Starting demo analysis for Ganesha Ecosphere Limited
2025-06-09 13:54:50,772 - INFO - Starting comprehensive analysis for Ganesha Ecosphere Limited
2025-06-09 13:54:50,774 - ERROR - MicroAgent Error: 'AlphaSageMicroAgents' object has no attribute '_get_ticker_for_company', Context: {"agent": "ScenarioAnalysisAgent", "company_name": "Ganesha Ecosphere Limited"}
2025-06-09 13:54:50,776 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1549, in perform_scenario_analysis
    ticker = self._get_ticker_for_company(company_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMicroAgents' object has no attribute '_get_ticker_for_company'

2025-06-09 13:54:50,777 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 13:54:53,603 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 13:54:53,604 - INFO - Comprehensive analysis completed in 2.83 seconds
2025-06-09 13:54:53,605 - INFO - Demo analysis completed successfully for Ganesha Ecosphere Limited
2025-06-09 14:29:31,515 - INFO - MongoDB connection established
2025-06-09 14:29:31,527 - INFO - Redis connection established
2025-06-09 14:29:31,878 - INFO - ChromaDB connection established
2025-06-09 14:42:17,374 - INFO - MongoDB connection established
2025-06-09 14:42:17,382 - INFO - Redis connection established
2025-06-09 14:42:17,607 - INFO - ChromaDB connection established
2025-06-09 14:45:07,084 - INFO - MongoDB connection established
2025-06-09 14:45:07,088 - INFO - Redis connection established
2025-06-09 14:45:07,239 - INFO - ChromaDB connection established
2025-06-09 14:45:54,703 - INFO - MongoDB connection established
2025-06-09 14:45:54,708 - INFO - Redis connection established
2025-06-09 14:45:54,952 - INFO - ChromaDB connection established
2025-06-09 14:52:14,973 - INFO - MongoDB connection established
2025-06-09 14:52:14,978 - INFO - Redis connection established
2025-06-09 14:52:15,227 - INFO - ChromaDB connection established
2025-06-09 14:52:15,272 - INFO - MongoDB connection established
2025-06-09 14:52:15,274 - INFO - Redis connection established
2025-06-09 14:52:15,275 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 14:52:15,501 - INFO - ChromaDB connection established
2025-06-09 14:52:15,507 - INFO - Redis connection established for macro agents
2025-06-09 14:52:15,529 - INFO - MongoDB connection established for macro agents
2025-06-09 14:52:15,532 - INFO - Redis connection established for micro agents
2025-06-09 14:52:15,590 - INFO - MongoDB connection established for micro agents
2025-06-09 14:52:46,123 - INFO - MongoDB connection established
2025-06-09 14:52:46,127 - INFO - Redis connection established
2025-06-09 14:52:46,337 - INFO - ChromaDB connection established
2025-06-09 14:52:46,377 - INFO - MongoDB connection established
2025-06-09 14:52:46,378 - INFO - Redis connection established
2025-06-09 14:52:46,379 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 14:52:46,554 - INFO - ChromaDB connection established
2025-06-09 14:52:46,561 - INFO - Redis connection established for macro agents
2025-06-09 14:52:46,621 - INFO - MongoDB connection established for macro agents
2025-06-09 14:52:46,629 - INFO - Redis connection established for micro agents
2025-06-09 14:52:46,673 - INFO - MongoDB connection established for micro agents
2025-06-09 14:54:56,918 - INFO - MongoDB connection established
2025-06-09 14:54:56,923 - INFO - Redis connection established
2025-06-09 14:54:57,082 - INFO - ChromaDB connection established
2025-06-09 14:54:57,100 - INFO - MongoDB connection established
2025-06-09 14:54:57,101 - INFO - Redis connection established
2025-06-09 14:54:57,101 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 14:54:57,215 - INFO - ChromaDB connection established
2025-06-09 14:54:57,218 - INFO - Redis connection established for macro agents
2025-06-09 14:54:57,250 - INFO - MongoDB connection established for macro agents
2025-06-09 14:54:57,253 - INFO - Redis connection established for micro agents
2025-06-09 14:54:57,288 - INFO - MongoDB connection established for micro agents
2025-06-09 14:54:57,417 - INFO - Configured 10 micro agents
2025-06-09 14:54:57,580 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 14:54:57,666 - INFO - Configured 8 macro agents
2025-06-09 14:54:57,670 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 14:55:37,314 - INFO - MongoDB connection established
2025-06-09 14:55:37,322 - INFO - Redis connection established
2025-06-09 14:55:37,577 - INFO - ChromaDB connection established
2025-06-09 14:55:37,613 - INFO - MongoDB connection established
2025-06-09 14:55:37,614 - INFO - Redis connection established
2025-06-09 14:55:37,615 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 14:55:37,800 - INFO - ChromaDB connection established
2025-06-09 14:55:37,804 - INFO - Redis connection established for macro agents
2025-06-09 14:55:37,823 - INFO - MongoDB connection established for macro agents
2025-06-09 14:55:37,828 - INFO - Redis connection established for micro agents
2025-06-09 14:55:37,848 - INFO - MongoDB connection established for micro agents
2025-06-09 14:55:38,058 - INFO - Configured 10 micro agents
2025-06-09 14:55:38,227 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 14:55:38,379 - INFO - Configured 8 macro agents
2025-06-09 14:55:38,386 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 14:55:38,410 - INFO - Starting comprehensive analysis for Ganesha Ecosphere Limited
2025-06-09 14:55:38,419 - ERROR - MicroAgent Error: YFinanceNumberTool.fetch_financial_data() got an unexpected keyword argument 'period', Context: {"ticker": "GANECOS.NS", "company_name": "Ganesha Ecosphere Limited", "years": 5}
2025-06-09 14:55:38,420 - ERROR - Traceback (most recent call last):
  File "C:\Users\Jiten\Desktop\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1190, in fetch_historical_data
    price_data = await YFinanceNumberTool.fetch_financial_data(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: YFinanceNumberTool.fetch_financial_data() got an unexpected keyword argument 'period'

2025-06-09 14:55:38,421 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 14:55:38,424 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 14:55:39,230 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 14:55:39,604 - ERROR - MicroAgent Error: YFinanceNumberTool.fetch_financial_data() got an unexpected keyword argument 'period', Context: {"ticker": "Ganesha Ecosphere Limited.NS", "company_name": "Ganesha Ecosphere Limited", "years": 10}
2025-06-09 14:55:39,605 - ERROR - Traceback (most recent call last):
  File "C:\Users\Jiten\Desktop\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1190, in fetch_historical_data
    price_data = await YFinanceNumberTool.fetch_financial_data(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: YFinanceNumberTool.fetch_financial_data() got an unexpected keyword argument 'period'

2025-06-09 14:55:39,612 - WARNING - Failed to get company name from ticker Ganesha Ecosphere Limited.NS: name 'get_mongodb_connection' is not defined
2025-06-09 14:55:40,029 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 14:55:40,191 - WARNING - Failed to fetch debt to equity: 0
2025-06-09 14:55:40,192 - WARNING - Failed to get company name from ticker Ganesha Ecosphere Limited.NS: name 'get_mongodb_connection' is not defined
2025-06-09 14:55:41,691 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 14:55:41,697 - WARNING - Failed to fetch total debt: 0
2025-06-09 14:55:41,699 - WARNING - Failed to get company name from ticker Ganesha Ecosphere Limited.NS: name 'get_mongodb_connection' is not defined
2025-06-09 14:55:42,854 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 14:55:42,860 - WARNING - Failed to fetch total equity: 0
2025-06-09 14:55:42,862 - INFO - Using cached financial data for Ganesha Ecosphere Limited.NS, metric: total debt
2025-06-09 14:55:42,863 - WARNING - Failed to get company name from ticker Ganesha Ecosphere Limited.NS: name 'get_mongodb_connection' is not defined
2025-06-09 14:55:43,373 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 14:55:43,379 - WARNING - Failed to get company name from ticker Ganesha Ecosphere Limited.NS: name 'get_mongodb_connection' is not defined
2025-06-09 14:55:43,724 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 14:55:43,730 - WARNING - Leverage calculations failed: 0
2025-06-09 14:55:43,731 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 14:55:43,731 - ERROR - MicroAgent Error: ArithmeticCalculationTool.calculate_metrics() got an unexpected keyword argument 'inputs', Context: {"ticker": "Ganesha Ecosphere Limited.NS", "company_name": "Ganesha Ecosphere Limited"}
2025-06-09 14:55:43,732 - ERROR - Traceback (most recent call last):
  File "C:\Users\Jiten\Desktop\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1043, in calculate_leverage_ratios
    dummy_leverage_calc = ArithmeticCalculationTool.calculate_metrics(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ArithmeticCalculationTool.calculate_metrics() got an unexpected keyword argument 'inputs'

2025-06-09 14:55:43,734 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 14:55:43,737 - INFO - Using cached financial data for Ganesha Ecosphere Limited.NS, metric: debt to equity
2025-06-09 14:55:43,744 - ERROR - MicroAgent Error: YFinanceNumberTool.fetch_financial_data() got an unexpected keyword argument 'period', Context: {"ticker": "GANECOS.NS", "company_name": "Ganesha Ecosphere Limited", "years": 5}
2025-06-09 14:55:43,745 - ERROR - Traceback (most recent call last):
  File "C:\Users\Jiten\Desktop\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1190, in fetch_historical_data
    price_data = await YFinanceNumberTool.fetch_financial_data(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: YFinanceNumberTool.fetch_financial_data() got an unexpected keyword argument 'period'

2025-06-09 14:55:43,746 - ERROR - MicroAgent Error: 'AlphaSageMicroAgents' object has no attribute '_get_ticker_for_company', Context: {"agent": "ScenarioAnalysisAgent", "company_name": "Ganesha Ecosphere Limited"}
2025-06-09 14:55:43,750 - ERROR - Traceback (most recent call last):
  File "C:\Users\Jiten\Desktop\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1549, in perform_scenario_analysis
    ticker = self._get_ticker_for_company(company_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMicroAgents' object has no attribute '_get_ticker_for_company'

2025-06-09 14:55:43,753 - INFO - Using cached financial data for GANECOS.NS, metric: revenue
2025-06-09 14:55:43,770 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 14:55:43,773 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 14:55:43,775 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 14:55:43,776 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 14:55:43,777 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 14:55:44,049 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 14:55:44,253 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 14:55:45,289 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 14:55:45,295 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 14:55:45,297 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 14:55:45,308 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 14:55:45,478 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 14:55:45,480 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 14:55:45,581 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 14:55:46,820 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 14:55:46,821 - INFO - Comprehensive analysis completed in 8.41 seconds
2025-06-09 14:55:46,822 - ERROR - Error generating PDF report: 'MacroAgentResult' object has no attribute 'get'
2025-06-09 14:58:07,645 - INFO - MongoDB connection established
2025-06-09 14:58:07,649 - INFO - Redis connection established
2025-06-09 14:58:07,833 - INFO - ChromaDB connection established
2025-06-09 14:58:07,849 - INFO - MongoDB connection established
2025-06-09 14:58:07,850 - INFO - Redis connection established
2025-06-09 14:58:07,850 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 14:58:07,978 - INFO - ChromaDB connection established
2025-06-09 14:58:07,984 - INFO - Redis connection established for macro agents
2025-06-09 14:58:08,003 - INFO - MongoDB connection established for macro agents
2025-06-09 14:58:08,006 - INFO - Redis connection established for micro agents
2025-06-09 14:58:08,052 - INFO - MongoDB connection established for micro agents
2025-06-09 14:58:08,140 - INFO - Configured 10 micro agents
2025-06-09 14:58:08,257 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 14:58:08,324 - INFO - Configured 8 macro agents
2025-06-09 14:58:08,330 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 14:58:08,341 - INFO - Starting comprehensive analysis for Ganesha Ecosphere Limited
2025-06-09 14:58:08,345 - INFO - Comprehensive analysis completed in 0.00 seconds
2025-06-09 14:58:08,346 - ERROR - Error generating PDF report: 'MacroAgentResult' object has no attribute 'get'
2025-06-09 15:01:36,861 - INFO - MongoDB connection established
2025-06-09 15:01:36,873 - INFO - Redis connection established
2025-06-09 15:01:37,162 - INFO - ChromaDB connection established
2025-06-09 15:01:37,185 - INFO - MongoDB connection established
2025-06-09 15:01:37,186 - INFO - Redis connection established
2025-06-09 15:01:37,187 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 15:01:37,409 - INFO - ChromaDB connection established
2025-06-09 15:01:37,413 - INFO - Redis connection established for macro agents
2025-06-09 15:01:37,425 - INFO - MongoDB connection established for macro agents
2025-06-09 15:01:37,428 - INFO - Redis connection established for micro agents
2025-06-09 15:01:37,440 - INFO - MongoDB connection established for micro agents
2025-06-09 15:01:37,546 - INFO - Configured 10 micro agents
2025-06-09 15:01:37,656 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:01:37,739 - INFO - Configured 8 macro agents
2025-06-09 15:01:37,746 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:01:37,758 - INFO - Starting comprehensive analysis for Ganesha Ecosphere Limited
2025-06-09 15:01:37,763 - INFO - Comprehensive analysis completed in 0.01 seconds
2025-06-09 15:01:39,256 - INFO - PDF report generated successfully: output\Ganesha_Ecosphere_Limited_report.pdf
2025-06-09 15:06:17,763 - INFO - MongoDB connection established
2025-06-09 15:06:17,769 - INFO - Redis connection established
2025-06-09 15:06:17,959 - INFO - ChromaDB connection established
2025-06-09 15:06:17,982 - INFO - MongoDB connection established
2025-06-09 15:06:17,982 - INFO - Redis connection established
2025-06-09 15:06:17,983 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 15:06:18,148 - INFO - ChromaDB connection established
2025-06-09 15:06:18,156 - INFO - Redis connection established for macro agents
2025-06-09 15:06:18,195 - INFO - MongoDB connection established for macro agents
2025-06-09 15:06:18,197 - INFO - Redis connection established for micro agents
2025-06-09 15:06:18,241 - INFO - MongoDB connection established for micro agents
2025-06-09 15:06:18,333 - INFO - Configured 10 micro agents
2025-06-09 15:06:18,491 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:06:18,585 - INFO - Configured 8 macro agents
2025-06-09 15:06:18,590 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:06:18,604 - INFO - Starting comprehensive analysis for Ganesha Ecosphere Limited
2025-06-09 15:06:18,610 - INFO - Comprehensive analysis completed in 0.01 seconds
2025-06-09 15:06:19,708 - INFO - PDF report generated successfully: output\Ganesha_Ecosphere_Limited_report.pdf
2025-06-09 15:20:56,360 - INFO - MongoDB connection established
2025-06-09 15:20:56,373 - INFO - Redis connection established
2025-06-09 15:20:56,532 - INFO - ChromaDB connection established
2025-06-09 15:20:56,613 - INFO - MongoDB connection established
2025-06-09 15:20:56,613 - INFO - Redis connection established
2025-06-09 15:20:56,613 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 15:20:56,645 - INFO - ChromaDB connection established
2025-06-09 15:20:56,651 - INFO - Redis connection established for macro agents
2025-06-09 15:20:56,679 - INFO - MongoDB connection established for macro agents
2025-06-09 15:20:56,685 - INFO - Redis connection established for micro agents
2025-06-09 15:20:56,707 - INFO - MongoDB connection established for micro agents
2025-06-09 15:20:56,817 - INFO - Configured 10 micro agents
2025-06-09 15:20:57,029 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:20:57,108 - INFO - Configured 8 macro agents
2025-06-09 15:20:57,111 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:20:57,116 - INFO - Redis connection established for micro agents
2025-06-09 15:20:57,161 - INFO - MongoDB connection established for micro agents
2025-06-09 15:20:57,263 - INFO - Configured 10 micro agents
2025-06-09 15:20:57,265 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:22:29,431 - INFO - MongoDB connection established
2025-06-09 15:22:29,479 - INFO - Redis connection established
2025-06-09 15:22:29,555 - INFO - ChromaDB connection established
2025-06-09 15:22:29,564 - INFO - MongoDB connection established
2025-06-09 15:22:29,564 - INFO - Redis connection established
2025-06-09 15:22:29,564 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 15:22:29,590 - INFO - ChromaDB connection established
2025-06-09 15:22:29,595 - INFO - Redis connection established for macro agents
2025-06-09 15:22:29,612 - INFO - MongoDB connection established for macro agents
2025-06-09 15:22:29,619 - INFO - Redis connection established for micro agents
2025-06-09 15:22:29,643 - INFO - MongoDB connection established for micro agents
2025-06-09 15:22:29,749 - INFO - Configured 10 micro agents
2025-06-09 15:22:29,793 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:22:29,870 - INFO - Configured 8 macro agents
2025-06-09 15:22:29,872 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:22:29,877 - INFO - Redis connection established for micro agents
2025-06-09 15:22:29,883 - INFO - MongoDB connection established for micro agents
2025-06-09 15:22:29,982 - INFO - Configured 10 micro agents
2025-06-09 15:22:29,985 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:22:29,999 - INFO - PDF Output Agent initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 15:22:29,999 - INFO - Starting comprehensive PDF report generation...
2025-06-09 15:22:29,999 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-09 15:22:29,999 - INFO - Executing macro agents analysis...
2025-06-09 15:22:29,999 - INFO - Executing macro agent: business
2025-06-09 15:22:30,001 - INFO - Macro agent business completed successfully
2025-06-09 15:22:30,001 - INFO - Executing macro agent: sector
2025-06-09 15:22:31,023 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 15:22:31,024 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:31,025 - INFO - Macro agent sector completed successfully
2025-06-09 15:22:31,025 - INFO - Executing macro agent: deepdive
2025-06-09 15:22:31,026 - ERROR - MicroAgent Error: YFinanceNumberTool.fetch_financial_data() got an unexpected keyword argument 'period', Context: {"ticker": "Ganesha Ecosphere Limited.NS", "company_name": "Ganesha Ecosphere Limited", "years": 10}
2025-06-09 15:22:31,027 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1190, in fetch_historical_data
    price_data = await YFinanceNumberTool.fetch_financial_data(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: YFinanceNumberTool.fetch_financial_data() got an unexpected keyword argument 'period'

2025-06-09 15:22:32,278 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 15:22:32,279 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:32,584 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 15:22:32,585 - INFO - Macro agent deepdive completed successfully
2025-06-09 15:22:32,585 - INFO - Executing macro agent: debt_wc
2025-06-09 15:22:32,587 - WARNING - Failed to get company name from ticker Ganesha Ecosphere Limited.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:32,995 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 15:22:33,310 - WARNING - Failed to fetch debt to equity: 0
2025-06-09 15:22:33,311 - WARNING - Failed to get company name from ticker Ganesha Ecosphere Limited.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:33,665 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 15:22:33,670 - WARNING - Failed to fetch total debt: 0
2025-06-09 15:22:33,670 - WARNING - Failed to get company name from ticker Ganesha Ecosphere Limited.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:34,163 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 15:22:34,166 - WARNING - Failed to fetch total equity: 0
2025-06-09 15:22:34,167 - INFO - Using cached financial data for Ganesha Ecosphere Limited.NS, metric: total debt
2025-06-09 15:22:34,168 - WARNING - Failed to get company name from ticker Ganesha Ecosphere Limited.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:34,525 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 15:22:34,529 - WARNING - Failed to get company name from ticker Ganesha Ecosphere Limited.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:34,805 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 15:22:34,808 - WARNING - Leverage calculations failed: 0
2025-06-09 15:22:34,808 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:34,808 - ERROR - MicroAgent Error: ArithmeticCalculationTool.calculate_metrics() got an unexpected keyword argument 'inputs', Context: {"ticker": "Ganesha Ecosphere Limited.NS", "company_name": "Ganesha Ecosphere Limited"}
2025-06-09 15:22:34,808 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1043, in calculate_leverage_ratios
    dummy_leverage_calc = ArithmeticCalculationTool.calculate_metrics(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ArithmeticCalculationTool.calculate_metrics() got an unexpected keyword argument 'inputs'

2025-06-09 15:22:34,809 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:34,810 - INFO - Using cached financial data for Ganesha Ecosphere Limited.NS, metric: debt to equity
2025-06-09 15:22:34,811 - INFO - Macro agent debt_wc completed successfully
2025-06-09 15:22:34,811 - INFO - Executing macro agent: current_affairs
2025-06-09 15:22:35,108 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 15:22:35,236 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:35,239 - INFO - Macro agent current_affairs completed successfully
2025-06-09 15:22:35,239 - INFO - Executing macro agent: predictions
2025-06-09 15:22:35,240 - INFO - Macro agent predictions completed successfully
2025-06-09 15:22:35,240 - INFO - Executing macro agent: concall
2025-06-09 15:22:35,241 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:36,344 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 15:22:36,346 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:36,797 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 15:22:36,799 - INFO - Macro agent concall completed successfully
2025-06-09 15:22:36,799 - INFO - Executing macro agent: risks
2025-06-09 15:22:37,876 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 15:22:38,035 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:38,349 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 15:22:38,351 - INFO - Macro agent risks completed successfully
2025-06-09 15:22:38,352 - INFO - Executing micro agents analysis...
2025-06-09 15:22:38,352 - INFO - Executing micro agent: valuation
2025-06-09 15:22:38,353 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,203 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,325 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,377 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,426 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,487 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,536 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,583 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,640 - WARNING - Custom ratio calculations failed: 0
2025-06-09 15:22:39,640 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:39,641 - INFO - Micro agent valuation completed successfully
2025-06-09 15:22:39,641 - INFO - Executing micro agent: profitability
2025-06-09 15:22:39,643 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,705 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,757 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,820 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:39,883 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:40,024 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:40,080 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:40,130 - INFO - Using cached financial data for GANECOS.NS, metric: revenue
2025-06-09 15:22:40,130 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:40,131 - WARNING - Historical trend analysis failed: YFinanceNumberTool.fetch_financial_data() got an unexpected keyword argument 'period'
2025-06-09 15:22:40,131 - INFO - Micro agent profitability completed successfully
2025-06-09 15:22:40,131 - INFO - Executing micro agent: liquidity
2025-06-09 15:22:40,133 - INFO - Micro agent liquidity completed successfully
2025-06-09 15:22:40,133 - INFO - Executing micro agent: leverage
2025-06-09 15:22:40,135 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:40,183 - WARNING - Failed to fetch debt to equity: 0
2025-06-09 15:22:40,184 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:40,242 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:40,288 - INFO - Using cached financial data for GANECOS.NS, metric: total debt
2025-06-09 15:22:40,289 - INFO - Using cached financial data for GANECOS.NS, metric: total assets
2025-06-09 15:22:40,290 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:40,340 - WARNING - Failed to get company name from ticker GANECOS.NS: name 'get_mongodb_connection' is not defined
2025-06-09 15:22:40,415 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:40,415 - ERROR - MicroAgent Error: ArithmeticCalculationTool.calculate_metrics() got an unexpected keyword argument 'inputs', Context: {"ticker": "GANECOS.NS", "company_name": "Ganesha Ecosphere Limited"}
2025-06-09 15:22:40,416 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1043, in calculate_leverage_ratios
    dummy_leverage_calc = ArithmeticCalculationTool.calculate_metrics(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ArithmeticCalculationTool.calculate_metrics() got an unexpected keyword argument 'inputs'

2025-06-09 15:22:40,416 - INFO - Micro agent leverage completed successfully
2025-06-09 15:22:40,417 - INFO - Executing micro agent: efficiency
2025-06-09 15:22:40,417 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:40,418 - INFO - Micro agent efficiency completed successfully
2025-06-09 15:22:40,418 - INFO - Executing micro agent: news
2025-06-09 15:22:40,419 - INFO - Micro agent news completed successfully
2025-06-09 15:22:40,419 - INFO - Executing micro agent: historical
2025-06-09 15:22:40,419 - INFO - Micro agent historical completed successfully
2025-06-09 15:22:40,419 - INFO - Executing micro agent: guidance
2025-06-09 15:22:40,419 - INFO - Micro agent guidance completed successfully
2025-06-09 15:22:40,420 - INFO - Executing micro agent: sentiment
2025-06-09 15:22:40,420 - ERROR - VectorSearchRAGTool error: name 'get_chromadb_connection' is not defined
2025-06-09 15:22:40,700 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 15:22:40,701 - INFO - Micro agent sentiment completed successfully
2025-06-09 15:22:40,701 - INFO - Generating consolidated insights...
2025-06-09 15:22:41,969 - WARNING - Gemini API rate limit exceeded: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateCo...
2025-06-09 15:22:41,969 - INFO - Analysis orchestration completed in 11.97s
2025-06-09 15:22:41,983 - INFO - PDF report generated successfully: output\Ganesha_Ecosphere_Limited_comprehensive_report_20250609_152229.pdf
2025-06-09 15:22:41,983 - INFO - Total execution time: 11.97s
2025-06-09 15:22:41,983 - INFO - Data quality score: 94.1%
2025-06-09 15:22:41,983 - INFO - Agents used: 8 macro, 9 micro
2025-06-09 16:52:30,841 - INFO - MongoDB connection established
2025-06-09 16:52:30,919 - INFO - Redis connection established
2025-06-09 16:52:31,224 - INFO - ChromaDB connection established
2025-06-09 16:52:31,280 - INFO - MongoDB connection established
2025-06-09 16:52:31,281 - INFO - Redis connection established
2025-06-09 16:52:31,281 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 16:52:31,345 - INFO - ChromaDB connection established
2025-06-09 16:52:31,359 - INFO - Redis connection established for macro agents
2025-06-09 16:52:31,404 - INFO - MongoDB connection established for macro agents
2025-06-09 16:52:31,425 - INFO - Redis connection established for micro agents
2025-06-09 16:52:31,436 - INFO - MongoDB connection established for micro agents
2025-06-09 16:52:31,719 - INFO - Configured 10 micro agents
2025-06-09 16:52:31,957 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 16:52:32,249 - INFO - Configured 8 macro agents
2025-06-09 16:52:32,256 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 16:52:32,286 - INFO - Redis connection established for micro agents
2025-06-09 16:52:32,325 - INFO - MongoDB connection established for micro agents
2025-06-09 16:52:32,752 - INFO - Configured 10 micro agents
2025-06-09 16:52:32,757 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 16:52:32,808 - INFO - PDF Output Agent initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 16:52:32,810 - INFO - Starting comprehensive PDF report generation...
2025-06-09 16:52:32,810 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-09 16:52:32,811 - INFO - Executing macro agents analysis...
2025-06-09 16:52:32,811 - INFO - Executing macro agent: business
2025-06-09 16:53:03,132 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:03,132 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:10,845 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:10,846 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:14,756 - ERROR - ChromaDB query error: Expected where to have exactly one operator, got {'company': {'$eq': 'Ganesha Ecosphere Limited'}, 'category': 'Future Insights'} in query.
2025-06-09 16:53:14,759 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:14,992 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Extract management guidance and forward-looking statements. Identify specific numerical targets, growth rates, and strategic directions."}
2025-06-09 16:53:14,994 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:14,996 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:15,023 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Extract management guidance and forward-looking statements. Identify specific numerical targets, growth rates, and strategic directions."}
2025-06-09 16:53:15,024 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:15,343 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:15,344 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:18,708 - ERROR - ChromaDB query error: Expected where to have exactly one operator, got {'company': {'$eq': 'Ganesha Ecosphere Limited'}, 'category': 'Company Info'} in query.
2025-06-09 16:53:18,711 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:18,717 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Analyze the business model of Ganesha Ecosphere Limited. What are their core products/services, revenue streams, competitive advantages, and growth strategy? Provide a comprehensive business overview."}
2025-06-09 16:53:18,718 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:18,720 - INFO - Macro agent business completed successfully
2025-06-09 16:53:18,722 - INFO - Executing macro agent: sector
2025-06-09 16:53:19,223 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:19,227 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Analyze the overall sentiment towards this company. Is it positive, negative, or neutral? Provide specific reasons and a confidence score."}
2025-06-09 16:53:19,228 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:19,235 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:19,239 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:22,534 - INFO - Macro agent sector completed successfully
2025-06-09 16:53:22,535 - INFO - Executing macro agent: deepdive
2025-06-09 16:53:22,535 - INFO - Macro agent deepdive completed successfully
2025-06-09 16:53:22,537 - INFO - Executing macro agent: debt_wc
2025-06-09 16:53:22,948 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 16:53:23,141 - WARNING - Failed to fetch debt to equity: 0
2025-06-09 16:53:23,517 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 16:53:23,520 - WARNING - Failed to fetch total debt: 0
2025-06-09 16:53:24,000 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 16:53:24,004 - WARNING - Failed to fetch total equity: 0
2025-06-09 16:53:24,005 - INFO - Using cached financial data for Ganesha Ecosphere Limited.NS, metric: total debt
2025-06-09 16:53:24,341 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 16:53:24,898 - WARNING - yfinance .info failed for Ganesha Ecosphere Limited.NS: HTTP Error 404: 
2025-06-09 16:53:24,901 - WARNING - Leverage calculations failed: 0
2025-06-09 16:53:24,904 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:24,904 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:28,056 - ERROR - MicroAgent Error: ArithmeticCalculationTool.calculate_metrics() missing 1 required positional argument: 'data', Context: {"ticker": "Ganesha Ecosphere Limited.NS", "company_name": "Ganesha Ecosphere Limited"}
2025-06-09 16:53:28,058 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1043, in calculate_leverage_ratios
    dummy_leverage_calc = ArithmeticCalculationTool.calculate_metrics(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ArithmeticCalculationTool.calculate_metrics() missing 1 required positional argument: 'data'

2025-06-09 16:53:28,060 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:28,061 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:31,459 - INFO - Using cached financial data for Ganesha Ecosphere Limited.NS, metric: debt to equity
2025-06-09 16:53:31,460 - INFO - Macro agent debt_wc completed successfully
2025-06-09 16:53:31,460 - INFO - Executing macro agent: current_affairs
2025-06-09 16:53:31,462 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:31,465 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Analyze the overall sentiment towards this company. Is it positive, negative, or neutral? Provide specific reasons and a confidence score."}
2025-06-09 16:53:31,467 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:31,645 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:31,646 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:35,268 - INFO - Macro agent current_affairs completed successfully
2025-06-09 16:53:35,268 - INFO - Executing macro agent: predictions
2025-06-09 16:53:35,270 - ERROR - MicroAgent Error: 'AlphaSageMicroAgents' object has no attribute '_get_ticker_for_company', Context: {"agent": "ScenarioAnalysisAgent", "company_name": "Ganesha Ecosphere Limited"}
2025-06-09 16:53:35,270 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1549, in perform_scenario_analysis
    ticker = self._get_ticker_for_company(company_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMicroAgents' object has no attribute '_get_ticker_for_company'

2025-06-09 16:53:35,271 - INFO - Using cached financial data for GANECOS.NS, metric: revenue
2025-06-09 16:53:35,272 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:35,312 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Analyze the financial projections for Ganesha Ecosphere Limited. What are the key assumptions and risk factors?"}
2025-06-09 16:53:35,313 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:35,314 - INFO - Macro agent predictions completed successfully
2025-06-09 16:53:35,314 - INFO - Executing macro agent: concall
2025-06-09 16:53:35,317 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:35,322 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Analyze the overall sentiment towards this company. Is it positive, negative, or neutral? Provide specific reasons and a confidence score."}
2025-06-09 16:53:35,323 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:35,327 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:35,327 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:38,636 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:38,639 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Analyze earnings call insights for Ganesha Ecosphere Limited. What are the key management messages and investor concerns?"}
2025-06-09 16:53:38,640 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:38,641 - INFO - Macro agent concall completed successfully
2025-06-09 16:53:38,642 - INFO - Executing macro agent: risks
2025-06-09 16:53:38,645 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:38,647 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Analyze the overall sentiment towards this company. Is it positive, negative, or neutral? Provide specific reasons and a confidence score."}
2025-06-09 16:53:38,648 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:39,106 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:39,106 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:42,211 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:42,215 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Analyze investment risks for Ganesha Ecosphere Limited. What are the key risk factors and mitigation strategies?"}
2025-06-09 16:53:42,216 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:42,217 - INFO - Macro agent risks completed successfully
2025-06-09 16:53:42,218 - INFO - Executing micro agents analysis...
2025-06-09 16:53:42,218 - INFO - Executing micro agent: valuation
2025-06-09 16:53:43,491 - INFO - Using cached financial data for GANECOS.NS, metric: revenue
2025-06-09 16:53:43,612 - WARNING - Custom ratio calculations failed: 0
2025-06-09 16:53:43,614 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:43,614 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:46,562 - ERROR - ChromaDB query error: Expected where to have exactly one operator, got {'company': {'$eq': 'Ganesha Ecosphere Limited'}, 'category': 'Valuation Ratios'} in query.
2025-06-09 16:53:46,563 - INFO - Micro agent valuation completed successfully
2025-06-09 16:53:46,563 - INFO - Executing micro agent: profitability
2025-06-09 16:53:47,944 - INFO - Using cached financial data for GANECOS.NS, metric: revenue
2025-06-09 16:53:47,947 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:47,947 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:51,563 - ERROR - ChromaDB query error: Expected where to have exactly one operator, got {'company': {'$eq': 'Ganesha Ecosphere Limited'}, 'category': 'Technical Ratios'} in query.
2025-06-09 16:53:51,565 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:53:51,631 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Extract profitability insights for Ganesha Ecosphere Limited from this text"}
2025-06-09 16:53:51,633 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:53:51,923 - INFO - Micro agent profitability completed successfully
2025-06-09 16:53:51,923 - INFO - Executing micro agent: liquidity
2025-06-09 16:53:51,923 - INFO - Micro agent liquidity completed successfully
2025-06-09 16:53:51,924 - INFO - Executing micro agent: leverage
2025-06-09 16:53:52,053 - WARNING - Failed to fetch debt to equity: 0
2025-06-09 16:53:52,353 - INFO - Using cached financial data for GANECOS.NS, metric: total debt
2025-06-09 16:53:52,354 - INFO - Using cached financial data for GANECOS.NS, metric: total assets
2025-06-09 16:53:52,666 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:52,666 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:55,837 - ERROR - MicroAgent Error: ArithmeticCalculationTool.calculate_metrics() missing 1 required positional argument: 'data', Context: {"ticker": "GANECOS.NS", "company_name": "Ganesha Ecosphere Limited"}
2025-06-09 16:53:55,837 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1043, in calculate_leverage_ratios
    dummy_leverage_calc = ArithmeticCalculationTool.calculate_metrics(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ArithmeticCalculationTool.calculate_metrics() missing 1 required positional argument: 'data'

2025-06-09 16:53:55,837 - INFO - Micro agent leverage completed successfully
2025-06-09 16:53:55,837 - INFO - Executing micro agent: efficiency
2025-06-09 16:53:55,841 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:55,841 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:53:59,056 - INFO - Micro agent efficiency completed successfully
2025-06-09 16:53:59,056 - INFO - Executing micro agent: news
2025-06-09 16:53:59,057 - INFO - Micro agent news completed successfully
2025-06-09 16:53:59,057 - INFO - Executing micro agent: historical
2025-06-09 16:53:59,057 - INFO - Micro agent historical completed successfully
2025-06-09 16:53:59,057 - INFO - Executing micro agent: guidance
2025-06-09 16:53:59,059 - INFO - Micro agent guidance completed successfully
2025-06-09 16:53:59,059 - INFO - Executing micro agent: sentiment
2025-06-09 16:53:59,061 - INFO - Use pytorch device_name: cpu
2025-06-09 16:53:59,061 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 16:54:02,482 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:54:02,485 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Analyze the overall sentiment towards this company. Is it positive, negative, or neutral? Provide specific reasons and a confidence score."}
2025-06-09 16:54:02,485 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:54:02,487 - INFO - Micro agent sentiment completed successfully
2025-06-09 16:54:02,487 - INFO - Generating consolidated insights...
2025-06-09 16:54:02,488 - WARNING - Gemini API failed, falling back to Gemma: name 'prompt' is not defined
2025-06-09 16:54:02,491 - ERROR - Error: name 'prompt' is not defined, Context: {"action": "reason_on_data", "query": "Generate a comprehensive executive summary for Ganesha Ecosphere Limited based on this analysis"}
2025-06-09 16:54:02,492 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 449, in reason_on_data
    prompt,
    ^^^^^^
NameError: name 'prompt' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 462, in reason_on_data
    "messages": [{"role": "user", "content": prompt}],
                                             ^^^^^^
NameError: name 'prompt' is not defined

2025-06-09 16:54:02,492 - INFO - Analysis orchestration completed in 89.68s
2025-06-09 16:54:02,509 - INFO - PDF report generated successfully: output\Ganesha_Ecosphere_Limited_comprehensive_report_20250609_165232.pdf
2025-06-09 16:54:02,509 - INFO - Total execution time: 89.68s
2025-06-09 16:54:02,509 - INFO - Data quality score: 94.1%
2025-06-09 16:54:02,509 - INFO - Agents used: 8 macro, 9 micro
2025-06-09 17:29:56,899 - INFO - MongoDB connection established
2025-06-09 17:29:56,934 - INFO - Redis connection established
2025-06-09 17:29:57,111 - INFO - ChromaDB connection established
2025-06-09 17:30:10,058 - INFO - MongoDB connection established
2025-06-09 17:30:10,071 - INFO - Redis connection established
2025-06-09 17:30:10,155 - INFO - ChromaDB connection established
2025-06-09 17:30:10,609 - WARNING - Gemini API failed, falling back to Gemma: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-09 17:30:10,651 - ERROR - Error: Session is closed, Context: {"action": "reason_on_data", "query": "Is this company profitable?"}
2025-06-09 17:30:10,716 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 464, in reason_on_data
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jsh Agarwal\AppData\Local\Programs\Python\Python311\Lib\asyncio\threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jsh Agarwal\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 475, in reason_on_data
    async with gemma_client.post(
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\aiohttp\client.py", line 1473, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\aiohttp\client.py", line 518, in _request
    raise RuntimeError("Session is closed")
RuntimeError: Session is closed

2025-06-09 17:31:13,474 - INFO - MongoDB connection established
2025-06-09 17:31:13,487 - INFO - Redis connection established
2025-06-09 17:31:13,568 - INFO - ChromaDB connection established
2025-06-09 17:43:54,333 - INFO - MongoDB connection established
2025-06-09 17:43:54,347 - INFO - Redis connection established
2025-06-09 17:43:54,501 - INFO - ChromaDB connection established
2025-06-09 18:27:32,910 - INFO - MongoDB connection established
2025-06-09 18:27:32,921 - INFO - Redis connection established
2025-06-09 18:27:33,065 - INFO - ChromaDB connection established
2025-06-09 18:27:33,100 - INFO - MongoDB connection established
2025-06-09 18:27:33,101 - INFO - Redis connection established
2025-06-09 18:27:33,101 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 18:27:33,135 - INFO - ChromaDB connection established
2025-06-09 18:27:33,144 - INFO - Redis connection established for macro agents
2025-06-09 18:27:33,148 - INFO - MongoDB connection established for macro agents
2025-06-09 18:27:33,155 - INFO - Redis connection established for micro agents
2025-06-09 18:27:33,162 - INFO - MongoDB connection established for micro agents
2025-06-09 18:27:33,273 - INFO - Configured 10 micro agents
2025-06-09 18:27:33,346 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 18:27:33,430 - INFO - Configured 8 macro agents
2025-06-09 18:27:33,433 - INFO - AlphaSage Macro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 18:27:33,438 - INFO - Redis connection established for micro agents
2025-06-09 18:27:33,444 - INFO - MongoDB connection established for micro agents
2025-06-09 18:27:33,542 - INFO - Configured 10 micro agents
2025-06-09 18:27:33,544 - INFO - AlphaSage Micro Agents initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 18:27:33,556 - INFO - PDF Output Agent initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 18:27:33,558 - INFO - Starting comprehensive PDF report generation...
2025-06-09 18:27:33,558 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-09 18:27:33,558 - INFO - Executing macro agents analysis...
2025-06-09 18:27:33,558 - INFO - Executing macro agent: business
2025-06-09 18:27:33,561 - INFO - Macro agent business completed successfully
2025-06-09 18:27:33,561 - INFO - Executing macro agent: sector
2025-06-09 18:27:33,561 - WARNING - NewsAnalysisAgent failed: 'AlphaSageMicroAgents' object has no attribute 'analyze_news'
2025-06-09 18:27:33,561 - WARNING - SentimentAnalysisAgent failed: 'AlphaSageMicroAgents' object has no attribute 'analyze_sentiment'
2025-06-09 18:27:41,522 - INFO - Use pytorch device_name: cpu
2025-06-09 18:27:41,522 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 18:27:45,834 - INFO - Macro agent sector completed successfully
2025-06-09 18:27:45,834 - INFO - Executing macro agent: deepdive
2025-06-09 18:27:45,835 - ERROR - Macro Agent Error: 'AlphaSageMicroAgents' object has no attribute 'fetch_historical_data', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 18:27:45,835 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 733, in deep_dive_company
    self.micro_agents.fetch_historical_data,
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMicroAgents' object has no attribute 'fetch_historical_data'

2025-06-09 18:27:45,835 - INFO - Macro agent deepdive completed successfully
2025-06-09 18:27:45,835 - INFO - Executing macro agent: debt_wc
2025-06-09 18:27:45,836 - ERROR - Macro Agent Error: 'AlphaSageMicroAgents' object has no attribute 'calculate_leverage_ratios', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 18:27:45,837 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 863, in analyze_debt_wc
    self.micro_agents.calculate_leverage_ratios,
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMicroAgents' object has no attribute 'calculate_leverage_ratios'

2025-06-09 18:27:45,837 - INFO - Macro agent debt_wc completed successfully
2025-06-09 18:27:45,837 - INFO - Executing macro agent: current_affairs
2025-06-09 18:27:45,838 - WARNING - NewsAnalysisAgent failed: 'AlphaSageMicroAgents' object has no attribute 'analyze_news'
2025-06-09 18:27:45,838 - WARNING - SentimentAnalysisAgent failed: 'AlphaSageMicroAgents' object has no attribute 'analyze_sentiment'
2025-06-09 18:27:47,429 - INFO - Use pytorch device_name: cpu
2025-06-09 18:27:47,429 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-09 18:27:50,096 - INFO - Macro agent current_affairs completed successfully
2025-06-09 18:27:50,096 - INFO - Executing macro agent: predictions
2025-06-09 18:27:50,097 - INFO - Macro agent predictions completed successfully
2025-06-09 18:27:50,097 - INFO - Executing macro agent: concall
2025-06-09 18:27:50,098 - ERROR - Macro Agent Error: 'AlphaSageMicroAgents' object has no attribute 'extract_guidance', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 18:27:50,098 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 1350, in analyze_concall
    self.micro_agents.extract_guidance,
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMicroAgents' object has no attribute 'extract_guidance'

2025-06-09 18:27:50,099 - INFO - Macro agent concall completed successfully
2025-06-09 18:27:50,099 - INFO - Executing macro agent: risks
2025-06-09 18:27:50,099 - ERROR - Macro Agent Error: 'AlphaSageMicroAgents' object has no attribute 'analyze_news', Context: {"company_name": "Ganesha Ecosphere Limited"}
2025-06-09 18:27:50,100 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 1492, in analyze_risks
    self.micro_agents.analyze_news,
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AlphaSageMicroAgents' object has no attribute 'analyze_news'

2025-06-09 18:27:50,100 - INFO - Macro agent risks completed successfully
2025-06-09 18:27:50,100 - INFO - Executing micro agents analysis...
2025-06-09 18:27:50,100 - INFO - Executing micro agent: valuation
2025-06-09 18:27:50,101 - ERROR - Error in micro agent valuation: 'AlphaSageMicroAgents' object has no attribute 'calculate_valuation_ratios'
2025-06-09 18:27:50,101 - INFO - Executing micro agent: profitability
2025-06-09 18:27:50,101 - ERROR - Error in micro agent profitability: 'AlphaSageMicroAgents' object has no attribute 'calculate_profitability_ratios'
2025-06-09 18:27:50,101 - INFO - Executing micro agent: liquidity
2025-06-09 18:27:50,101 - ERROR - Error in micro agent liquidity: 'AlphaSageMicroAgents' object has no attribute 'calculate_liquidity_ratios'
2025-06-09 18:27:50,101 - INFO - Executing micro agent: leverage
2025-06-09 18:27:50,101 - ERROR - Error in micro agent leverage: 'AlphaSageMicroAgents' object has no attribute 'calculate_leverage_ratios'
2025-06-09 18:27:50,102 - INFO - Executing micro agent: efficiency
2025-06-09 18:27:50,102 - ERROR - Error in micro agent efficiency: 'AlphaSageMicroAgents' object has no attribute 'calculate_efficiency_ratios'
2025-06-09 18:27:50,102 - INFO - Executing micro agent: news
2025-06-09 18:27:50,102 - ERROR - Error in micro agent news: 'AlphaSageMicroAgents' object has no attribute 'analyze_news'
2025-06-09 18:27:50,102 - INFO - Executing micro agent: historical
2025-06-09 18:27:50,102 - ERROR - Error in micro agent historical: 'AlphaSageMicroAgents' object has no attribute 'fetch_historical_data'
2025-06-09 18:27:50,102 - INFO - Executing micro agent: guidance
2025-06-09 18:27:50,103 - ERROR - Error in micro agent guidance: 'AlphaSageMicroAgents' object has no attribute 'extract_guidance'
2025-06-09 18:27:50,103 - INFO - Executing micro agent: sentiment
2025-06-09 18:27:50,103 - ERROR - Error in micro agent sentiment: 'AlphaSageMicroAgents' object has no attribute 'analyze_sentiment'
2025-06-09 18:27:50,103 - INFO - Generating consolidated insights...
2025-06-09 18:27:50,502 - WARNING - Gemini API failed, falling back to Gemma: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-09 18:27:50,523 - ERROR - Error: Session is closed, Context: {"action": "reason_on_data", "query": "Generate a comprehensive executive summary for Ganesha Ecosphere Limited based on this analysis"}
2025-06-09 18:27:50,529 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 464, in reason_on_data
    response = await asyncio.to_thread(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jsh Agarwal\AppData\Local\Programs\Python\Python311\Lib\asyncio\threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jsh Agarwal\AppData\Local\Programs\Python\Python311\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               ^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 ^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             ^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 475, in reason_on_data
    async with gemma_client.post(
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\aiohttp\client.py", line 1473, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\aiohttp\client.py", line 518, in _request
    raise RuntimeError("Session is closed")
RuntimeError: Session is closed

2025-06-09 18:27:50,532 - INFO - Analysis orchestration completed in 16.97s
2025-06-09 18:27:50,548 - INFO - PDF report generated successfully: output\Ganesha_Ecosphere_Limited_comprehensive_report_20250609_182733.pdf
2025-06-09 18:27:50,549 - INFO - Total execution time: 16.97s
2025-06-09 18:27:50,549 - INFO - Data quality score: 47.1%
2025-06-09 18:27:50,549 - INFO - Agents used: 8 macro, 9 micro
2025-06-09 18:33:47,286 - INFO - MongoDB connection established
2025-06-09 18:33:47,298 - INFO - Redis connection established
2025-06-09 18:33:47,444 - INFO - ChromaDB connection established
2025-06-09 18:33:47,466 - INFO - MongoDB connection established
2025-06-09 18:33:47,466 - INFO - Redis connection established
2025-06-09 18:33:47,466 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 18:33:47,496 - INFO - ChromaDB connection established
2025-06-09 18:33:47,504 - INFO - Redis connection established for macro agents
2025-06-09 18:33:47,510 - INFO - MongoDB connection established for macro agents
2025-06-09 18:33:47,516 - INFO - Redis connection established for micro agents
2025-06-09 18:33:47,521 - INFO - MongoDB connection established for micro agents
2025-06-09 18:33:47,541 - ERROR - Micro agent initialization error: 'AlphaSageMicroAgents' object has no attribute 'agents'
2025-06-09 18:33:47,542 - ERROR - Macro agent initialization error: 'AlphaSageMicroAgents' object has no attribute 'agents'
2025-06-09 18:33:47,542 - ERROR - PDF Output Agent initialization error: 'AlphaSageMicroAgents' object has no attribute 'agents'
2025-06-09 18:39:12,165 - INFO - MongoDB connection established
2025-06-09 18:39:12,177 - INFO - Redis connection established
2025-06-09 18:39:12,320 - INFO - ChromaDB connection established
2025-06-09 18:39:12,345 - INFO - MongoDB connection established
2025-06-09 18:39:12,345 - INFO - Redis connection established
2025-06-09 18:39:12,346 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 18:39:12,376 - INFO - ChromaDB connection established
2025-06-09 18:39:12,385 - INFO - Redis connection established for macro agents
2025-06-09 18:39:12,391 - INFO - MongoDB connection established for macro agents
2025-06-09 18:39:12,399 - INFO - Redis connection established for micro agents
2025-06-09 18:39:12,404 - INFO - MongoDB connection established for micro agents
2025-06-09 18:39:12,484 - INFO - Micro agents configured successfully
2025-06-09 18:39:12,484 - INFO - Micro agents initialized successfully
2025-06-09 18:39:12,565 - INFO - Macro agents configured successfully
2025-06-09 18:39:12,565 - INFO - Macro agents initialized successfully
2025-06-09 18:39:12,573 - INFO - Redis connection established for micro agents
2025-06-09 18:39:12,596 - INFO - MongoDB connection established for micro agents
2025-06-09 18:39:12,664 - INFO - Micro agents configured successfully
2025-06-09 18:39:12,665 - INFO - Micro agents initialized successfully
2025-06-09 18:39:12,806 - INFO - PDF Output Agent initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 18:39:12,807 - INFO - Starting comprehensive PDF report generation...
2025-06-09 18:39:12,807 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-09 18:39:12,808 - INFO - Executing macro agents analysis...
2025-06-09 18:39:12,808 - INFO - Executing macro agent: business
2025-06-09 18:39:14,894 - WARNING - yfinance info failed for GANECOS.NS: 'dict' object is not callable
2025-06-09 18:39:14,894 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:14,896 - INFO - Macro agent business completed successfully
2025-06-09 18:39:14,896 - INFO - Executing macro agent: sector
2025-06-09 18:39:15,390 - WARNING - yfinance sector info failed for GANECOS.NS: 'dict' object is not callable
2025-06-09 18:39:15,390 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,391 - INFO - Macro agent sector completed successfully
2025-06-09 18:39:15,391 - INFO - Executing macro agent: deepdive
2025-06-09 18:39:15,397 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,397 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,402 - ERROR - ReasoningTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,403 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,405 - ERROR - ReasoningTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,406 - INFO - Macro agent deepdive completed successfully
2025-06-09 18:39:15,407 - INFO - Executing macro agent: debt_wc
2025-06-09 18:39:15,408 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,409 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,410 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,410 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,411 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,412 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,412 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,412 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,415 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,416 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,417 - INFO - Macro agent debt_wc completed successfully
2025-06-09 18:39:15,417 - INFO - Executing macro agent: current_affairs
2025-06-09 18:39:15,418 - INFO - Macro agent current_affairs completed successfully
2025-06-09 18:39:15,418 - INFO - Executing macro agent: predictions
2025-06-09 18:39:15,419 - INFO - Macro agent predictions completed successfully
2025-06-09 18:39:15,419 - INFO - Executing macro agent: concall
2025-06-09 18:39:15,420 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,422 - ERROR - ReasoningTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,423 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,423 - ERROR - ReasoningTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,424 - INFO - Macro agent concall completed successfully
2025-06-09 18:39:15,424 - INFO - Executing macro agent: risks
2025-06-09 18:39:15,754 - ERROR - ReasoningTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,895 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,897 - ERROR - ReasoningTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,899 - INFO - Macro agent risks completed successfully
2025-06-09 18:39:15,899 - INFO - Executing micro agents analysis...
2025-06-09 18:39:15,900 - INFO - Executing micro agent: valuation
2025-06-09 18:39:15,900 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,901 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,902 - INFO - Micro agent valuation completed successfully
2025-06-09 18:39:15,902 - INFO - Executing micro agent: profitability
2025-06-09 18:39:15,903 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,903 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,905 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,906 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,907 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,907 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,908 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,909 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,909 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,910 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,910 - INFO - Micro agent profitability completed successfully
2025-06-09 18:39:15,911 - INFO - Executing micro agent: liquidity
2025-06-09 18:39:15,912 - INFO - Micro agent liquidity completed successfully
2025-06-09 18:39:15,912 - INFO - Executing micro agent: leverage
2025-06-09 18:39:15,912 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,913 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,914 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,914 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,915 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,915 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,916 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:15,916 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,916 - INFO - Micro agent leverage completed successfully
2025-06-09 18:39:15,916 - INFO - Executing micro agent: efficiency
2025-06-09 18:39:15,917 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:15,918 - INFO - Micro agent efficiency completed successfully
2025-06-09 18:39:15,918 - INFO - Executing micro agent: news
2025-06-09 18:39:16,050 - INFO - Micro agent news completed successfully
2025-06-09 18:39:16,050 - INFO - Executing micro agent: historical
2025-06-09 18:39:16,052 - INFO - Micro agent historical completed successfully
2025-06-09 18:39:16,052 - INFO - Executing micro agent: guidance
2025-06-09 18:39:16,053 - INFO - Micro agent guidance completed successfully
2025-06-09 18:39:16,054 - INFO - Executing micro agent: sentiment
2025-06-09 18:39:16,055 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:39:16,055 - ERROR - ReasoningTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:16,056 - INFO - Micro agent sentiment completed successfully
2025-06-09 18:39:16,056 - INFO - Generating consolidated insights...
2025-06-09 18:39:16,057 - ERROR - ReasoningTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:39:16,058 - INFO - Analysis orchestration completed in 3.25s
2025-06-09 18:39:16,058 - ERROR - Error generating PDF report: PDFOutputAgent._create_enhanced_cover_page() missing 1 required positional argument: 'analysis_data'
2025-06-09 18:39:16,058 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\pdf_output_agent.py", line 1204, in generate_pdf_report
    elements.extend(self._create_enhanced_cover_page(doc, analysis_data))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: PDFOutputAgent._create_enhanced_cover_page() missing 1 required positional argument: 'analysis_data'

2025-06-09 18:52:03,322 - INFO - MongoDB connection established
2025-06-09 18:52:03,333 - INFO - Redis connection established
2025-06-09 18:52:03,469 - INFO - ChromaDB connection established
2025-06-09 18:52:03,483 - INFO - MongoDB connection established
2025-06-09 18:52:03,483 - INFO - Redis connection established
2025-06-09 18:52:03,484 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-09 18:52:03,518 - INFO - ChromaDB connection established
2025-06-09 18:52:03,525 - INFO - Redis connection established for macro agents
2025-06-09 18:52:03,531 - INFO - MongoDB connection established for macro agents
2025-06-09 18:52:03,539 - INFO - Redis connection established for micro agents
2025-06-09 18:52:03,563 - INFO - MongoDB connection established for micro agents
2025-06-09 18:52:03,651 - INFO - Micro agents configured successfully
2025-06-09 18:52:03,652 - INFO - Micro agents initialized successfully
2025-06-09 18:52:03,726 - INFO - Macro agents configured successfully
2025-06-09 18:52:03,726 - INFO - Macro agents initialized successfully
2025-06-09 18:52:03,732 - INFO - Redis connection established for micro agents
2025-06-09 18:52:03,737 - INFO - MongoDB connection established for micro agents
2025-06-09 18:52:03,804 - INFO - Micro agents configured successfully
2025-06-09 18:52:03,804 - INFO - Micro agents initialized successfully
2025-06-09 18:52:03,972 - INFO - PDF Output Agent initialized. System health: {'mongodb': True, 'redis': True, 'chromadb': True, 'gemini_api': True}
2025-06-09 18:52:03,973 - INFO - Starting comprehensive PDF report generation...
2025-06-09 18:52:03,973 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-09 18:52:03,973 - INFO - Executing macro agents analysis...
2025-06-09 18:52:03,973 - INFO - Executing macro agent: business
2025-06-09 18:52:04,528 - WARNING - yfinance info failed for GANECOS.NS: 'dict' object is not callable
2025-06-09 18:52:04,529 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:52:04,529 - INFO - Macro agent business completed successfully
2025-06-09 18:52:04,529 - INFO - Executing macro agent: sector
2025-06-09 18:52:04,765 - WARNING - yfinance sector info failed for GANECOS.NS: 'dict' object is not callable
2025-06-09 18:52:04,766 - ERROR - VectorSearchRAGTool error: 'Client' object has no attribute 'collection'
2025-06-09 18:52:04,766 - INFO - Macro agent sector completed successfully
2025-06-09 18:52:04,766 - INFO - Executing macro agent: deepdive
2025-06-09 18:52:04,777 - INFO - Macro agent deepdive completed successfully
2025-06-09 18:52:04,777 - INFO - Executing macro agent: debt_wc
2025-06-09 18:52:04,779 - INFO - Macro agent debt_wc completed successfully
2025-06-09 18:52:04,779 - INFO - Executing macro agent: current_affairs
2025-06-09 18:52:04,781 - INFO - Macro agent current_affairs completed successfully
2025-06-09 18:52:04,781 - INFO - Executing macro agent: predictions
2025-06-09 18:52:04,783 - INFO - Macro agent predictions completed successfully
2025-06-09 18:52:04,783 - INFO - Executing macro agent: concall
2025-06-09 18:52:04,784 - INFO - Macro agent concall completed successfully
2025-06-09 18:52:04,784 - INFO - Executing macro agent: risks
2025-06-09 18:52:04,785 - INFO - Macro agent risks completed successfully
2025-06-09 18:52:04,786 - INFO - Executing micro agents analysis...
2025-06-09 18:52:04,786 - INFO - Executing micro agent: valuation
2025-06-09 18:52:04,787 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:52:04,787 - ERROR - YFinanceNumberTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:52:04,788 - INFO - Micro agent valuation completed successfully
2025-06-09 18:52:04,788 - INFO - Executing micro agent: profitability
2025-06-09 18:52:04,789 - INFO - Micro agent profitability completed successfully
2025-06-09 18:52:04,789 - INFO - Executing micro agent: liquidity
2025-06-09 18:52:04,790 - INFO - Micro agent liquidity completed successfully
2025-06-09 18:52:04,790 - INFO - Executing micro agent: leverage
2025-06-09 18:52:04,791 - INFO - Micro agent leverage completed successfully
2025-06-09 18:52:04,791 - INFO - Executing micro agent: efficiency
2025-06-09 18:52:04,792 - INFO - Micro agent efficiency completed successfully
2025-06-09 18:52:04,792 - INFO - Executing micro agent: news
2025-06-09 18:52:05,166 - INFO - Micro agent news completed successfully
2025-06-09 18:52:05,166 - INFO - Executing micro agent: historical
2025-06-09 18:52:05,168 - INFO - Micro agent historical completed successfully
2025-06-09 18:52:05,168 - INFO - Executing micro agent: guidance
2025-06-09 18:52:05,169 - INFO - Micro agent guidance completed successfully
2025-06-09 18:52:05,169 - INFO - Executing micro agent: sentiment
2025-06-09 18:52:05,170 - INFO - Micro agent sentiment completed successfully
2025-06-09 18:52:05,170 - INFO - Generating consolidated insights...
2025-06-09 18:52:05,171 - ERROR - ReasoningTool error: object NoneType can't be used in 'await' expression
2025-06-09 18:52:05,171 - INFO - Analysis orchestration completed in 1.20s
2025-06-09 18:52:05,173 - ERROR - Error generating PDF report: PDFOutputAgent._create_enhanced_cover_page() missing 1 required positional argument: 'analysis_data'
2025-06-09 18:52:05,173 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\pdf_output_agent.py", line 1204, in generate_pdf_report
    elements.extend(self._create_enhanced_cover_page(doc, analysis_data))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: PDFOutputAgent._create_enhanced_cover_page() missing 1 required positional argument: 'analysis_data'

2025-06-10 02:34:53,850 - INFO - MongoDB connection established
2025-06-10 02:34:53,919 - INFO - Redis connection established
2025-06-10 02:34:54,377 - INFO - ChromaDB connection established
2025-06-10 02:37:55,148 - INFO - MongoDB connection established
2025-06-10 02:37:55,156 - INFO - Redis connection established
2025-06-10 02:37:55,306 - INFO - ChromaDB connection established
2025-06-10 02:40:25,011 - INFO - MongoDB connection established
2025-06-10 02:40:25,018 - INFO - Redis connection established
2025-06-10 02:40:25,151 - INFO - ChromaDB connection established
2025-06-10 02:41:14,039 - INFO - MongoDB connection established
2025-06-10 02:41:14,080 - INFO - Redis connection established
2025-06-10 02:41:14,159 - INFO - ChromaDB connection established
2025-06-10 02:41:14,229 - INFO - MongoDB connection established
2025-06-10 02:41:14,229 - INFO - Redis connection established
2025-06-10 02:41:14,230 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 02:41:14,272 - INFO - ChromaDB connection established
2025-06-10 02:41:14,279 - INFO - Redis connection established for macro agents
2025-06-10 02:41:14,304 - INFO - MongoDB connection established for macro agents
2025-06-10 02:41:14,315 - INFO - ChromaDB connection established for macro agents
2025-06-10 02:41:14,323 - INFO - Redis connection established for micro agents
2025-06-10 02:41:14,345 - INFO - MongoDB connection established for micro agents
2025-06-10 02:41:14,465 - INFO - Micro agents configured successfully
2025-06-10 02:41:14,465 - INFO - Micro agents initialized successfully
2025-06-10 02:41:14,577 - INFO - Macro agents configured successfully
2025-06-10 02:41:14,577 - INFO - Macro agents initialized successfully
2025-06-10 02:41:14,584 - INFO - Redis connection established for micro agents
2025-06-10 02:41:14,589 - INFO - MongoDB connection established for micro agents
2025-06-10 02:41:14,674 - INFO - Micro agents configured successfully
2025-06-10 02:41:14,674 - INFO - Micro agents initialized successfully
2025-06-10 02:41:14,674 - ERROR - PDF Output Agent initialization error: name 'COMPANY_NAME' is not defined
2025-06-10 02:42:36,177 - INFO - MongoDB connection established
2025-06-10 02:42:36,188 - INFO - Redis connection established
2025-06-10 02:42:36,329 - INFO - ChromaDB connection established
2025-06-10 02:42:36,345 - INFO - MongoDB connection established
2025-06-10 02:42:36,345 - INFO - Redis connection established
2025-06-10 02:42:36,347 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 02:42:36,383 - INFO - ChromaDB connection established
2025-06-10 02:42:36,389 - INFO - Redis connection established for macro agents
2025-06-10 02:42:36,412 - INFO - MongoDB connection established for macro agents
2025-06-10 02:42:36,422 - INFO - ChromaDB connection established for macro agents
2025-06-10 02:42:36,428 - INFO - Redis connection established for micro agents
2025-06-10 02:42:36,434 - INFO - MongoDB connection established for micro agents
2025-06-10 02:42:36,512 - INFO - Micro agents configured successfully
2025-06-10 02:42:36,512 - INFO - Micro agents initialized successfully
2025-06-10 02:42:36,595 - INFO - Macro agents configured successfully
2025-06-10 02:42:36,596 - INFO - Macro agents initialized successfully
2025-06-10 02:42:36,603 - INFO - Redis connection established for micro agents
2025-06-10 02:42:36,630 - INFO - MongoDB connection established for micro agents
2025-06-10 02:42:36,698 - INFO - Micro agents configured successfully
2025-06-10 02:42:36,699 - INFO - Micro agents initialized successfully
2025-06-10 02:42:36,709 - INFO - PDF Output Agent initialized. System health: <coroutine object check_system_health at 0x000001DEC4DAB760>
2025-06-10 02:42:36,720 - INFO - Starting comprehensive report generation for Ganesha Ecosphere Limited...
2025-06-10 02:42:36,721 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-10 02:42:36,721 - INFO - Executing macro agents analysis...
2025-06-10 02:42:36,721 - INFO - Executing macro agent: business
2025-06-10 02:42:36,723 - ERROR - Error in macro agent business: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:36,724 - INFO - Executing macro agent: sector
2025-06-10 02:42:36,724 - ERROR - Error in macro agent sector: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:36,725 - INFO - Executing macro agent: deepdive
2025-06-10 02:42:36,725 - ERROR - Error in macro agent deepdive: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:36,725 - INFO - Executing macro agent: debt_wc
2025-06-10 02:42:36,725 - ERROR - Error in macro agent debt_wc: 'AlphaSageMacroAgents' object has no attribute 'analyze_debt_wc'
2025-06-10 02:42:36,725 - INFO - Executing macro agent: current_affairs
2025-06-10 02:42:36,725 - ERROR - Error in macro agent current_affairs: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:36,725 - INFO - Executing macro agent: predictions
2025-06-10 02:42:36,725 - ERROR - Error in macro agent predictions: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:36,726 - INFO - Executing macro agent: concall
2025-06-10 02:42:36,726 - ERROR - Error in macro agent concall: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:36,726 - INFO - Executing macro agent: risks
2025-06-10 02:42:36,726 - ERROR - Error in macro agent risks: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:36,726 - INFO - Executing micro agents analysis...
2025-06-10 02:42:36,726 - INFO - Executing micro agent: valuation
2025-06-10 02:42:37,435 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 1: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,435 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 2: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,435 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 3: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,437 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "retry_async", "func": "_fetch_yfinance_data", "attempt": 3}
2025-06-10 02:42:37,437 - ERROR - NoneType: None

2025-06-10 02:42:37,437 - WARNING - yfinance failed for False/PE: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,437 - ERROR - MongoDB fallback failed: name 'DB_NAME' is not defined
2025-06-10 02:42:37,438 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 1: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,439 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 2: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,439 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 3: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,439 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "retry_async", "func": "_fetch_yfinance_data", "attempt": 3}
2025-06-10 02:42:37,439 - ERROR - NoneType: None

2025-06-10 02:42:37,439 - WARNING - yfinance failed for False/PB: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,439 - ERROR - MongoDB fallback failed: name 'DB_NAME' is not defined
2025-06-10 02:42:37,439 - INFO - Micro agent valuation completed successfully
2025-06-10 02:42:37,439 - INFO - Executing micro agent: profitability
2025-06-10 02:42:37,440 - ERROR - Error in micro agent profitability: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:37,440 - INFO - Executing micro agent: liquidity
2025-06-10 02:42:37,440 - ERROR - Error in micro agent liquidity: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:37,440 - INFO - Executing micro agent: leverage
2025-06-10 02:42:37,440 - ERROR - Error in micro agent leverage: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:37,440 - INFO - Executing micro agent: efficiency
2025-06-10 02:42:37,441 - ERROR - Error in micro agent efficiency: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:37,441 - INFO - Executing micro agent: news
2025-06-10 02:42:37,544 - WARNING - NoneType/TypeError in _fetch_news attempt 1: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,545 - WARNING - NoneType/TypeError in _fetch_news attempt 2: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,545 - WARNING - NoneType/TypeError in _fetch_news attempt 3: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,545 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "retry_async", "func": "_fetch_news", "attempt": 3}
2025-06-10 02:42:37,545 - ERROR - NoneType: None

2025-06-10 02:42:37,545 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "fetch_company_news", "ticker": false}
2025-06-10 02:42:37,582 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 674, in fetch_company_news
    raw_news = await retry_async(_fetch_news, max_attempts=3)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 369, in retry_async
    raise last_exception
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 333, in retry_async
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 665, in _fetch_news
    ticker_obj = yf.Ticker(ticker)
                 ^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\ticker.py", line 35, in __init__
    super(Ticker, self).__init__(ticker, session=session, proxy=proxy)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\base.py", line 52, in __init__
    self.ticker = ticker.upper()
                  ^^^^^^^^^^^^
AttributeError: 'bool' object has no attribute 'upper'

2025-06-10 02:42:37,583 - ERROR - YFinanceNewsTool error: 'bool' object has no attribute 'upper'
2025-06-10 02:42:37,583 - WARNING - No news data returned
2025-06-10 02:42:37,584 - INFO - Micro agent news completed successfully
2025-06-10 02:42:37,584 - INFO - Executing micro agent: historical
2025-06-10 02:42:37,584 - ERROR - Error in micro agent historical: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:37,584 - INFO - Executing micro agent: guidance
2025-06-10 02:42:37,584 - ERROR - Error in micro agent guidance: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:37,584 - INFO - Executing micro agent: sentiment
2025-06-10 02:42:37,585 - ERROR - Error in micro agent sentiment: 'coroutine' object has no attribute 'get'
2025-06-10 02:42:37,585 - INFO - Generating consolidated insights...
2025-06-10 02:42:37,585 - ERROR - Error consolidating analysis data: name 'COMPANY_NAME' is not defined
2025-06-10 02:42:37,585 - INFO - Analysis orchestration completed in 0.86s
2025-06-10 02:42:37,585 - ERROR - Error generating reports: "Style 'Subtitle' not found in stylesheet"
2025-06-10 02:42:37,598 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\reportlab\lib\styles.py", line 230, in __getitem__
    return self.byAlias[key]
           ~~~~~~~~~~~~^^^^^
KeyError: 'Subtitle'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\reportlab\lib\styles.py", line 233, in __getitem__
    return self.byName[key]
           ~~~~~~~~~~~^^^^^
KeyError: 'Subtitle'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\pdf_output_agent.py", line 1318, in generate_pdf_report
    elements.extend(self._create_enhanced_cover_page(analysis_data))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\pdf_output_agent.py", line 803, in _create_enhanced_cover_page
    elements.append(Paragraph("Comprehensive Business Analysis Report", self.styles["Subtitle"]))
                                                                        ~~~~~~~~~~~^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\reportlab\lib\styles.py", line 235, in __getitem__
    raise KeyError("Style '%s' not found in stylesheet" % key)
KeyError: "Style 'Subtitle' not found in stylesheet"

2025-06-10 02:47:16,826 - INFO - MongoDB connection established
2025-06-10 02:47:16,834 - INFO - Redis connection established
2025-06-10 02:47:16,985 - INFO - ChromaDB connection established
2025-06-10 02:47:17,022 - INFO - MongoDB connection established
2025-06-10 02:47:17,022 - INFO - Redis connection established
2025-06-10 02:47:17,022 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 02:47:17,053 - INFO - ChromaDB connection established
2025-06-10 02:47:17,059 - INFO - Redis connection established for macro agents
2025-06-10 02:47:17,088 - INFO - MongoDB connection established for macro agents
2025-06-10 02:47:17,097 - INFO - ChromaDB connection established for macro agents
2025-06-10 02:47:17,177 - INFO - All macro agents configured successfully
2025-06-10 02:47:17,178 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 02:47:17,179 - INFO - Macro agents initialized successfully
2025-06-10 02:47:17,182 - INFO - Redis connection established for micro agents
2025-06-10 02:47:17,211 - INFO - MongoDB connection established for micro agents
2025-06-10 02:47:17,302 - INFO - All micro agents configured successfully
2025-06-10 02:47:17,302 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 02:47:17,302 - INFO - Micro agents initialized successfully
2025-06-10 02:47:19,633 - INFO - PDF Output Agent initialized. System health: {'status': 'healthy', 'dependencies': {'mongodb': 'connected', 'redis': 'connected', 'chromadb': 'connected', 'yfinance': 'connected'}, 'timestamp': '2025-06-10T02:47:17.313549'}
2025-06-10 02:47:19,641 - INFO - Starting comprehensive report generation for Ganesha Ecosphere Limited...
2025-06-10 02:47:19,642 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-10 02:47:19,642 - INFO - Executing macro agents analysis...
2025-06-10 02:47:19,642 - INFO - Executing macro agent: business
2025-06-10 02:47:19,643 - ERROR - Error in macro agent business: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:19,645 - INFO - Executing macro agent: sector
2025-06-10 02:47:19,645 - ERROR - Error in macro agent sector: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:19,645 - INFO - Executing macro agent: deepdive
2025-06-10 02:47:19,645 - ERROR - Error in macro agent deepdive: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:19,645 - INFO - Executing macro agent: current_affairs
2025-06-10 02:47:19,645 - ERROR - Error in macro agent current_affairs: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:19,646 - INFO - Executing macro agent: predictions
2025-06-10 02:47:19,646 - ERROR - Error in macro agent predictions: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:19,646 - INFO - Executing macro agent: concall
2025-06-10 02:47:19,646 - ERROR - Error in macro agent concall: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:19,647 - INFO - Executing macro agent: risks
2025-06-10 02:47:19,647 - ERROR - Error in macro agent risks: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:19,647 - INFO - Executing micro agents analysis...
2025-06-10 02:47:19,647 - INFO - Executing micro agent: valuation
2025-06-10 02:47:20,567 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 1: 'bool' object has no attribute 'upper'
2025-06-10 02:47:20,568 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 2: 'bool' object has no attribute 'upper'
2025-06-10 02:47:20,568 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 3: 'bool' object has no attribute 'upper'
2025-06-10 02:47:20,568 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "retry_async", "func": "_fetch_yfinance_data", "attempt": 3}
2025-06-10 02:47:20,568 - ERROR - NoneType: None

2025-06-10 02:47:20,569 - WARNING - yfinance failed for False/PE: 'bool' object has no attribute 'upper'
2025-06-10 02:47:20,569 - ERROR - MongoDB fallback failed: name 'DB_NAME' is not defined
2025-06-10 02:47:20,571 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 1: 'bool' object has no attribute 'upper'
2025-06-10 02:47:20,571 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 2: 'bool' object has no attribute 'upper'
2025-06-10 02:47:20,571 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 3: 'bool' object has no attribute 'upper'
2025-06-10 02:47:20,571 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "retry_async", "func": "_fetch_yfinance_data", "attempt": 3}
2025-06-10 02:47:20,572 - ERROR - NoneType: None

2025-06-10 02:47:20,572 - WARNING - yfinance failed for False/PB: 'bool' object has no attribute 'upper'
2025-06-10 02:47:20,572 - ERROR - MongoDB fallback failed: name 'DB_NAME' is not defined
2025-06-10 02:47:20,572 - INFO - Micro agent valuation completed successfully
2025-06-10 02:47:20,572 - INFO - Executing micro agent: profitability
2025-06-10 02:47:20,573 - ERROR - Error in micro agent profitability: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:20,573 - INFO - Executing micro agent: liquidity
2025-06-10 02:47:20,573 - ERROR - Error in micro agent liquidity: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:20,573 - INFO - Executing micro agent: leverage
2025-06-10 02:47:20,574 - ERROR - Error in micro agent leverage: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:20,574 - INFO - Executing micro agent: efficiency
2025-06-10 02:47:20,574 - ERROR - Error in micro agent efficiency: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:20,574 - INFO - Executing micro agent: news
2025-06-10 02:47:21,068 - WARNING - NoneType/TypeError in _fetch_news attempt 1: 'bool' object has no attribute 'upper'
2025-06-10 02:47:21,068 - WARNING - NoneType/TypeError in _fetch_news attempt 2: 'bool' object has no attribute 'upper'
2025-06-10 02:47:21,068 - WARNING - NoneType/TypeError in _fetch_news attempt 3: 'bool' object has no attribute 'upper'
2025-06-10 02:47:21,068 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "retry_async", "func": "_fetch_news", "attempt": 3}
2025-06-10 02:47:21,068 - ERROR - NoneType: None

2025-06-10 02:47:21,068 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "fetch_company_news", "ticker": false}
2025-06-10 02:47:21,119 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 677, in fetch_company_news
    raw_news = await retry_async(_fetch_news, max_attempts=3)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 372, in retry_async
    raise last_exception
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 336, in retry_async
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 668, in _fetch_news
    ticker_obj = yf.Ticker(ticker)
                 ^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\ticker.py", line 35, in __init__
    super(Ticker, self).__init__(ticker, session=session, proxy=proxy)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\base.py", line 52, in __init__
    self.ticker = ticker.upper()
                  ^^^^^^^^^^^^
AttributeError: 'bool' object has no attribute 'upper'

2025-06-10 02:47:21,120 - ERROR - YFinanceNewsTool error: 'bool' object has no attribute 'upper'
2025-06-10 02:47:21,120 - WARNING - No news data returned
2025-06-10 02:47:21,120 - INFO - Micro agent news completed successfully
2025-06-10 02:47:21,121 - INFO - Executing micro agent: historical
2025-06-10 02:47:21,121 - ERROR - Error in micro agent historical: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:21,121 - INFO - Executing micro agent: guidance
2025-06-10 02:47:21,121 - ERROR - Error in micro agent guidance: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:21,121 - INFO - Executing micro agent: sentiment
2025-06-10 02:47:21,122 - ERROR - Error in micro agent sentiment: 'coroutine' object has no attribute 'get'
2025-06-10 02:47:21,122 - INFO - Generating consolidated insights...
2025-06-10 02:47:23,156 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:47:23,156 - WARNING - Rate limit hit for _call_gemini, waiting 4s
2025-06-10 02:47:27,521 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:47:27,521 - WARNING - Rate limit hit for _call_gemini, waiting 8s
2025-06-10 02:47:35,916 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:47:35,918 - WARNING - Rate limit hit for _call_gemini, waiting 16s
2025-06-10 02:47:51,931 - ERROR - Error: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
], Context: {"action": "retry_async", "func": "_call_gemini", "attempt": 3}
2025-06-10 02:47:51,932 - ERROR - NoneType: None

2025-06-10 02:47:51,932 - ERROR - ReasoningTool error: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:47:51,932 - INFO - Analysis orchestration completed in 32.29s
2025-06-10 02:47:51,960 - INFO - Reports generated successfully:
2025-06-10 02:47:51,960 - INFO - PDF: output\Ganesha_Ecosphere_Limited_comprehensive_report_20250610_024719.pdf
2025-06-10 02:47:51,960 - INFO - TXT: output\Ganesha_Ecosphere_Limited_comprehensive_report_20250610_024719.txt
2025-06-10 02:47:51,961 - INFO - Total execution time: 32.29s
2025-06-10 02:47:51,961 - INFO - Data quality score: 12.5%
2025-06-10 02:53:05,678 - INFO - MongoDB connection established
2025-06-10 02:53:05,687 - INFO - Redis connection established
2025-06-10 02:53:05,837 - INFO - ChromaDB connection established
2025-06-10 02:53:05,869 - INFO - MongoDB connection established
2025-06-10 02:53:05,869 - INFO - Redis connection established
2025-06-10 02:53:05,870 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 02:53:05,902 - INFO - ChromaDB connection established
2025-06-10 02:53:05,907 - INFO - Redis connection established for macro agents
2025-06-10 02:53:05,934 - INFO - MongoDB connection established for macro agents
2025-06-10 02:53:05,944 - INFO - ChromaDB connection established for macro agents
2025-06-10 02:53:06,041 - INFO - All macro agents configured successfully
2025-06-10 02:53:06,041 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 02:53:06,042 - INFO - Macro agents initialized successfully
2025-06-10 02:53:06,048 - INFO - Redis connection established for micro agents
2025-06-10 02:53:06,052 - INFO - MongoDB connection established for micro agents
2025-06-10 02:53:06,144 - INFO - All micro agents configured successfully
2025-06-10 02:53:06,144 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 02:53:06,145 - INFO - Micro agents initialized successfully
2025-06-10 02:53:06,915 - INFO - PDF Output Agent initialized. System health: {'status': 'healthy', 'dependencies': {'mongodb': 'connected', 'redis': 'connected', 'chromadb': 'connected', 'yfinance': 'connected'}, 'timestamp': '2025-06-10T02:53:06.155515'}
2025-06-10 02:53:06,917 - INFO - Starting comprehensive report generation for Ganesha Ecosphere Limited...
2025-06-10 02:53:06,918 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-10 02:53:06,918 - INFO - Executing macro agents analysis...
2025-06-10 02:53:06,918 - INFO - Executing macro agent: business
2025-06-10 02:53:06,918 - ERROR - Error in macro agent business: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:06,920 - INFO - Executing macro agent: sector
2025-06-10 02:53:06,920 - ERROR - Error in macro agent sector: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:06,920 - INFO - Executing macro agent: deepdive
2025-06-10 02:53:06,921 - ERROR - Error in macro agent deepdive: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:06,921 - INFO - Executing macro agent: current_affairs
2025-06-10 02:53:06,921 - ERROR - Error in macro agent current_affairs: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:06,921 - INFO - Executing macro agent: predictions
2025-06-10 02:53:06,921 - ERROR - Error in macro agent predictions: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:06,921 - INFO - Executing macro agent: concall
2025-06-10 02:53:06,921 - ERROR - Error in macro agent concall: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:06,921 - INFO - Executing macro agent: risks
2025-06-10 02:53:06,923 - ERROR - Error in macro agent risks: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:06,923 - INFO - Executing micro agents analysis...
2025-06-10 02:53:06,923 - INFO - Executing micro agent: valuation
2025-06-10 02:53:07,234 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 1: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,234 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 2: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,234 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 3: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,235 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "retry_async", "func": "_fetch_yfinance_data", "attempt": 3}
2025-06-10 02:53:07,235 - ERROR - NoneType: None

2025-06-10 02:53:07,235 - WARNING - yfinance failed for False/PE: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,270 - ERROR - MongoDB fallback failed: No data found in MongoDB
2025-06-10 02:53:07,272 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 1: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,272 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 2: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,272 - WARNING - NoneType/TypeError in _fetch_yfinance_data attempt 3: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,272 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "retry_async", "func": "_fetch_yfinance_data", "attempt": 3}
2025-06-10 02:53:07,272 - ERROR - NoneType: None

2025-06-10 02:53:07,272 - WARNING - yfinance failed for False/PB: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,274 - ERROR - MongoDB fallback failed: No data found in MongoDB
2025-06-10 02:53:07,274 - INFO - Micro agent valuation completed successfully
2025-06-10 02:53:07,274 - INFO - Executing micro agent: profitability
2025-06-10 02:53:07,274 - ERROR - Error in micro agent profitability: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:07,275 - INFO - Executing micro agent: liquidity
2025-06-10 02:53:07,275 - ERROR - Error in micro agent liquidity: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:07,275 - INFO - Executing micro agent: leverage
2025-06-10 02:53:07,275 - ERROR - Error in micro agent leverage: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:07,275 - INFO - Executing micro agent: efficiency
2025-06-10 02:53:07,275 - ERROR - Error in micro agent efficiency: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:07,275 - INFO - Executing micro agent: news
2025-06-10 02:53:07,394 - WARNING - NoneType/TypeError in _fetch_news attempt 1: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,394 - WARNING - NoneType/TypeError in _fetch_news attempt 2: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,394 - WARNING - NoneType/TypeError in _fetch_news attempt 3: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,394 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "retry_async", "func": "_fetch_news", "attempt": 3}
2025-06-10 02:53:07,395 - ERROR - NoneType: None

2025-06-10 02:53:07,395 - ERROR - Error: 'bool' object has no attribute 'upper', Context: {"action": "fetch_company_news", "ticker": false}
2025-06-10 02:53:07,396 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 718, in fetch_company_news
    raw_news = await retry_async(_fetch_news, max_attempts=3)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 413, in retry_async
    raise last_exception
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 377, in retry_async
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\tools.py", line 709, in _fetch_news
    ticker_obj = yf.Ticker(ticker)
                 ^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\ticker.py", line 35, in __init__
    super(Ticker, self).__init__(ticker, session=session, proxy=proxy)
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\venv\Lib\site-packages\yfinance\base.py", line 52, in __init__
    self.ticker = ticker.upper()
                  ^^^^^^^^^^^^
AttributeError: 'bool' object has no attribute 'upper'

2025-06-10 02:53:07,396 - ERROR - YFinanceNewsTool error: 'bool' object has no attribute 'upper'
2025-06-10 02:53:07,397 - WARNING - No news data returned
2025-06-10 02:53:07,397 - INFO - Micro agent news completed successfully
2025-06-10 02:53:07,397 - INFO - Executing micro agent: historical
2025-06-10 02:53:07,397 - ERROR - Error in micro agent historical: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:07,397 - INFO - Executing micro agent: guidance
2025-06-10 02:53:07,397 - ERROR - Error in micro agent guidance: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:07,397 - INFO - Executing micro agent: sentiment
2025-06-10 02:53:07,397 - ERROR - Error in micro agent sentiment: 'coroutine' object has no attribute 'get'
2025-06-10 02:53:07,398 - INFO - Generating consolidated insights...
2025-06-10 02:53:09,237 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:53:09,238 - WARNING - Rate limit hit for _call_gemini, waiting 4s
2025-06-10 02:53:13,600 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:53:13,601 - WARNING - Rate limit hit for _call_gemini, waiting 8s
2025-06-10 02:53:21,994 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:53:21,994 - WARNING - Rate limit hit for _call_gemini, waiting 16s
2025-06-10 02:53:38,001 - ERROR - Error: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
], Context: {"action": "retry_async", "func": "_call_gemini", "attempt": 3}
2025-06-10 02:53:38,001 - ERROR - NoneType: None

2025-06-10 02:53:38,001 - ERROR - ReasoningTool error: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:53:38,002 - INFO - Analysis orchestration completed in 31.08s
2025-06-10 02:53:38,010 - INFO - Reports generated successfully:
2025-06-10 02:53:38,011 - INFO - PDF: output\Ganesha_Ecosphere_Limited_comprehensive_report_20250610_025306.pdf
2025-06-10 02:53:38,011 - INFO - TXT: output\Ganesha_Ecosphere_Limited_comprehensive_report_20250610_025306.txt
2025-06-10 02:53:38,011 - INFO - Total execution time: 31.08s
2025-06-10 02:53:38,011 - INFO - Data quality score: 12.5%
2025-06-10 02:56:05,082 - INFO - MongoDB connection established
2025-06-10 02:56:05,092 - INFO - Redis connection established
2025-06-10 02:56:05,157 - INFO - ChromaDB connection established
2025-06-10 02:56:05,167 - INFO - MongoDB connection established
2025-06-10 02:56:05,167 - INFO - Redis connection established
2025-06-10 02:56:05,167 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 02:56:05,193 - INFO - ChromaDB connection established
2025-06-10 02:56:05,197 - INFO - Redis connection established for macro agents
2025-06-10 02:56:05,217 - INFO - MongoDB connection established for macro agents
2025-06-10 02:56:05,225 - INFO - ChromaDB connection established for macro agents
2025-06-10 02:56:05,306 - INFO - All macro agents configured successfully
2025-06-10 02:56:05,307 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 02:56:05,307 - INFO - Macro agents initialized successfully
2025-06-10 02:56:05,312 - INFO - Redis connection established for micro agents
2025-06-10 02:56:05,339 - INFO - MongoDB connection established for micro agents
2025-06-10 02:56:05,455 - INFO - All micro agents configured successfully
2025-06-10 02:56:05,456 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 02:56:05,456 - INFO - Micro agents initialized successfully
2025-06-10 02:56:06,113 - INFO - PDF Output Agent initialized. System health: {'status': 'healthy', 'dependencies': {'mongodb': 'connected', 'redis': 'connected', 'chromadb': 'connected', 'yfinance': 'connected'}, 'timestamp': '2025-06-10T02:56:05.468307'}
2025-06-10 02:56:06,113 - INFO - Starting comprehensive report generation for Ganesha Ecosphere Limited...
2025-06-10 02:56:06,113 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-10 02:56:06,113 - INFO - Executing macro agents analysis...
2025-06-10 02:56:06,114 - INFO - Executing macro agent: business
2025-06-10 02:56:06,114 - ERROR - Error in macro agent business: 'coroutine' object has no attribute 'get'
2025-06-10 02:56:06,116 - INFO - Executing macro agent: sector
2025-06-10 02:56:06,116 - ERROR - Error in macro agent sector: 'coroutine' object has no attribute 'get'
2025-06-10 02:56:06,116 - INFO - Executing macro agent: deepdive
2025-06-10 02:56:06,117 - ERROR - Error in macro agent deepdive: 'coroutine' object has no attribute 'get'
2025-06-10 02:56:06,117 - INFO - Executing macro agent: current_affairs
2025-06-10 02:56:06,117 - ERROR - Error in macro agent current_affairs: 'coroutine' object has no attribute 'get'
2025-06-10 02:56:06,117 - INFO - Executing macro agent: predictions
2025-06-10 02:56:06,117 - ERROR - Error in macro agent predictions: 'coroutine' object has no attribute 'get'
2025-06-10 02:56:06,117 - INFO - Executing macro agent: concall
2025-06-10 02:56:06,117 - ERROR - Error in macro agent concall: 'coroutine' object has no attribute 'get'
2025-06-10 02:56:06,117 - INFO - Executing macro agent: risks
2025-06-10 02:56:06,118 - ERROR - Error in macro agent risks: 'coroutine' object has no attribute 'get'
2025-06-10 02:56:06,118 - INFO - Executing micro agents analysis...
2025-06-10 02:56:06,118 - INFO - Executing micro agent: valuation
2025-06-10 02:56:06,118 - ERROR - Error in micro agent valuation: 'AlphaSageMicroAgents' object has no attribute 'analyze_valuation'
2025-06-10 02:56:06,118 - INFO - Executing micro agent: profitability
2025-06-10 02:56:06,118 - ERROR - Error in micro agent profitability: 'AlphaSageMicroAgents' object has no attribute 'analyze_profitability'
2025-06-10 02:56:06,118 - INFO - Executing micro agent: liquidity
2025-06-10 02:56:06,118 - ERROR - Error in micro agent liquidity: 'AlphaSageMicroAgents' object has no attribute 'analyze_liquidity'
2025-06-10 02:56:06,119 - INFO - Executing micro agent: leverage
2025-06-10 02:56:06,119 - ERROR - Error in micro agent leverage: 'AlphaSageMicroAgents' object has no attribute 'analyze_leverage'
2025-06-10 02:56:06,119 - INFO - Executing micro agent: efficiency
2025-06-10 02:56:06,119 - ERROR - Error in micro agent efficiency: 'AlphaSageMicroAgents' object has no attribute 'analyze_efficiency'
2025-06-10 02:56:06,119 - INFO - Executing micro agent: news
2025-06-10 02:56:06,461 - ERROR - Error validating ticker Ganesha Ecosphere Limited: HTTP Error 404: 
2025-06-10 02:56:06,461 - ERROR - MicroAgent Error: Invalid ticker: Ganesha Ecosphere Limited, Context: {"ticker": "Ganesha Ecosphere Limited"}
2025-06-10 02:56:06,461 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1149, in analyze_news
    raise ValueError(f"Invalid ticker: {ticker}")
ValueError: Invalid ticker: Ganesha Ecosphere Limited

2025-06-10 02:56:06,462 - INFO - Micro agent news completed successfully
2025-06-10 02:56:06,462 - INFO - Executing micro agent: historical
2025-06-10 02:56:06,462 - ERROR - Error in micro agent historical: 'AlphaSageMicroAgents' object has no attribute 'analyze_historical'
2025-06-10 02:56:06,462 - INFO - Executing micro agent: guidance
2025-06-10 02:56:06,463 - ERROR - Error in micro agent guidance: 'AlphaSageMicroAgents' object has no attribute 'analyze_guidance'
2025-06-10 02:56:06,463 - INFO - Executing micro agent: sentiment
2025-06-10 02:56:06,463 - ERROR - Error in micro agent sentiment: 'coroutine' object has no attribute 'get'
2025-06-10 02:56:06,463 - INFO - Generating consolidated insights...
2025-06-10 02:56:08,266 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:56:08,267 - WARNING - Rate limit hit for _call_gemini, waiting 4s
2025-06-10 02:56:12,705 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:56:12,706 - WARNING - Rate limit hit for _call_gemini, waiting 8s
2025-06-10 02:56:21,049 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:56:21,050 - WARNING - Rate limit hit for _call_gemini, waiting 16s
2025-06-10 02:56:37,062 - ERROR - Error: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
], Context: {"action": "retry_async", "func": "_call_gemini", "attempt": 3}
2025-06-10 02:56:37,063 - ERROR - NoneType: None

2025-06-10 02:56:37,063 - ERROR - ReasoningTool error: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 02:56:37,065 - INFO - Analysis orchestration completed in 30.95s
2025-06-10 02:56:37,075 - INFO - Reports generated successfully:
2025-06-10 02:56:37,075 - INFO - PDF: output\Ganesha_Ecosphere_Limited_comprehensive_report_20250610_025606.pdf
2025-06-10 02:56:37,075 - INFO - TXT: output\Ganesha_Ecosphere_Limited_comprehensive_report_20250610_025606.txt
2025-06-10 02:56:37,076 - INFO - Total execution time: 30.95s
2025-06-10 02:56:37,076 - INFO - Data quality score: 0.0%
2025-06-10 03:27:39,783 - INFO - Loaded 3 Gemini API keys
2025-06-10 03:27:39,788 - INFO - MongoDB connection established
2025-06-10 03:27:39,836 - INFO - Redis connection established
2025-06-10 03:27:39,838 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:27:39,838 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:27:39,838 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:27:39,838 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:27:39,996 - INFO - ChromaDB connection established
2025-06-10 03:27:40,024 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:27:40,024 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:27:40,024 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:27:40,024 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:27:40,027 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:27:40,028 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:27:40,028 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:27:40,028 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:27:40,032 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:27:40,032 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:27:40,032 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:27:40,032 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:33:22,070 - INFO - Loaded 3 Gemini API keys
2025-06-10 03:33:22,075 - INFO - MongoDB connection established
2025-06-10 03:33:22,087 - INFO - Redis connection established
2025-06-10 03:33:22,089 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:33:22,090 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:33:22,090 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:33:22,090 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:33:22,228 - INFO - ChromaDB connection established
2025-06-10 03:33:22,232 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:33:22,232 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:33:22,233 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:33:22,233 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:33:22,236 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:33:22,237 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:33:22,237 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:33:22,237 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:33:22,239 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:33:22,239 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:33:22,239 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:33:22,240 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:33:22,248 - INFO - Redis connection established
2025-06-10 03:33:22,276 - INFO - MongoDB connection established
2025-06-10 03:33:22,277 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 03:33:22,296 - INFO - ChromaDB connection established
2025-06-10 03:40:39,622 - INFO - Loaded 3 Gemini API keys
2025-06-10 03:40:39,626 - INFO - MongoDB connection established
2025-06-10 03:40:39,674 - INFO - Redis connection established
2025-06-10 03:40:39,677 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:40:39,677 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:40:39,678 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:40:39,678 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:40:39,759 - INFO - ChromaDB connection established
2025-06-10 03:40:39,762 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:40:39,762 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:40:39,762 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:40:39,763 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:40:39,765 - WARNING - python-dotenv could not parse statement starting at line 33
2025-06-10 03:40:39,765 - WARNING - python-dotenv could not parse statement starting at line 34
2025-06-10 03:40:39,766 - WARNING - python-dotenv could not parse statement starting at line 35
2025-06-10 03:40:39,766 - WARNING - python-dotenv could not parse statement starting at line 36
2025-06-10 03:40:39,769 - WARNING - python-dotenv could not parse statement starting at line 53
2025-06-10 03:40:39,769 - WARNING - python-dotenv could not parse statement starting at line 54
2025-06-10 03:40:39,769 - WARNING - python-dotenv could not parse statement starting at line 55
2025-06-10 03:40:39,769 - WARNING - python-dotenv could not parse statement starting at line 56
2025-06-10 03:40:39,777 - INFO - Redis connection established
2025-06-10 03:40:39,784 - INFO - MongoDB connection established
2025-06-10 03:40:39,784 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 03:40:39,803 - INFO - ChromaDB connection established
2025-06-10 03:52:10,431 - INFO - Loaded 3 Gemini API keys
2025-06-10 03:52:10,436 - INFO - MongoDB connection established
2025-06-10 03:52:10,453 - INFO - Redis connection established
2025-06-10 03:52:10,602 - INFO - ChromaDB connection established
2025-06-10 03:52:10,625 - INFO - MongoDB connection established
2025-06-10 03:52:10,625 - INFO - Redis connection established
2025-06-10 03:52:10,625 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 03:52:10,657 - INFO - ChromaDB connection established
2025-06-10 03:52:10,663 - INFO - Redis connection established for macro agents
2025-06-10 03:52:10,669 - INFO - MongoDB connection established for macro agents
2025-06-10 03:52:10,677 - INFO - ChromaDB connection established for macro agents
2025-06-10 03:52:10,762 - INFO - All macro agents configured successfully
2025-06-10 03:52:10,763 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 03:52:10,763 - INFO - Macro agents initialized successfully
2025-06-10 03:52:10,771 - INFO - Redis connection established for micro agents
2025-06-10 03:52:10,790 - INFO - MongoDB connection established for micro agents
2025-06-10 03:52:10,878 - INFO - All micro agents configured successfully
2025-06-10 03:52:10,879 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 03:52:10,879 - INFO - Micro agents initialized successfully
2025-06-10 03:52:12,554 - INFO - PDF Output Agent initialized. System health: {'status': 'healthy', 'dependencies': {'mongodb': 'connected', 'redis': 'connected', 'chromadb': 'connected', 'yfinance': 'connected'}, 'timestamp': '2025-06-10T03:52:10.891476'}
2025-06-10 03:52:12,555 - INFO - Starting comprehensive report generation for Ganesha Ecosphere Limited...
2025-06-10 03:52:12,555 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-10 03:52:12,555 - INFO - Executing macro agents analysis...
2025-06-10 03:52:12,556 - INFO - Executing macro agent: business
2025-06-10 03:52:12,567 - ERROR - Error in macro agent business: 'coroutine' object has no attribute 'get'
2025-06-10 03:52:12,569 - INFO - Executing macro agent: sector
2025-06-10 03:52:12,569 - ERROR - Error in macro agent sector: 'coroutine' object has no attribute 'get'
2025-06-10 03:52:12,571 - INFO - Executing macro agent: deepdive
2025-06-10 03:52:12,571 - ERROR - Error in macro agent deepdive: 'coroutine' object has no attribute 'get'
2025-06-10 03:52:12,571 - INFO - Executing macro agent: current_affairs
2025-06-10 03:52:12,571 - ERROR - Error in macro agent current_affairs: 'coroutine' object has no attribute 'get'
2025-06-10 03:52:12,571 - INFO - Executing macro agent: predictions
2025-06-10 03:52:12,571 - ERROR - Error in macro agent predictions: 'coroutine' object has no attribute 'get'
2025-06-10 03:52:12,571 - INFO - Executing macro agent: concall
2025-06-10 03:52:12,572 - ERROR - Error in macro agent concall: 'coroutine' object has no attribute 'get'
2025-06-10 03:52:12,572 - INFO - Executing macro agent: risks
2025-06-10 03:52:12,572 - ERROR - Error in macro agent risks: 'coroutine' object has no attribute 'get'
2025-06-10 03:52:12,572 - INFO - Executing micro agents analysis...
2025-06-10 03:52:12,572 - INFO - Executing micro agent: valuation
2025-06-10 03:52:12,572 - ERROR - Error in micro agent valuation: 'AlphaSageMicroAgents' object has no attribute 'analyze_valuation'
2025-06-10 03:52:12,573 - INFO - Executing micro agent: profitability
2025-06-10 03:52:12,573 - ERROR - Error in micro agent profitability: 'AlphaSageMicroAgents' object has no attribute 'analyze_profitability'
2025-06-10 03:52:12,573 - INFO - Executing micro agent: liquidity
2025-06-10 03:52:12,573 - ERROR - Error in micro agent liquidity: 'AlphaSageMicroAgents' object has no attribute 'analyze_liquidity'
2025-06-10 03:52:12,573 - INFO - Executing micro agent: leverage
2025-06-10 03:52:12,573 - ERROR - Error in micro agent leverage: 'AlphaSageMicroAgents' object has no attribute 'analyze_leverage'
2025-06-10 03:52:12,575 - INFO - Executing micro agent: efficiency
2025-06-10 03:52:12,575 - ERROR - Error in micro agent efficiency: 'AlphaSageMicroAgents' object has no attribute 'analyze_efficiency'
2025-06-10 03:52:12,575 - INFO - Executing micro agent: news
2025-06-10 03:52:12,879 - ERROR - Error validating ticker Ganesha Ecosphere Limited: HTTP Error 404: 
2025-06-10 03:52:12,879 - ERROR - MicroAgent Error: Invalid ticker: Ganesha Ecosphere Limited, Context: {"ticker": "Ganesha Ecosphere Limited"}
2025-06-10 03:52:12,881 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\microagent.py", line 1155, in analyze_news
    raise ValueError(f"Invalid ticker: {ticker}")
ValueError: Invalid ticker: Ganesha Ecosphere Limited

2025-06-10 03:52:12,881 - INFO - Micro agent news completed successfully
2025-06-10 03:52:12,882 - INFO - Executing micro agent: historical
2025-06-10 03:52:12,882 - ERROR - Error in micro agent historical: 'AlphaSageMicroAgents' object has no attribute 'analyze_historical'
2025-06-10 03:52:12,882 - INFO - Executing micro agent: guidance
2025-06-10 03:52:12,882 - ERROR - Error in micro agent guidance: 'AlphaSageMicroAgents' object has no attribute 'analyze_guidance'
2025-06-10 03:52:12,882 - INFO - Executing micro agent: sentiment
2025-06-10 03:52:12,882 - ERROR - Error in micro agent sentiment: 'coroutine' object has no attribute 'get'
2025-06-10 03:52:12,883 - INFO - Generating consolidated insights...
2025-06-10 03:52:15,292 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 03:52:15,293 - WARNING - Rate limit hit for _call_gemini, waiting 4s
2025-06-10 03:52:19,756 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 03:52:19,757 - WARNING - Rate limit hit for _call_gemini, waiting 8s
2025-06-10 03:52:28,152 - ERROR - Gemini API call failed: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 03:52:28,154 - WARNING - Rate limit hit for _call_gemini, waiting 16s
2025-06-10 03:52:44,161 - ERROR - Error: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
], Context: {"action": "retry_async", "func": "_call_gemini", "attempt": 3}
2025-06-10 03:52:44,162 - ERROR - NoneType: None

2025-06-10 03:52:44,162 - ERROR - ReasoningTool error: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:4036925562'. [reason: "RATE_LIMIT_EXCEEDED"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
metadata {
  key: "quota_unit"
  value: "1/min/{project}/{region}"
}
metadata {
  key: "quota_metric"
  value: "generativelanguage.googleapis.com/generate_content_requests"
}
metadata {
  key: "quota_location"
  value: "us-south1"
}
metadata {
  key: "quota_limit"
  value: "GenerateContentRequestsPerMinutePerProjectPerRegion"
}
metadata {
  key: "quota_limit_value"
  value: "0"
}
metadata {
  key: "consumer"
  value: "projects/4036925562"
}
, links {
  description: "Request a higher quota limit."
  url: "https://cloud.google.com/docs/quotas/help/request_increase"
}
]
2025-06-10 03:52:44,163 - INFO - Analysis orchestration completed in 31.61s
2025-06-10 03:52:44,163 - ERROR - Missing required section: executive_summary
2025-06-10 03:52:44,163 - ERROR - Error generating report: Analysis data validation failed
2025-06-10 03:57:44,671 - INFO - Loaded 3 Gemini API keys
2025-06-10 03:57:44,678 - INFO - MongoDB connection established
2025-06-10 03:57:44,689 - INFO - Redis connection established
2025-06-10 03:57:44,880 - INFO - ChromaDB connection established
2025-06-10 03:57:44,928 - INFO - MongoDB connection established
2025-06-10 03:57:44,929 - INFO - Redis connection established
2025-06-10 03:57:44,929 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 03:57:44,964 - INFO - ChromaDB connection established
2025-06-10 03:57:44,972 - INFO - Redis connection established for macro agents
2025-06-10 03:57:44,978 - INFO - MongoDB connection established for macro agents
2025-06-10 03:57:44,986 - INFO - ChromaDB connection established for macro agents
2025-06-10 03:57:45,072 - INFO - All macro agents configured successfully
2025-06-10 03:57:45,073 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 03:57:45,073 - INFO - Macro agents initialized successfully
2025-06-10 03:57:45,080 - INFO - Redis connection established for micro agents
2025-06-10 03:57:45,087 - INFO - MongoDB connection established for micro agents
2025-06-10 03:57:45,185 - INFO - All micro agents configured successfully
2025-06-10 03:57:45,186 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 03:57:45,186 - INFO - Micro agents initialized successfully
2025-06-10 03:57:45,940 - INFO - PDF Output Agent initialized. System health: {'status': 'healthy', 'dependencies': {'mongodb': 'connected', 'redis': 'connected', 'chromadb': 'connected', 'yfinance': 'connected'}, 'timestamp': '2025-06-10T03:57:45.198111'}
2025-06-10 03:57:45,941 - INFO - Starting comprehensive report generation for Ganesha Ecosphere Limited...
2025-06-10 03:57:45,941 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-10 03:57:45,941 - INFO - Executing macro agents analysis...
2025-06-10 03:57:45,941 - INFO - Executing macro agent: business
2025-06-10 03:57:45,941 - INFO - Executing macro agent: sector
2025-06-10 03:57:45,942 - INFO - Executing macro agent: deepdive
2025-06-10 03:57:45,942 - INFO - Executing macro agent: current_affairs
2025-06-10 03:57:45,942 - INFO - Executing macro agent: predictions
2025-06-10 03:57:45,942 - INFO - Executing macro agent: concall
2025-06-10 03:57:45,942 - INFO - Executing macro agent: risks
2025-06-10 03:57:45,943 - ERROR - Error awaiting macro agent business: generate_cache_key() takes 1 positional argument but 2 were given
2025-06-10 03:57:45,943 - ERROR - Error in analysis orchestration: AgentResult.__init__() got an unexpected keyword argument 'metadata'
2025-06-10 03:57:45,953 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\pdf_output_agent.py", line 660, in _run_macro_agents
    result = await task
             ^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 100, in execute
    self.cache_key = self._generate_cache_key(company_name, **kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 162, in _generate_cache_key
    return generate_cache_key(self.name, company_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: generate_cache_key() takes 1 positional argument but 2 were given

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\pdf_output_agent.py", line 606, in _orchestrate_comprehensive_analysis
    macro_results = await self._run_macro_agents(company_name)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\pdf_output_agent.py", line 664, in _run_macro_agents
    macro_results[agent_name] = AgentResult(
                                ^^^^^^^^^^^^
TypeError: AgentResult.__init__() got an unexpected keyword argument 'metadata'

2025-06-10 03:57:45,954 - ERROR - Error generating report: AgentResult.__init__() got an unexpected keyword argument 'metadata'
2025-06-10 03:57:47,233 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-8' coro=<MacroAgent.execute() done, defined at D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py:97> exception=TypeError('generate_cache_key() takes 1 positional argument but 2 were given')>
Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 100, in execute
    self.cache_key = self._generate_cache_key(company_name, **kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 162, in _generate_cache_key
    return generate_cache_key(self.name, company_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: generate_cache_key() takes 1 positional argument but 2 were given
2025-06-10 03:57:47,234 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-7' coro=<MacroAgent.execute() done, defined at D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py:97> exception=TypeError('generate_cache_key() takes 1 positional argument but 2 were given')>
Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 100, in execute
    self.cache_key = self._generate_cache_key(company_name, **kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 162, in _generate_cache_key
    return generate_cache_key(self.name, company_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: generate_cache_key() takes 1 positional argument but 2 were given
2025-06-10 03:57:47,235 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-6' coro=<MacroAgent.execute() done, defined at D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py:97> exception=TypeError('generate_cache_key() takes 1 positional argument but 2 were given')>
Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 100, in execute
    self.cache_key = self._generate_cache_key(company_name, **kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 162, in _generate_cache_key
    return generate_cache_key(self.name, company_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: generate_cache_key() takes 1 positional argument but 2 were given
2025-06-10 03:57:47,235 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-5' coro=<MacroAgent.execute() done, defined at D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py:97> exception=TypeError('generate_cache_key() takes 1 positional argument but 2 were given')>
Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 100, in execute
    self.cache_key = self._generate_cache_key(company_name, **kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 162, in _generate_cache_key
    return generate_cache_key(self.name, company_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: generate_cache_key() takes 1 positional argument but 2 were given
2025-06-10 03:57:47,236 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-4' coro=<MacroAgent.execute() done, defined at D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py:97> exception=TypeError('generate_cache_key() takes 1 positional argument but 2 were given')>
Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 100, in execute
    self.cache_key = self._generate_cache_key(company_name, **kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 162, in _generate_cache_key
    return generate_cache_key(self.name, company_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: generate_cache_key() takes 1 positional argument but 2 were given
2025-06-10 03:57:47,236 - ERROR - Task exception was never retrieved
future: <Task finished name='Task-3' coro=<MacroAgent.execute() done, defined at D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py:97> exception=TypeError('generate_cache_key() takes 1 positional argument but 2 were given')>
Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 100, in execute
    self.cache_key = self._generate_cache_key(company_name, **kwargs)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\macroagent.py", line 162, in _generate_cache_key
    return generate_cache_key(self.name, company_name, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: generate_cache_key() takes 1 positional argument but 2 were given
2025-06-10 04:02:39,775 - INFO - Loaded 3 Gemini API keys
2025-06-10 04:02:39,780 - INFO - MongoDB connection established
2025-06-10 04:02:39,787 - INFO - Redis connection established
2025-06-10 04:02:39,938 - INFO - ChromaDB connection established
2025-06-10 04:02:39,973 - INFO - MongoDB connection established
2025-06-10 04:02:39,973 - INFO - Redis connection established
2025-06-10 04:02:39,973 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 04:02:40,007 - INFO - ChromaDB connection established
2025-06-10 04:02:40,014 - INFO - Redis connection established for macro agents
2025-06-10 04:02:40,020 - INFO - MongoDB connection established for macro agents
2025-06-10 04:02:40,029 - INFO - ChromaDB connection established for macro agents
2025-06-10 04:02:40,029 - INFO - All macro agents configured successfully
2025-06-10 04:02:40,030 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 04:02:40,030 - INFO - Macro agents initialized successfully
2025-06-10 04:02:40,035 - INFO - Redis connection established for micro agents
2025-06-10 04:02:40,056 - INFO - MongoDB connection established for micro agents
2025-06-10 04:02:40,175 - INFO - All micro agents configured successfully
2025-06-10 04:02:40,176 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 04:02:40,176 - INFO - Micro agents initialized successfully
2025-06-10 04:02:42,561 - INFO - PDF Output Agent initialized. System health: {'status': 'healthy', 'dependencies': {'mongodb': 'connected', 'redis': 'connected', 'chromadb': 'connected', 'yfinance': 'connected'}, 'timestamp': '2025-06-10T04:02:40.187116'}
2025-06-10 04:02:42,561 - INFO - Starting comprehensive report generation for Ganesha Ecosphere Limited...
2025-06-10 04:02:42,561 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-10 04:02:42,562 - INFO - Executing macro agents analysis...
2025-06-10 04:02:42,562 - INFO - Executing macro agent: business
2025-06-10 04:02:42,562 - INFO - Executing macro agent: sector
2025-06-10 04:02:42,562 - INFO - Executing macro agent: deepdive
2025-06-10 04:02:42,562 - INFO - Executing macro agent: current_affairs
2025-06-10 04:02:42,563 - INFO - Executing macro agent: predictions
2025-06-10 04:02:42,563 - INFO - Executing macro agent: concall
2025-06-10 04:02:42,563 - INFO - Executing macro agent: risks
2025-06-10 04:02:42,565 - ERROR - Error in macro agent BusinessAnalysisAgent: 'MacroAgent' object has no attribute '_perform_analysis'
2025-06-10 04:02:42,566 - ERROR - Error in macro agent SectorAnalysisAgent: 'MacroAgent' object has no attribute '_perform_analysis'
2025-06-10 04:02:42,568 - ERROR - Error in macro agent DeepDiveAgent: 'MacroAgent' object has no attribute '_perform_analysis'
2025-06-10 04:02:42,569 - ERROR - Error in macro agent CurrentAffairsAgent: 'MacroAgent' object has no attribute '_perform_analysis'
2025-06-10 04:02:42,570 - ERROR - Error in macro agent PredictionsAgent: 'MacroAgent' object has no attribute '_perform_analysis'
2025-06-10 04:02:42,571 - ERROR - Error in macro agent ConcallAnalysisAgent: 'MacroAgent' object has no attribute '_perform_analysis'
2025-06-10 04:02:42,574 - ERROR - Error in macro agent RiskAnalysisAgent: 'MacroAgent' object has no attribute '_perform_analysis'
2025-06-10 04:02:42,574 - INFO - Executing micro agents analysis...
2025-06-10 04:02:42,574 - INFO - Executing micro agent: valuation
2025-06-10 04:02:42,574 - INFO - Executing micro agent: profitability
2025-06-10 04:02:42,574 - INFO - Executing micro agent: liquidity
2025-06-10 04:02:42,575 - INFO - Executing micro agent: efficiency
2025-06-10 04:02:42,575 - INFO - Executing micro agent: leverage
2025-06-10 04:02:42,575 - INFO - Executing micro agent: news
2025-06-10 04:02:42,575 - INFO - Executing micro agent: historical
2025-06-10 04:02:42,575 - INFO - Executing micro agent: guidance
2025-06-10 04:02:42,576 - INFO - Executing micro agent: sentiment
2025-06-10 04:02:42,577 - ERROR - Error in ValuationRatiosAgent execution: Subclasses must implement _analyze method
2025-06-10 04:02:42,578 - ERROR - Error in ProfitabilityRatiosAgent execution: Subclasses must implement _analyze method
2025-06-10 04:02:42,578 - ERROR - Error in LiquidityRatiosAgent execution: Subclasses must implement _analyze method
2025-06-10 04:02:42,579 - ERROR - Error in EfficiencyRatiosAgent execution: Subclasses must implement _analyze method
2025-06-10 04:02:42,581 - ERROR - Error in LeverageRatiosAgent execution: Subclasses must implement _analyze method
2025-06-10 04:02:42,582 - ERROR - Error in NewsAnalysisAgent execution: Subclasses must implement _analyze method
2025-06-10 04:02:42,583 - ERROR - Error in HistoricalDataAgent execution: Subclasses must implement _analyze method
2025-06-10 04:02:42,584 - ERROR - Error in GuidanceExtractionAgent execution: Subclasses must implement _analyze method
2025-06-10 04:02:42,584 - ERROR - Error in SentimentAnalysisAgent execution: Subclasses must implement _analyze method
2025-06-10 04:02:42,586 - INFO - Generating consolidated insights...
2025-06-10 04:02:42,586 - ERROR - Error consolidating analysis data: 'AgentResult' object has no attribute 'get'
2025-06-10 04:02:42,586 - ERROR - Error in analysis orchestration: 'AgentResult' object has no attribute 'get'
2025-06-10 04:02:42,587 - ERROR - Traceback (most recent call last):
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\pdf_output_agent.py", line 624, in _orchestrate_comprehensive_analysis
    "successful_macro_agents": sum(1 for r in macro_results.values() if r.get("success", False)),
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Mistral-OCR-and-Synthetic-data-Generation\pdf_output_agent.py", line 624, in <genexpr>
    "successful_macro_agents": sum(1 for r in macro_results.values() if r.get("success", False)),
                                                                        ^^^^^
AttributeError: 'AgentResult' object has no attribute 'get'

2025-06-10 04:02:42,587 - ERROR - Error generating report: 'AgentResult' object has no attribute 'get'
2025-06-10 04:08:58,237 - INFO - Loaded 3 Gemini API keys
2025-06-10 04:08:58,243 - INFO - MongoDB connection established
2025-06-10 04:08:58,252 - INFO - Redis connection established
2025-06-10 04:08:58,401 - INFO - ChromaDB connection established
2025-06-10 04:08:58,438 - INFO - MongoDB connection established
2025-06-10 04:08:58,439 - INFO - Redis connection established
2025-06-10 04:08:58,439 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-10 04:08:58,469 - INFO - ChromaDB connection established
2025-06-10 04:08:58,475 - INFO - Redis connection established for macro agents
2025-06-10 04:08:58,483 - INFO - MongoDB connection established for macro agents
2025-06-10 04:08:58,491 - INFO - ChromaDB connection established for macro agents
2025-06-10 04:08:58,492 - ERROR - Error configuring macro agents: name 'autogen' is not defined
2025-06-10 04:08:58,492 - ERROR - Error initializing macro agents: name 'autogen' is not defined
2025-06-10 04:08:58,492 - ERROR - Failed to create macro agents: name 'autogen' is not defined
2025-06-10 04:08:58,492 - WARNING - Failed to initialize macro agents, some functionality may be limited
2025-06-10 04:08:58,498 - INFO - Redis connection established for micro agents
2025-06-10 04:08:58,506 - INFO - MongoDB connection established for micro agents
2025-06-10 04:08:58,611 - INFO - All micro agents configured successfully
2025-06-10 04:08:58,613 - INFO - Connected to existing ChromaDB collection: alphasage_chunks
2025-06-10 04:08:58,613 - INFO - Micro agents initialized successfully
2025-06-10 04:08:59,415 - INFO - PDF Output Agent initialized. System health: {'status': 'healthy', 'dependencies': {'mongodb': 'connected', 'redis': 'connected', 'chromadb': 'connected', 'yfinance': 'connected'}, 'timestamp': '2025-06-10T04:08:58.624138'}
2025-06-10 04:08:59,416 - INFO - Starting comprehensive report generation for Ganesha Ecosphere Limited...
2025-06-10 04:08:59,416 - INFO - Starting comprehensive analysis orchestration for Ganesha Ecosphere Limited
2025-06-10 04:08:59,416 - INFO - Executing macro agents analysis...
2025-06-10 04:08:59,417 - ERROR - Error in analysis orchestration: 'NoneType' object has no attribute 'agents'
2025-06-10 04:08:59,417 - ERROR - Error generating report: 'NoneType' object has no attribute 'agents'
2025-06-10 04:32:40,321 - INFO - Loaded 3 Gemini API keys
2025-06-10 04:32:40,327 - INFO - MongoDB connection established
2025-06-10 04:32:40,348 - INFO - Redis connection established
2025-06-10 04:32:40,531 - INFO - ChromaDB connection established
2025-06-10 04:35:10,745 - INFO - Loaded 3 Gemini API keys
2025-06-10 04:35:10,750 - INFO - MongoDB connection established
2025-06-10 04:35:10,759 - INFO - Redis connection established
2025-06-10 04:35:10,836 - INFO - ChromaDB connection established
2025-06-10 06:31:37,029 - alphasage.gemini - DEBUG - Loaded 3 Gemini API keys
2025-06-10 06:31:37,029 - alphasage.tools - DEBUG - Attempting MongoDB connection (attempt 1/3)
2025-06-10 06:31:37,032 - pymongo.topology - DEBUG - {"message": "Starting topology monitoring", "topologyId": {"$oid": "684783f1e7f472bb91c847b4"}}
2025-06-10 06:31:37,033 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "684783f1e7f472bb91c847b4"}, "previousDescription": "<TopologyDescription id: 684783f1e7f472bb91c847b4, topology_type: Unknown, servers: []>", "newDescription": "<TopologyDescription id: 684783f1e7f472bb91c847b4, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>"}
2025-06-10 06:31:37,033 - pymongo.topology - DEBUG - {"message": "Starting server monitoring", "topologyId": {"$oid": "684783f1e7f472bb91c847b4"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 06:31:37,034 - pymongo.connection - DEBUG - {"message": "Connection pool created", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "serverHost": "localhost", "serverPort": 27017, "maxPoolSize": 10}
2025-06-10 06:31:37,036 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "ping", "topologyDescription": "<TopologyDescription id: 684783f1e7f472bb91c847b4, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}}
2025-06-10 06:31:37,037 - pymongo.serverSelection - DEBUG - {"message": "Waiting for suitable server to become available", "selector": "Primary()", "operation": "ping", "topologyDescription": "<TopologyDescription id: 684783f1e7f472bb91c847b4, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "remainingTimeMS": 30000}
2025-06-10 06:31:37,039 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "684783f1e7f472bb91c847b4"}, "driverConnectionId": 1, "serverHost": "localhost", "serverPort": 27017, "awaited": false}
2025-06-10 06:31:37,043 - pymongo.topology - DEBUG - {"message": "Server heartbeat succeeded", "topologyId": {"$oid": "684783f1e7f472bb91c847b4"}, "driverConnectionId": 1, "serverConnectionId": 225, "serverHost": "localhost", "serverPort": 27017, "awaited": false, "durationMS": 0.0, "reply": "{\"helloOk\": true, \"ismaster\": true, \"topologyVersion\": {\"processId\": {\"$oid\": \"684749947f4860064c1c4649\"}}, \"maxBsonObjectSize\": 16777216, \"maxMessageSizeBytes\": 48000000, \"maxWriteBatchSize\": 100000, \"localTime\": {\"$date\": \"2025-06-10T01:01:37.043Z\"}, \"logicalSessionTimeoutMinutes\": 30, \"connectionId\": 225, \"maxWireVersion\": 21, \"ok\": 1.0}"}
2025-06-10 06:31:37,043 - pymongo.connection - DEBUG - {"message": "Connection pool ready", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 06:31:37,044 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "684783f1e7f472bb91c847b4"}, "previousDescription": "<TopologyDescription id: 684783f1e7f472bb91c847b4, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "newDescription": "<TopologyDescription id: 684783f1e7f472bb91c847b4, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>"}
2025-06-10 06:31:37,044 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "ping", "topologyDescription": "<TopologyDescription id: 684783f1e7f472bb91c847b4, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 06:31:37,044 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "684783f1e7f472bb91c847b4"}, "driverConnectionId": 1, "serverConnectionId": 225, "serverHost": "localhost", "serverPort": 27017, "awaited": true}
2025-06-10 06:31:37,045 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 06:31:37,045 - pymongo.connection - DEBUG - {"message": "Connection created", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 06:31:37,047 - pymongo.connection - DEBUG - {"message": "Connection ready", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 06:31:37,047 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 06:31:37,048 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "command": "{\"ping\": 1, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"ECe9bEQPSQKZZ3g5p4z0pw==\", \"subType\": \"04\"}}}, \"$db\": \"admin\"}", "commandName": "ping", "databaseName": "admin", "requestId": 14448, "operationId": 14448, "driverConnectionId": 1, "serverConnectionId": 227, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 06:31:37,048 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "durationMS": 0.0, "reply": "{\"ok\": 1.0}", "commandName": "ping", "databaseName": "admin", "requestId": 14448, "operationId": 14448, "driverConnectionId": 1, "serverConnectionId": 227, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 06:31:37,049 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "684783f1e7f472bb91c847b4"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 06:31:37,049 - alphasage.tools - INFO - MongoDB connection established successfully
2025-06-10 06:31:37,049 - alphasage.tools - INFO - MongoDB collections initialized
2025-06-10 06:31:37,088 - alphasage.tools - INFO - Redis connection established
2025-06-10 06:31:37,154 - chromadb.config - DEBUG - Starting component System
2025-06-10 06:31:37,155 - chromadb.config - DEBUG - Starting component Posthog
2025-06-10 06:31:37,244 - alphasage.tools - INFO - ChromaDB connection established
2025-06-10 06:31:38,063 - pymongo.topology - DEBUG - {"message": "Server heartbeat failed", "topologyId": {"$oid": "684783f1e7f472bb91c847b4"}, "serverHost": "localhost", "serverPort": 27017, "awaited": true, "durationMS": 1014.9999999994179, "failure": "\"_OperationCancelled('operation cancelled')\"", "driverConnectionId": 1}
2025-06-10 07:34:47,105 - asyncio - DEBUG - Using proactor: IocpProactor
2025-06-10 07:34:47,165 - pymongo.topology - DEBUG - {"message": "Starting topology monitoring", "topologyId": {"$oid": "684792bf7b4935d9033ef466"}}
2025-06-10 07:34:47,165 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "684792bf7b4935d9033ef466"}, "previousDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Unknown, servers: []>", "newDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>"}
2025-06-10 07:34:47,165 - pymongo.topology - DEBUG - {"message": "Starting server monitoring", "topologyId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:47,166 - pymongo.connection - DEBUG - {"message": "Connection pool created", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:47,168 - __main__ - INFO - Checking MongoDB for existing dashboard for Hitachi Energy India Ltd. (POWERINDIA.NS)
2025-06-10 07:34:47,168 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "clientId": {"$oid": "684792bf7b4935d9033ef466"}}
2025-06-10 07:34:47,168 - pymongo.serverSelection - DEBUG - {"message": "Waiting for suitable server to become available", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "remainingTimeMS": 30000}
2025-06-10 07:34:47,170 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "684792bf7b4935d9033ef466"}, "driverConnectionId": 1, "serverHost": "localhost", "serverPort": 27017, "awaited": false}
2025-06-10 07:34:47,186 - pymongo.topology - DEBUG - {"message": "Server heartbeat succeeded", "topologyId": {"$oid": "684792bf7b4935d9033ef466"}, "driverConnectionId": 1, "serverConnectionId": 228, "serverHost": "localhost", "serverPort": 27017, "awaited": false, "durationMS": 14.999999999417923, "reply": "{\"helloOk\": true, \"ismaster\": true, \"topologyVersion\": {\"processId\": {\"$oid\": \"684749947f4860064c1c4649\"}}, \"maxBsonObjectSize\": 16777216, \"maxMessageSizeBytes\": 48000000, \"maxWriteBatchSize\": 100000, \"localTime\": {\"$date\": \"2025-06-10T02:04:47.186Z\"}, \"logicalSessionTimeoutMinutes\": 30, \"connectionId\": 228, \"maxWireVersion\": 21, \"ok\": 1.0}"}
2025-06-10 07:34:47,186 - pymongo.connection - DEBUG - {"message": "Connection pool ready", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:47,186 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "684792bf7b4935d9033ef466"}, "previousDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "newDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.014999999999417923>]>"}
2025-06-10 07:34:47,187 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.014999999999417923>]>", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:47,187 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:47,187 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "684792bf7b4935d9033ef466"}, "driverConnectionId": 1, "serverConnectionId": 228, "serverHost": "localhost", "serverPort": 27017, "awaited": true}
2025-06-10 07:34:47,187 - pymongo.connection - DEBUG - {"message": "Connection created", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:34:47,189 - pymongo.connection - DEBUG - {"message": "Connection ready", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 07:34:47,189 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 07:34:47,189 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T07:34:47.168Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"EfFFZl2rRkewwwMrobZAlg==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 28428, "operationId": 28428, "driverConnectionId": 1, "serverConnectionId": 230, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:47,193 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "durationMS": 3.277, "reply": "{\"cursor\": {\"ns\": \"alphasage.dashboards\"}, \"ok\": 1.0}", "commandName": "find", "databaseName": "alphasage", "requestId": 28428, "operationId": 28428, "driverConnectionId": 1, "serverConnectionId": 230, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:47,193 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:34:47,194 - __main__ - INFO - Generating new dashboard for Hitachi Energy India Ltd. (POWERINDIA.NS)
2025-06-10 07:34:47,194 - yfinance - DEBUG - get_raw_json(): https://query2.finance.yahoo.com/v10/finance/quoteSummary/POWERINDIA.NS
2025-06-10 07:34:47,194 - yfinance - DEBUG - Entering get()
2025-06-10 07:34:47,194 - yfinance - DEBUG -  Entering _make_request()
2025-06-10 07:34:47,194 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/v10/finance/quoteSummary/POWERINDIA.NS
2025-06-10 07:34:47,194 - yfinance - DEBUG - params={'modules': 'financialData,quoteType,defaultKeyStatistics,assetProfile,summaryDetail', 'corsDomain': 'finance.yahoo.com', 'formatted': 'false', 'symbol': 'POWERINDIA.NS'}
2025-06-10 07:34:47,194 - yfinance - DEBUG -   Entering _get_cookie_and_crumb()
2025-06-10 07:34:47,194 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:47,194 - yfinance - DEBUG -    Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:47,194 - yfinance - DEBUG -     Entering _get_cookie_basic()
2025-06-10 07:34:47,194 - yfinance - DEBUG -      Entering _load_cookie_curlCffi()
2025-06-10 07:34:47,203 - peewee - DEBUG - ('CREATE TABLE IF NOT EXISTS "_cookieschema" ("strategy" VARCHAR(255) NOT NULL PRIMARY KEY, "fetch_date" DATETIME NOT NULL, "cookie_bytes" BLOB NOT NULL) WITHOUT ROWID', [])
2025-06-10 07:34:47,203 - peewee - DEBUG - ('SELECT "t1"."strategy", "t1"."fetch_date", "t1"."cookie_bytes" FROM "_cookieschema" AS "t1" WHERE ("t1"."strategy" = ?) LIMIT ? OFFSET ?', ['curlCffi', 1, 0])
2025-06-10 07:34:47,204 - yfinance - DEBUG -      Exiting _load_cookie_curlCffi()
2025-06-10 07:34:47,204 - yfinance - DEBUG - reusing persistent cookie
2025-06-10 07:34:47,204 - yfinance - DEBUG -     Exiting _get_cookie_basic()
2025-06-10 07:34:47,204 - yfinance - DEBUG -     Entering _get_crumb_basic()
2025-06-10 07:34:47,204 - yfinance - DEBUG -      Entering _get_cookie_basic()
2025-06-10 07:34:47,204 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:47,204 - yfinance - DEBUG -      Exiting _get_cookie_basic()
2025-06-10 07:34:47,442 - yfinance - DEBUG - crumb = '9kb8ySX7AIF'
2025-06-10 07:34:47,442 - yfinance - DEBUG -     Exiting _get_crumb_basic()
2025-06-10 07:34:47,442 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:47,442 - yfinance - DEBUG -   Exiting _get_cookie_and_crumb()
2025-06-10 07:34:47,782 - yfinance - DEBUG - response code=200
2025-06-10 07:34:47,782 - yfinance - DEBUG -  Exiting _make_request()
2025-06-10 07:34:47,782 - yfinance - DEBUG - Exiting get()
2025-06-10 07:34:47,783 - yfinance - DEBUG - get_raw_json(): https://query1.finance.yahoo.com/v7/finance/quote?
2025-06-10 07:34:47,783 - yfinance - DEBUG - Entering get()
2025-06-10 07:34:47,783 - yfinance - DEBUG -  Entering _make_request()
2025-06-10 07:34:47,783 - yfinance - DEBUG - url=https://query1.finance.yahoo.com/v7/finance/quote?
2025-06-10 07:34:47,784 - yfinance - DEBUG - params={'symbols': 'POWERINDIA.NS', 'formatted': 'false'}
2025-06-10 07:34:47,784 - yfinance - DEBUG -   Entering _get_cookie_and_crumb()
2025-06-10 07:34:47,784 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:47,784 - yfinance - DEBUG -    Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:47,784 - yfinance - DEBUG -     Entering _get_cookie_basic()
2025-06-10 07:34:47,784 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:47,784 - yfinance - DEBUG -     Exiting _get_cookie_basic()
2025-06-10 07:34:47,784 - yfinance - DEBUG -     Entering _get_crumb_basic()
2025-06-10 07:34:47,784 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:47,784 - yfinance - DEBUG -     Exiting _get_crumb_basic()
2025-06-10 07:34:47,784 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:47,784 - yfinance - DEBUG -   Exiting _get_cookie_and_crumb()
2025-06-10 07:34:47,901 - yfinance - DEBUG - response code=200
2025-06-10 07:34:47,902 - yfinance - DEBUG -  Exiting _make_request()
2025-06-10 07:34:47,902 - yfinance - DEBUG - Exiting get()
2025-06-10 07:34:47,909 - yfinance - DEBUG - Entering get()
2025-06-10 07:34:47,909 - yfinance - DEBUG -  Entering _make_request()
2025-06-10 07:34:47,909 - yfinance - DEBUG - url=https://query1.finance.yahoo.com/ws/fundamentals-timeseries/v1/finance/timeseries/POWERINDIA.NS?symbol=POWERINDIA.NS&type=trailingPegRatio&period1=1733788800&period2=1749600000
2025-06-10 07:34:47,909 - yfinance - DEBUG - params=None
2025-06-10 07:34:47,910 - yfinance - DEBUG -   Entering _get_cookie_and_crumb()
2025-06-10 07:34:47,910 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:47,910 - yfinance - DEBUG -    Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:47,910 - yfinance - DEBUG -     Entering _get_cookie_basic()
2025-06-10 07:34:47,910 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:47,910 - yfinance - DEBUG -     Exiting _get_cookie_basic()
2025-06-10 07:34:47,910 - yfinance - DEBUG -     Entering _get_crumb_basic()
2025-06-10 07:34:47,910 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:47,910 - yfinance - DEBUG -     Exiting _get_crumb_basic()
2025-06-10 07:34:47,910 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:47,910 - yfinance - DEBUG -   Exiting _get_cookie_and_crumb()
2025-06-10 07:34:48,031 - yfinance - DEBUG - response code=200
2025-06-10 07:34:48,031 - yfinance - DEBUG -  Exiting _make_request()
2025-06-10 07:34:48,031 - yfinance - DEBUG - Exiting get()
2025-06-10 07:34:48,031 - yfinance - DEBUG - Entering history()
2025-06-10 07:34:48,035 - peewee - DEBUG - ('CREATE TABLE IF NOT EXISTS "_kv" ("key" VARCHAR(255) NOT NULL PRIMARY KEY, "value" VARCHAR(255)) WITHOUT ROWID', [])
2025-06-10 07:34:48,035 - peewee - DEBUG - ('SELECT "t1"."key", "t1"."value" FROM "_kv" AS "t1" WHERE ("t1"."key" = ?) LIMIT ? OFFSET ?', ['POWERINDIA.NS', 1, 0])
2025-06-10 07:34:48,035 - yfinance - DEBUG -  Entering _fetch_ticker_tz()
2025-06-10 07:34:48,035 - yfinance - DEBUG -   Entering get()
2025-06-10 07:34:48,035 - yfinance - DEBUG -    Entering _make_request()
2025-06-10 07:34:48,035 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/v8/finance/chart/POWERINDIA.NS
2025-06-10 07:34:48,035 - yfinance - DEBUG - params=frozendict.frozendict({'range': '1d', 'interval': '1d'})
2025-06-10 07:34:48,035 - yfinance - DEBUG -     Entering _get_cookie_and_crumb()
2025-06-10 07:34:48,035 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:48,035 - yfinance - DEBUG -      Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:48,036 - yfinance - DEBUG -       Entering _get_cookie_basic()
2025-06-10 07:34:48,036 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:48,036 - yfinance - DEBUG -       Exiting _get_cookie_basic()
2025-06-10 07:34:48,036 - yfinance - DEBUG -       Entering _get_crumb_basic()
2025-06-10 07:34:48,036 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:48,036 - yfinance - DEBUG -       Exiting _get_crumb_basic()
2025-06-10 07:34:48,036 - yfinance - DEBUG -      Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:48,036 - yfinance - DEBUG -     Exiting _get_cookie_and_crumb()
2025-06-10 07:34:48,135 - yfinance - DEBUG - response code=200
2025-06-10 07:34:48,135 - yfinance - DEBUG -    Exiting _make_request()
2025-06-10 07:34:48,135 - yfinance - DEBUG -   Exiting get()
2025-06-10 07:34:48,135 - yfinance - DEBUG -  Exiting _fetch_ticker_tz()
2025-06-10 07:34:50,300 - peewee - DEBUG - ('BEGIN', None)
2025-06-10 07:34:50,300 - peewee - DEBUG - ('INSERT INTO "_kv" ("key", "value") VALUES (?, ?)', ['POWERINDIA.NS', 'Asia/Kolkata'])
2025-06-10 07:34:50,308 - yfinance - DEBUG -  Entering history()
2025-06-10 07:34:50,309 - yfinance - DEBUG - POWERINDIA.NS: Yahoo GET parameters: {'range': '1y', 'interval': '1d', 'includePrePost': False, 'events': 'div,splits,capitalGains'}
2025-06-10 07:34:50,309 - yfinance - DEBUG -   Entering get()
2025-06-10 07:34:50,309 - yfinance - DEBUG -    Entering _make_request()
2025-06-10 07:34:50,309 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/v8/finance/chart/POWERINDIA.NS
2025-06-10 07:34:50,309 - yfinance - DEBUG - params={'range': '1y', 'interval': '1d', 'includePrePost': False, 'events': 'div,splits,capitalGains'}
2025-06-10 07:34:50,309 - yfinance - DEBUG -     Entering _get_cookie_and_crumb()
2025-06-10 07:34:50,309 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:50,309 - yfinance - DEBUG -      Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:50,309 - yfinance - DEBUG -       Entering _get_cookie_basic()
2025-06-10 07:34:50,309 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:50,309 - yfinance - DEBUG -       Exiting _get_cookie_basic()
2025-06-10 07:34:50,309 - yfinance - DEBUG -       Entering _get_crumb_basic()
2025-06-10 07:34:50,309 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:50,310 - yfinance - DEBUG -       Exiting _get_crumb_basic()
2025-06-10 07:34:50,310 - yfinance - DEBUG -      Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:50,310 - yfinance - DEBUG -     Exiting _get_cookie_and_crumb()
2025-06-10 07:34:50,443 - yfinance - DEBUG - response code=200
2025-06-10 07:34:50,443 - yfinance - DEBUG -    Exiting _make_request()
2025-06-10 07:34:50,444 - yfinance - DEBUG -   Exiting get()
2025-06-10 07:34:50,454 - yfinance - DEBUG - POWERINDIA.NS: yfinance received OHLC data: 2024-06-10 03:45:00 -> 2025-06-09 03:45:00
2025-06-10 07:34:50,470 - yfinance - DEBUG - POWERINDIA.NS: OHLC after cleaning: 2024-06-10 09:15:00+05:30 -> 2025-06-09 09:15:00+05:30
2025-06-10 07:34:50,485 - yfinance - DEBUG - POWERINDIA.NS: OHLC after combining events: 2024-06-10 00:00:00+05:30 -> 2025-06-09 00:00:00+05:30
2025-06-10 07:34:50,492 - yfinance - DEBUG - POWERINDIA.NS: yfinance returning OHLC: 2024-06-10 00:00:00+05:30 -> 2025-06-09 00:00:00+05:30
2025-06-10 07:34:50,493 - yfinance - DEBUG -  Exiting history()
2025-06-10 07:34:50,493 - yfinance - DEBUG - Exiting history()
2025-06-10 07:34:50,493 - yfinance - DEBUG - Entering _fetch_time_series()
2025-06-10 07:34:50,493 - yfinance - DEBUG -  Entering get()
2025-06-10 07:34:50,493 - yfinance - DEBUG -   Entering _make_request()
2025-06-10 07:34:50,493 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/ws/fundamentals-timeseries/v1/finance/timeseries/POWERINDIA.NS?symbol=POWERINDIA.NS&type=annualTaxEffectOfUnusualItems,annualTaxRateForCalcs,annualNormalizedEBITDA,ann...
2025-06-10 07:34:50,493 - yfinance - DEBUG - params=None
2025-06-10 07:34:50,493 - yfinance - DEBUG -    Entering _get_cookie_and_crumb()
2025-06-10 07:34:50,493 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:50,493 - yfinance - DEBUG -     Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:50,493 - yfinance - DEBUG -      Entering _get_cookie_basic()
2025-06-10 07:34:50,493 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:50,493 - yfinance - DEBUG -      Exiting _get_cookie_basic()
2025-06-10 07:34:50,493 - yfinance - DEBUG -      Entering _get_crumb_basic()
2025-06-10 07:34:50,493 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:50,493 - yfinance - DEBUG -      Exiting _get_crumb_basic()
2025-06-10 07:34:50,493 - yfinance - DEBUG -     Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:50,494 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb()
2025-06-10 07:34:50,710 - yfinance - DEBUG - response code=200
2025-06-10 07:34:50,711 - yfinance - DEBUG -   Exiting _make_request()
2025-06-10 07:34:50,711 - yfinance - DEBUG -  Exiting get()
2025-06-10 07:34:50,743 - yfinance - DEBUG - Exiting _fetch_time_series()
2025-06-10 07:34:50,745 - yfinance - DEBUG - Entering _fetch_time_series()
2025-06-10 07:34:50,745 - yfinance - DEBUG -  Entering get()
2025-06-10 07:34:50,745 - yfinance - DEBUG -   Entering _make_request()
2025-06-10 07:34:50,745 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/ws/fundamentals-timeseries/v1/finance/timeseries/POWERINDIA.NS?symbol=POWERINDIA.NS&type=annualTreasurySharesNumber,annualPreferredSharesNumber,annualOrdinarySharesNum...
2025-06-10 07:34:50,745 - yfinance - DEBUG - params=None
2025-06-10 07:34:50,745 - yfinance - DEBUG -    Entering _get_cookie_and_crumb()
2025-06-10 07:34:50,745 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:50,745 - yfinance - DEBUG -     Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:50,745 - yfinance - DEBUG -      Entering _get_cookie_basic()
2025-06-10 07:34:50,745 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:50,745 - yfinance - DEBUG -      Exiting _get_cookie_basic()
2025-06-10 07:34:50,745 - yfinance - DEBUG -      Entering _get_crumb_basic()
2025-06-10 07:34:50,745 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:50,745 - yfinance - DEBUG -      Exiting _get_crumb_basic()
2025-06-10 07:34:50,745 - yfinance - DEBUG -     Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:50,745 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb()
2025-06-10 07:34:51,047 - yfinance - DEBUG - response code=200
2025-06-10 07:34:51,047 - yfinance - DEBUG -   Exiting _make_request()
2025-06-10 07:34:51,047 - yfinance - DEBUG -  Exiting get()
2025-06-10 07:34:51,075 - yfinance - DEBUG - Exiting _fetch_time_series()
2025-06-10 07:34:51,075 - yfinance - DEBUG - Entering _fetch_time_series()
2025-06-10 07:34:51,076 - yfinance - DEBUG -  Entering get()
2025-06-10 07:34:51,076 - yfinance - DEBUG -   Entering _make_request()
2025-06-10 07:34:51,076 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/ws/fundamentals-timeseries/v1/finance/timeseries/POWERINDIA.NS?symbol=POWERINDIA.NS&type=annualForeignSales,annualDomesticSales,annualAdjustedGeographySegmentData,annu...
2025-06-10 07:34:51,076 - yfinance - DEBUG - params=None
2025-06-10 07:34:51,076 - yfinance - DEBUG -    Entering _get_cookie_and_crumb()
2025-06-10 07:34:51,076 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:51,076 - yfinance - DEBUG -     Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:51,076 - yfinance - DEBUG -      Entering _get_cookie_basic()
2025-06-10 07:34:51,076 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:51,076 - yfinance - DEBUG -      Exiting _get_cookie_basic()
2025-06-10 07:34:51,076 - yfinance - DEBUG -      Entering _get_crumb_basic()
2025-06-10 07:34:51,076 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:51,076 - yfinance - DEBUG -      Exiting _get_crumb_basic()
2025-06-10 07:34:51,076 - yfinance - DEBUG -     Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:51,076 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb()
2025-06-10 07:34:51,368 - yfinance - DEBUG - response code=200
2025-06-10 07:34:51,368 - yfinance - DEBUG -   Exiting _make_request()
2025-06-10 07:34:51,368 - yfinance - DEBUG -  Exiting get()
2025-06-10 07:34:51,386 - yfinance - DEBUG - Exiting _fetch_time_series()
2025-06-10 07:34:51,387 - yfinance - DEBUG - get_raw_json(): https://query2.finance.yahoo.com/v10/finance/quoteSummary/POWERINDIA.NS
2025-06-10 07:34:51,387 - yfinance - DEBUG - Entering get()
2025-06-10 07:34:51,387 - yfinance - DEBUG -  Entering _make_request()
2025-06-10 07:34:51,387 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/v10/finance/quoteSummary/POWERINDIA.NS
2025-06-10 07:34:51,387 - yfinance - DEBUG - params={'modules': 'recommendationTrend', 'corsDomain': 'finance.yahoo.com', 'formatted': 'false', 'symbol': 'POWERINDIA.NS'}
2025-06-10 07:34:51,387 - yfinance - DEBUG -   Entering _get_cookie_and_crumb()
2025-06-10 07:34:51,387 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:51,387 - yfinance - DEBUG -    Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:51,387 - yfinance - DEBUG -     Entering _get_cookie_basic()
2025-06-10 07:34:51,387 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:51,387 - yfinance - DEBUG -     Exiting _get_cookie_basic()
2025-06-10 07:34:51,387 - yfinance - DEBUG -     Entering _get_crumb_basic()
2025-06-10 07:34:51,387 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:51,387 - yfinance - DEBUG -     Exiting _get_crumb_basic()
2025-06-10 07:34:51,387 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:51,387 - yfinance - DEBUG -   Exiting _get_cookie_and_crumb()
2025-06-10 07:34:51,501 - yfinance - DEBUG - response code=200
2025-06-10 07:34:51,501 - yfinance - DEBUG -  Exiting _make_request()
2025-06-10 07:34:51,501 - yfinance - DEBUG - Exiting get()
2025-06-10 07:34:51,545 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "<function writable_server_selector at 0x00000289B891ADE0>", "operation": "insert", "topologyDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.014999999999417923>]>", "clientId": {"$oid": "684792bf7b4935d9033ef466"}}
2025-06-10 07:34:51,545 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "<function writable_server_selector at 0x00000289B891ADE0>", "operation": "insert", "topologyDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.014999999999417923>]>", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:51,545 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:51,547 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 07:34:51,547 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "command": "{\"insert\": \"dashboards\", \"ordered\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"EfFFZl2rRkewwwMrobZAlg==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\", \"documents\": [{\"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"dashboard_data\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"about_company\": {\"description\": \"Hitachi Energy India Limited offers products, projects, and services for electricity transmission and related activities in India and internationally. The company is involved in engineering, integration, installation, commissioning, and support of project and services; and design, manufacturing, configuration, and supply of system, equipment, devices, and accessories products. It also manufactures and sells electric motors, generators, transformers, and electricity distribution and control apparatus, as well as related electrical equipment. The company was formerly known as ABB Power Products and Systems India Limited and changed its name to Hitachi Energy In...", "commandName": "insert", "databaseName": "alphasage", "requestId": 31934, "operationId": 31934, "driverConnectionId": 1, "serverConnectionId": 230, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:51,611 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "durationMS": 64.90799999999999, "reply": "{\"n\": 1, \"ok\": 1.0}", "commandName": "insert", "databaseName": "alphasage", "requestId": 31934, "operationId": 31934, "driverConnectionId": 1, "serverConnectionId": 230, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:51,611 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:34:51,613 - __main__ - INFO - Stored dashboard for Hitachi Energy India Ltd. in MongoDB
2025-06-10 07:34:51,613 - __main__ - INFO - Successfully generated and stored dashboard for Hitachi Energy India Ltd.
2025-06-10 07:34:51,614 - __main__ - INFO - Checking MongoDB for existing dashboard for Reliance Industries Ltd. (RELIANCE.NS)
2025-06-10 07:34:51,614 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.014999999999417923>]>", "clientId": {"$oid": "684792bf7b4935d9033ef466"}}
2025-06-10 07:34:51,614 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.014999999999417923>]>", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:51,614 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:51,614 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 07:34:51,614 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T07:34:51.614Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"EfFFZl2rRkewwwMrobZAlg==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 11147, "operationId": 11147, "driverConnectionId": 1, "serverConnectionId": 230, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:51,625 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "durationMS": 11.12, "reply": "{\"cursor\": {\"ns\": \"alphasage.dashboards\"}, \"ok\": 1.0}", "commandName": "find", "databaseName": "alphasage", "requestId": 11147, "operationId": 11147, "driverConnectionId": 1, "serverConnectionId": 230, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:51,625 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:34:51,625 - __main__ - INFO - Generating new dashboard for Reliance Industries Ltd. (RELIANCE.NS)
2025-06-10 07:34:51,625 - yfinance - DEBUG - get_raw_json(): https://query2.finance.yahoo.com/v10/finance/quoteSummary/RELIANCE.NS
2025-06-10 07:34:51,625 - yfinance - DEBUG - Entering get()
2025-06-10 07:34:51,625 - yfinance - DEBUG -  Entering _make_request()
2025-06-10 07:34:51,625 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/v10/finance/quoteSummary/RELIANCE.NS
2025-06-10 07:34:51,626 - yfinance - DEBUG - params={'modules': 'financialData,quoteType,defaultKeyStatistics,assetProfile,summaryDetail', 'corsDomain': 'finance.yahoo.com', 'formatted': 'false', 'symbol': 'RELIANCE.NS'}
2025-06-10 07:34:51,626 - yfinance - DEBUG -   Entering _get_cookie_and_crumb()
2025-06-10 07:34:51,626 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:51,626 - yfinance - DEBUG -    Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:51,626 - yfinance - DEBUG -     Entering _get_cookie_basic()
2025-06-10 07:34:51,626 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:51,626 - yfinance - DEBUG -     Exiting _get_cookie_basic()
2025-06-10 07:34:51,626 - yfinance - DEBUG -     Entering _get_crumb_basic()
2025-06-10 07:34:51,626 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:51,626 - yfinance - DEBUG -     Exiting _get_crumb_basic()
2025-06-10 07:34:51,626 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:51,626 - yfinance - DEBUG -   Exiting _get_cookie_and_crumb()
2025-06-10 07:34:51,795 - yfinance - DEBUG - response code=200
2025-06-10 07:34:51,795 - yfinance - DEBUG -  Exiting _make_request()
2025-06-10 07:34:51,795 - yfinance - DEBUG - Exiting get()
2025-06-10 07:34:51,795 - yfinance - DEBUG - get_raw_json(): https://query1.finance.yahoo.com/v7/finance/quote?
2025-06-10 07:34:51,795 - yfinance - DEBUG - Entering get()
2025-06-10 07:34:51,795 - yfinance - DEBUG -  Entering _make_request()
2025-06-10 07:34:51,795 - yfinance - DEBUG - url=https://query1.finance.yahoo.com/v7/finance/quote?
2025-06-10 07:34:51,795 - yfinance - DEBUG - params={'symbols': 'RELIANCE.NS', 'formatted': 'false'}
2025-06-10 07:34:51,795 - yfinance - DEBUG -   Entering _get_cookie_and_crumb()
2025-06-10 07:34:51,795 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:51,795 - yfinance - DEBUG -    Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:51,796 - yfinance - DEBUG -     Entering _get_cookie_basic()
2025-06-10 07:34:51,796 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:51,796 - yfinance - DEBUG -     Exiting _get_cookie_basic()
2025-06-10 07:34:51,796 - yfinance - DEBUG -     Entering _get_crumb_basic()
2025-06-10 07:34:51,796 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:51,796 - yfinance - DEBUG -     Exiting _get_crumb_basic()
2025-06-10 07:34:51,796 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:51,796 - yfinance - DEBUG -   Exiting _get_cookie_and_crumb()
2025-06-10 07:34:51,905 - yfinance - DEBUG - response code=200
2025-06-10 07:34:51,905 - yfinance - DEBUG -  Exiting _make_request()
2025-06-10 07:34:51,905 - yfinance - DEBUG - Exiting get()
2025-06-10 07:34:51,906 - yfinance - DEBUG - Entering get()
2025-06-10 07:34:51,906 - yfinance - DEBUG -  Entering _make_request()
2025-06-10 07:34:51,906 - yfinance - DEBUG - url=https://query1.finance.yahoo.com/ws/fundamentals-timeseries/v1/finance/timeseries/RELIANCE.NS?symbol=RELIANCE.NS&type=trailingPegRatio&period1=1733788800&period2=1749600000
2025-06-10 07:34:51,906 - yfinance - DEBUG - params=None
2025-06-10 07:34:51,906 - yfinance - DEBUG -   Entering _get_cookie_and_crumb()
2025-06-10 07:34:51,906 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:51,906 - yfinance - DEBUG -    Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:51,906 - yfinance - DEBUG -     Entering _get_cookie_basic()
2025-06-10 07:34:51,906 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:51,906 - yfinance - DEBUG -     Exiting _get_cookie_basic()
2025-06-10 07:34:51,906 - yfinance - DEBUG -     Entering _get_crumb_basic()
2025-06-10 07:34:51,906 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:51,906 - yfinance - DEBUG -     Exiting _get_crumb_basic()
2025-06-10 07:34:51,906 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:51,906 - yfinance - DEBUG -   Exiting _get_cookie_and_crumb()
2025-06-10 07:34:52,166 - yfinance - DEBUG - response code=200
2025-06-10 07:34:52,166 - yfinance - DEBUG -  Exiting _make_request()
2025-06-10 07:34:52,166 - yfinance - DEBUG - Exiting get()
2025-06-10 07:34:52,166 - yfinance - DEBUG - Entering history()
2025-06-10 07:34:52,167 - peewee - DEBUG - ('SELECT "t1"."key", "t1"."value" FROM "_kv" AS "t1" WHERE ("t1"."key" = ?) LIMIT ? OFFSET ?', ['RELIANCE.NS', 1, 0])
2025-06-10 07:34:52,167 - yfinance - DEBUG -  Entering history()
2025-06-10 07:34:52,167 - yfinance - DEBUG - RELIANCE.NS: Yahoo GET parameters: {'range': '1y', 'interval': '1d', 'includePrePost': False, 'events': 'div,splits,capitalGains'}
2025-06-10 07:34:52,167 - yfinance - DEBUG -   Entering get()
2025-06-10 07:34:52,167 - yfinance - DEBUG -    Entering _make_request()
2025-06-10 07:34:52,167 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/v8/finance/chart/RELIANCE.NS
2025-06-10 07:34:52,167 - yfinance - DEBUG - params={'range': '1y', 'interval': '1d', 'includePrePost': False, 'events': 'div,splits,capitalGains'}
2025-06-10 07:34:52,167 - yfinance - DEBUG -     Entering _get_cookie_and_crumb()
2025-06-10 07:34:52,167 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:52,167 - yfinance - DEBUG -      Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:52,167 - yfinance - DEBUG -       Entering _get_cookie_basic()
2025-06-10 07:34:52,167 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:52,167 - yfinance - DEBUG -       Exiting _get_cookie_basic()
2025-06-10 07:34:52,168 - yfinance - DEBUG -       Entering _get_crumb_basic()
2025-06-10 07:34:52,168 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:52,168 - yfinance - DEBUG -       Exiting _get_crumb_basic()
2025-06-10 07:34:52,168 - yfinance - DEBUG -      Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:52,168 - yfinance - DEBUG -     Exiting _get_cookie_and_crumb()
2025-06-10 07:34:52,315 - yfinance - DEBUG - response code=200
2025-06-10 07:34:52,315 - yfinance - DEBUG -    Exiting _make_request()
2025-06-10 07:34:52,315 - yfinance - DEBUG -   Exiting get()
2025-06-10 07:34:52,318 - yfinance - DEBUG - RELIANCE.NS: yfinance received OHLC data: 2024-06-10 03:45:00 -> 2025-06-09 03:45:00
2025-06-10 07:34:52,319 - yfinance - DEBUG - RELIANCE.NS: OHLC after cleaning: 2024-06-10 09:15:00+05:30 -> 2025-06-09 09:15:00+05:30
2025-06-10 07:34:52,324 - yfinance - DEBUG - RELIANCE.NS: OHLC after combining events: 2024-06-10 00:00:00+05:30 -> 2025-06-09 00:00:00+05:30
2025-06-10 07:34:52,328 - yfinance - DEBUG - RELIANCE.NS: yfinance returning OHLC: 2024-06-10 00:00:00+05:30 -> 2025-06-09 00:00:00+05:30
2025-06-10 07:34:52,328 - yfinance - DEBUG -  Exiting history()
2025-06-10 07:34:52,328 - yfinance - DEBUG - Exiting history()
2025-06-10 07:34:52,328 - yfinance - DEBUG - Entering _fetch_time_series()
2025-06-10 07:34:52,328 - yfinance - DEBUG -  Entering get()
2025-06-10 07:34:52,328 - yfinance - DEBUG -   Entering _make_request()
2025-06-10 07:34:52,328 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/ws/fundamentals-timeseries/v1/finance/timeseries/RELIANCE.NS?symbol=RELIANCE.NS&type=annualTaxEffectOfUnusualItems,annualTaxRateForCalcs,annualNormalizedEBITDA,annualN...
2025-06-10 07:34:52,328 - yfinance - DEBUG - params=None
2025-06-10 07:34:52,328 - yfinance - DEBUG -    Entering _get_cookie_and_crumb()
2025-06-10 07:34:52,328 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:52,328 - yfinance - DEBUG -     Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:52,328 - yfinance - DEBUG -      Entering _get_cookie_basic()
2025-06-10 07:34:52,328 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:52,328 - yfinance - DEBUG -      Exiting _get_cookie_basic()
2025-06-10 07:34:52,328 - yfinance - DEBUG -      Entering _get_crumb_basic()
2025-06-10 07:34:52,328 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:52,329 - yfinance - DEBUG -      Exiting _get_crumb_basic()
2025-06-10 07:34:52,329 - yfinance - DEBUG -     Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:52,329 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb()
2025-06-10 07:34:52,538 - yfinance - DEBUG - response code=200
2025-06-10 07:34:52,538 - yfinance - DEBUG -   Exiting _make_request()
2025-06-10 07:34:52,538 - yfinance - DEBUG -  Exiting get()
2025-06-10 07:34:52,571 - yfinance - DEBUG - Exiting _fetch_time_series()
2025-06-10 07:34:52,572 - yfinance - DEBUG - Entering _fetch_time_series()
2025-06-10 07:34:52,572 - yfinance - DEBUG -  Entering get()
2025-06-10 07:34:52,572 - yfinance - DEBUG -   Entering _make_request()
2025-06-10 07:34:52,572 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/ws/fundamentals-timeseries/v1/finance/timeseries/RELIANCE.NS?symbol=RELIANCE.NS&type=annualTreasurySharesNumber,annualPreferredSharesNumber,annualOrdinarySharesNumber,...
2025-06-10 07:34:52,572 - yfinance - DEBUG - params=None
2025-06-10 07:34:52,572 - yfinance - DEBUG -    Entering _get_cookie_and_crumb()
2025-06-10 07:34:52,572 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:52,572 - yfinance - DEBUG -     Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:52,572 - yfinance - DEBUG -      Entering _get_cookie_basic()
2025-06-10 07:34:52,572 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:52,573 - yfinance - DEBUG -      Exiting _get_cookie_basic()
2025-06-10 07:34:52,573 - yfinance - DEBUG -      Entering _get_crumb_basic()
2025-06-10 07:34:52,573 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:52,573 - yfinance - DEBUG -      Exiting _get_crumb_basic()
2025-06-10 07:34:52,573 - yfinance - DEBUG -     Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:52,573 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb()
2025-06-10 07:34:52,807 - yfinance - DEBUG - response code=200
2025-06-10 07:34:52,807 - yfinance - DEBUG -   Exiting _make_request()
2025-06-10 07:34:52,807 - yfinance - DEBUG -  Exiting get()
2025-06-10 07:34:52,824 - yfinance - DEBUG - Exiting _fetch_time_series()
2025-06-10 07:34:52,825 - yfinance - DEBUG - Entering _fetch_time_series()
2025-06-10 07:34:52,825 - yfinance - DEBUG -  Entering get()
2025-06-10 07:34:52,825 - yfinance - DEBUG -   Entering _make_request()
2025-06-10 07:34:52,825 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/ws/fundamentals-timeseries/v1/finance/timeseries/RELIANCE.NS?symbol=RELIANCE.NS&type=annualForeignSales,annualDomesticSales,annualAdjustedGeographySegmentData,annualFr...
2025-06-10 07:34:52,825 - yfinance - DEBUG - params=None
2025-06-10 07:34:52,825 - yfinance - DEBUG -    Entering _get_cookie_and_crumb()
2025-06-10 07:34:52,825 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:52,825 - yfinance - DEBUG -     Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:52,825 - yfinance - DEBUG -      Entering _get_cookie_basic()
2025-06-10 07:34:52,825 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:52,825 - yfinance - DEBUG -      Exiting _get_cookie_basic()
2025-06-10 07:34:52,825 - yfinance - DEBUG -      Entering _get_crumb_basic()
2025-06-10 07:34:52,825 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:52,826 - yfinance - DEBUG -      Exiting _get_crumb_basic()
2025-06-10 07:34:52,826 - yfinance - DEBUG -     Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:52,826 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb()
2025-06-10 07:34:53,033 - yfinance - DEBUG - response code=200
2025-06-10 07:34:53,033 - yfinance - DEBUG -   Exiting _make_request()
2025-06-10 07:34:53,033 - yfinance - DEBUG -  Exiting get()
2025-06-10 07:34:53,045 - yfinance - DEBUG - Exiting _fetch_time_series()
2025-06-10 07:34:53,045 - yfinance - DEBUG - get_raw_json(): https://query2.finance.yahoo.com/v10/finance/quoteSummary/RELIANCE.NS
2025-06-10 07:34:53,045 - yfinance - DEBUG - Entering get()
2025-06-10 07:34:53,045 - yfinance - DEBUG -  Entering _make_request()
2025-06-10 07:34:53,045 - yfinance - DEBUG - url=https://query2.finance.yahoo.com/v10/finance/quoteSummary/RELIANCE.NS
2025-06-10 07:34:53,045 - yfinance - DEBUG - params={'modules': 'recommendationTrend', 'corsDomain': 'finance.yahoo.com', 'formatted': 'false', 'symbol': 'RELIANCE.NS'}
2025-06-10 07:34:53,045 - yfinance - DEBUG -   Entering _get_cookie_and_crumb()
2025-06-10 07:34:53,045 - yfinance - DEBUG - cookie_mode = 'basic'
2025-06-10 07:34:53,046 - yfinance - DEBUG -    Entering _get_cookie_and_crumb_basic()
2025-06-10 07:34:53,046 - yfinance - DEBUG -     Entering _get_cookie_basic()
2025-06-10 07:34:53,046 - yfinance - DEBUG - reusing cookie
2025-06-10 07:34:53,046 - yfinance - DEBUG -     Exiting _get_cookie_basic()
2025-06-10 07:34:53,046 - yfinance - DEBUG -     Entering _get_crumb_basic()
2025-06-10 07:34:53,046 - yfinance - DEBUG - reusing crumb
2025-06-10 07:34:53,046 - yfinance - DEBUG -     Exiting _get_crumb_basic()
2025-06-10 07:34:53,046 - yfinance - DEBUG -    Exiting _get_cookie_and_crumb_basic()
2025-06-10 07:34:53,046 - yfinance - DEBUG -   Exiting _get_cookie_and_crumb()
2025-06-10 07:34:53,147 - yfinance - DEBUG - response code=200
2025-06-10 07:34:53,147 - yfinance - DEBUG -  Exiting _make_request()
2025-06-10 07:34:53,148 - yfinance - DEBUG - Exiting get()
2025-06-10 07:34:53,150 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "<function writable_server_selector at 0x00000289B891ADE0>", "operation": "insert", "topologyDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.014999999999417923>]>", "clientId": {"$oid": "684792bf7b4935d9033ef466"}}
2025-06-10 07:34:53,150 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "<function writable_server_selector at 0x00000289B891ADE0>", "operation": "insert", "topologyDescription": "<TopologyDescription id: 684792bf7b4935d9033ef466, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.014999999999417923>]>", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:53,151 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:53,151 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 07:34:53,151 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "command": "{\"insert\": \"dashboards\", \"ordered\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"EfFFZl2rRkewwwMrobZAlg==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\", \"documents\": [{\"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"dashboard_data\": {\"company_name\": \"Reliance Industries Ltd.\", \"about_company\": {\"description\": \"Reliance Industries Limited engages in hydrocarbon exploration and production, oil and chemicals, textile, retail, digital, material and composites, renewables, and financial services businesses worldwide. It operates through Oil to Chemicals, Oil and Gas, Retail, Digital Services, and Others segments. The company produces and markets petroleum products, such as liquefied petroleum gas, propylene, naphtha, gasoline, jet/aviation turbine fuel, kerosene oil, diesel, sulphur, and petroleum coke. It also provides petrochemicals, including high-density and low-density polyethylene (PE), linear low-density PE, polyester fibers and yarns, polypropylene, polyvinyl chlori...", "commandName": "insert", "databaseName": "alphasage", "requestId": 45, "operationId": 45, "driverConnectionId": 1, "serverConnectionId": 230, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:53,153 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "durationMS": 1.264, "reply": "{\"n\": 1, \"ok\": 1.0}", "commandName": "insert", "databaseName": "alphasage", "requestId": 45, "operationId": 45, "driverConnectionId": 1, "serverConnectionId": 230, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:34:53,153 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "684792bf7b4935d9033ef466"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:34:53,153 - __main__ - INFO - Stored dashboard for Reliance Industries Ltd. in MongoDB
2025-06-10 07:34:53,153 - __main__ - INFO - Successfully generated and stored dashboard for Reliance Industries Ltd.
2025-06-10 07:42:54,280 - asyncio - DEBUG - Using proactor: IocpProactor
2025-06-10 07:42:54,295 - pymongo.topology - DEBUG - {"message": "Starting topology monitoring", "topologyId": {"$oid": "684794a6393d2c6491a870b2"}}
2025-06-10 07:42:54,295 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "684794a6393d2c6491a870b2"}, "previousDescription": "<TopologyDescription id: 684794a6393d2c6491a870b2, topology_type: Unknown, servers: []>", "newDescription": "<TopologyDescription id: 684794a6393d2c6491a870b2, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>"}
2025-06-10 07:42:54,295 - pymongo.topology - DEBUG - {"message": "Starting server monitoring", "topologyId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,296 - pymongo.connection - DEBUG - {"message": "Connection pool created", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,302 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "684794a6393d2c6491a870b2"}, "driverConnectionId": 1, "serverHost": "localhost", "serverPort": 27017, "awaited": false}
2025-06-10 07:42:54,304 - pymongo.topology - DEBUG - {"message": "Server heartbeat succeeded", "topologyId": {"$oid": "684794a6393d2c6491a870b2"}, "driverConnectionId": 1, "serverConnectionId": 231, "serverHost": "localhost", "serverPort": 27017, "awaited": false, "durationMS": 0.0, "reply": "{\"helloOk\": true, \"ismaster\": true, \"topologyVersion\": {\"processId\": {\"$oid\": \"684749947f4860064c1c4649\"}}, \"maxBsonObjectSize\": 16777216, \"maxMessageSizeBytes\": 48000000, \"maxWriteBatchSize\": 100000, \"localTime\": {\"$date\": \"2025-06-10T02:12:54.305Z\"}, \"logicalSessionTimeoutMinutes\": 30, \"connectionId\": 231, \"maxWireVersion\": 21, \"ok\": 1.0}"}
2025-06-10 07:42:54,305 - pymongo.connection - DEBUG - {"message": "Connection pool ready", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,305 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "684794a6393d2c6491a870b2"}, "previousDescription": "<TopologyDescription id: 684794a6393d2c6491a870b2, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "newDescription": "<TopologyDescription id: 684794a6393d2c6491a870b2, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>"}
2025-06-10 07:42:54,306 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "684794a6393d2c6491a870b2"}, "driverConnectionId": 1, "serverConnectionId": 231, "serverHost": "localhost", "serverPort": 27017, "awaited": true}
2025-06-10 07:42:54,366 - __main__ - INFO - Checking MongoDB for existing dashboard for Hitachi Energy India Ltd. (POWERINDIA.NS)
2025-06-10 07:42:54,366 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684794a6393d2c6491a870b2, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "684794a6393d2c6491a870b2"}}
2025-06-10 07:42:54,366 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684794a6393d2c6491a870b2, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,366 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,366 - pymongo.connection - DEBUG - {"message": "Connection created", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:42:54,368 - pymongo.connection - DEBUG - {"message": "Connection ready", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 07:42:54,368 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 07:42:54,368 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T07:42:54.366Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"ABc+W8iUR62aG/UsFeVgCw==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 11869, "operationId": 11869, "driverConnectionId": 1, "serverConnectionId": 233, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,374 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "durationMS": 5.946, "reply": "{\"cursor\": {\"firstBatch\": [{\"_id\": {\"$oid\": \"684792c37b4935d9033ef467\"}, \"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"dashboard_data\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"about_company\": {\"description\": \"Hitachi Energy India Limited offers products, projects, and services for electricity transmission and related activities in India and internationally. The company is involved in engineering, integration, installation, commissioning, and support of project and services; and design, manufacturing, configuration, and supply of system, equipment, devices, and accessories products. It also manufactures and sells electric motors, generators, transformers, and electricity distribution and control apparatus, as well as related electrical equipment. The company was formerly known as ABB Power Products and Systems India Limited and changed its name to Hitachi Energy India Limited in November 2021. Hitachi Energy India Limited was incorporated in 2019 and is...", "commandName": "find", "databaseName": "alphasage", "requestId": 11869, "operationId": 11869, "driverConnectionId": 1, "serverConnectionId": 233, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,374 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:42:54,374 - __main__ - INFO - Found cached dashboard for Hitachi Energy India Ltd. from 2025-06-10 07:34:51.544000
2025-06-10 07:42:54,374 - __main__ - INFO - Returning cached dashboard for Hitachi Energy India Ltd.
2025-06-10 07:42:54,375 - __main__ - INFO - Checking MongoDB for existing dashboard for Reliance Industries Ltd. (RELIANCE.NS)
2025-06-10 07:42:54,375 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684794a6393d2c6491a870b2, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "684794a6393d2c6491a870b2"}}
2025-06-10 07:42:54,375 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684794a6393d2c6491a870b2, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,376 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,376 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 07:42:54,376 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T07:42:54.375Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"ABc+W8iUR62aG/UsFeVgCw==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 12150, "operationId": 12150, "driverConnectionId": 1, "serverConnectionId": 233, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,377 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "durationMS": 1.013, "reply": "{\"cursor\": {\"firstBatch\": [{\"_id\": {\"$oid\": \"684792c57b4935d9033ef468\"}, \"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"dashboard_data\": {\"company_name\": \"Reliance Industries Ltd.\", \"about_company\": {\"description\": \"Reliance Industries Limited engages in hydrocarbon exploration and production, oil and chemicals, textile, retail, digital, material and composites, renewables, and financial services businesses worldwide. It operates through Oil to Chemicals, Oil and Gas, Retail, Digital Services, and Others segments. The company produces and markets petroleum products, such as liquefied petroleum gas, propylene, naphtha, gasoline, jet/aviation turbine fuel, kerosene oil, diesel, sulphur, and petroleum coke. It also provides petrochemicals, including high-density and low-density polyethylene (PE), linear low-density PE, polyester fibers and yarns, polypropylene, polyvinyl chloride, purified terephthalic acid, ethylene glycols and oxide, paraxylene, ortho xylene, benz...", "commandName": "find", "databaseName": "alphasage", "requestId": 12150, "operationId": 12150, "driverConnectionId": 1, "serverConnectionId": 233, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:42:54,377 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "684794a6393d2c6491a870b2"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:42:54,377 - __main__ - INFO - Found cached dashboard for Reliance Industries Ltd. from 2025-06-10 07:34:53.150000
2025-06-10 07:42:54,377 - __main__ - INFO - Returning cached dashboard for Reliance Industries Ltd.
2025-06-10 07:44:02,865 - asyncio - DEBUG - Using proactor: IocpProactor
2025-06-10 07:44:02,873 - pymongo.topology - DEBUG - {"message": "Starting topology monitoring", "topologyId": {"$oid": "684794ea2ba4f24409cf0bf6"}}
2025-06-10 07:44:02,873 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "previousDescription": "<TopologyDescription id: 684794ea2ba4f24409cf0bf6, topology_type: Unknown, servers: []>", "newDescription": "<TopologyDescription id: 684794ea2ba4f24409cf0bf6, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>"}
2025-06-10 07:44:02,873 - pymongo.topology - DEBUG - {"message": "Starting server monitoring", "topologyId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,873 - pymongo.connection - DEBUG - {"message": "Connection pool created", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,877 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "driverConnectionId": 1, "serverHost": "localhost", "serverPort": 27017, "awaited": false}
2025-06-10 07:44:02,878 - pymongo.topology - DEBUG - {"message": "Server heartbeat succeeded", "topologyId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "driverConnectionId": 1, "serverConnectionId": 234, "serverHost": "localhost", "serverPort": 27017, "awaited": false, "durationMS": 0.0, "reply": "{\"helloOk\": true, \"ismaster\": true, \"topologyVersion\": {\"processId\": {\"$oid\": \"684749947f4860064c1c4649\"}}, \"maxBsonObjectSize\": 16777216, \"maxMessageSizeBytes\": 48000000, \"maxWriteBatchSize\": 100000, \"localTime\": {\"$date\": \"2025-06-10T02:14:02.879Z\"}, \"logicalSessionTimeoutMinutes\": 30, \"connectionId\": 234, \"maxWireVersion\": 21, \"ok\": 1.0}"}
2025-06-10 07:44:02,878 - pymongo.connection - DEBUG - {"message": "Connection pool ready", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,880 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "previousDescription": "<TopologyDescription id: 684794ea2ba4f24409cf0bf6, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "newDescription": "<TopologyDescription id: 684794ea2ba4f24409cf0bf6, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>"}
2025-06-10 07:44:02,880 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "driverConnectionId": 1, "serverConnectionId": 234, "serverHost": "localhost", "serverPort": 27017, "awaited": true}
2025-06-10 07:44:02,917 - __main__ - INFO - Checking MongoDB for existing dashboard for Hitachi Energy India Ltd. (POWERINDIA.NS)
2025-06-10 07:44:02,917 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684794ea2ba4f24409cf0bf6, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}}
2025-06-10 07:44:02,918 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684794ea2ba4f24409cf0bf6, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,918 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,918 - pymongo.connection - DEBUG - {"message": "Connection created", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:44:02,940 - pymongo.connection - DEBUG - {"message": "Connection ready", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 07:44:02,941 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.014999999999417923}
2025-06-10 07:44:02,941 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T07:44:02.917Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"Y/okozWaQhCJrT+oiCp0uw==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 6495, "operationId": 6495, "driverConnectionId": 1, "serverConnectionId": 236, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,943 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "durationMS": 2.675, "reply": "{\"cursor\": {\"firstBatch\": [{\"_id\": {\"$oid\": \"684792c37b4935d9033ef467\"}, \"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"dashboard_data\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"about_company\": {\"description\": \"Hitachi Energy India Limited offers products, projects, and services for electricity transmission and related activities in India and internationally. The company is involved in engineering, integration, installation, commissioning, and support of project and services; and design, manufacturing, configuration, and supply of system, equipment, devices, and accessories products. It also manufactures and sells electric motors, generators, transformers, and electricity distribution and control apparatus, as well as related electrical equipment. The company was formerly known as ABB Power Products and Systems India Limited and changed its name to Hitachi Energy India Limited in November 2021. Hitachi Energy India Limited was incorporated in 2019 and is...", "commandName": "find", "databaseName": "alphasage", "requestId": 6495, "operationId": 6495, "driverConnectionId": 1, "serverConnectionId": 236, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,944 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:44:02,944 - __main__ - INFO - Found cached dashboard for Hitachi Energy India Ltd. from 2025-06-10 07:34:51.544000
2025-06-10 07:44:02,944 - __main__ - INFO - Returning cached dashboard for Hitachi Energy India Ltd.
2025-06-10 07:44:02,945 - __main__ - INFO - Checking MongoDB for existing dashboard for Reliance Industries Ltd. (RELIANCE.NS)
2025-06-10 07:44:02,945 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684794ea2ba4f24409cf0bf6, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}}
2025-06-10 07:44:02,945 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 684794ea2ba4f24409cf0bf6, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,945 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,945 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 07:44:02,946 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T07:44:02.945Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"Y/okozWaQhCJrT+oiCp0uw==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 4570, "operationId": 4570, "driverConnectionId": 1, "serverConnectionId": 236, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,947 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "durationMS": 1.0610000000000002, "reply": "{\"cursor\": {\"firstBatch\": [{\"_id\": {\"$oid\": \"684792c57b4935d9033ef468\"}, \"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"dashboard_data\": {\"company_name\": \"Reliance Industries Ltd.\", \"about_company\": {\"description\": \"Reliance Industries Limited engages in hydrocarbon exploration and production, oil and chemicals, textile, retail, digital, material and composites, renewables, and financial services businesses worldwide. It operates through Oil to Chemicals, Oil and Gas, Retail, Digital Services, and Others segments. The company produces and markets petroleum products, such as liquefied petroleum gas, propylene, naphtha, gasoline, jet/aviation turbine fuel, kerosene oil, diesel, sulphur, and petroleum coke. It also provides petrochemicals, including high-density and low-density polyethylene (PE), linear low-density PE, polyester fibers and yarns, polypropylene, polyvinyl chloride, purified terephthalic acid, ethylene glycols and oxide, paraxylene, ortho xylene, benz...", "commandName": "find", "databaseName": "alphasage", "requestId": 4570, "operationId": 4570, "driverConnectionId": 1, "serverConnectionId": 236, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 07:44:02,948 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "684794ea2ba4f24409cf0bf6"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 07:44:02,948 - __main__ - INFO - Found cached dashboard for Reliance Industries Ltd. from 2025-06-10 07:34:53.150000
2025-06-10 07:44:02,948 - __main__ - INFO - Returning cached dashboard for Reliance Industries Ltd.
2025-06-10 08:14:41,819 - asyncio - DEBUG - Using proactor: IocpProactor
2025-06-10 08:14:41,833 - pymongo.topology - DEBUG - {"message": "Starting topology monitoring", "topologyId": {"$oid": "68479c19236b27766bd67453"}}
2025-06-10 08:14:41,834 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "68479c19236b27766bd67453"}, "previousDescription": "<TopologyDescription id: 68479c19236b27766bd67453, topology_type: Unknown, servers: []>", "newDescription": "<TopologyDescription id: 68479c19236b27766bd67453, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>"}
2025-06-10 08:14:41,834 - pymongo.topology - DEBUG - {"message": "Starting server monitoring", "topologyId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,834 - pymongo.connection - DEBUG - {"message": "Connection pool created", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,836 - __main__ - INFO - Checking MongoDB for existing dashboard for Hitachi Energy India Ltd. (POWERINDIA.NS)
2025-06-10 08:14:41,837 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479c19236b27766bd67453, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "clientId": {"$oid": "68479c19236b27766bd67453"}}
2025-06-10 08:14:41,837 - pymongo.serverSelection - DEBUG - {"message": "Waiting for suitable server to become available", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479c19236b27766bd67453, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "clientId": {"$oid": "68479c19236b27766bd67453"}, "remainingTimeMS": 30000}
2025-06-10 08:14:41,852 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "68479c19236b27766bd67453"}, "driverConnectionId": 1, "serverHost": "localhost", "serverPort": 27017, "awaited": false}
2025-06-10 08:14:41,853 - pymongo.topology - DEBUG - {"message": "Server heartbeat succeeded", "topologyId": {"$oid": "68479c19236b27766bd67453"}, "driverConnectionId": 1, "serverConnectionId": 237, "serverHost": "localhost", "serverPort": 27017, "awaited": false, "durationMS": 0.0, "reply": "{\"helloOk\": true, \"ismaster\": true, \"topologyVersion\": {\"processId\": {\"$oid\": \"684749947f4860064c1c4649\"}}, \"maxBsonObjectSize\": 16777216, \"maxMessageSizeBytes\": 48000000, \"maxWriteBatchSize\": 100000, \"localTime\": {\"$date\": \"2025-06-10T02:44:41.853Z\"}, \"logicalSessionTimeoutMinutes\": 30, \"connectionId\": 237, \"maxWireVersion\": 21, \"ok\": 1.0}"}
2025-06-10 08:14:41,853 - pymongo.connection - DEBUG - {"message": "Connection pool ready", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,853 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "68479c19236b27766bd67453"}, "previousDescription": "<TopologyDescription id: 68479c19236b27766bd67453, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "newDescription": "<TopologyDescription id: 68479c19236b27766bd67453, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>"}
2025-06-10 08:14:41,853 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479c19236b27766bd67453, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,854 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,854 - pymongo.connection - DEBUG - {"message": "Connection created", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 08:14:41,854 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "68479c19236b27766bd67453"}, "driverConnectionId": 1, "serverConnectionId": 237, "serverHost": "localhost", "serverPort": 27017, "awaited": true}
2025-06-10 08:14:41,869 - pymongo.connection - DEBUG - {"message": "Connection ready", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 08:14:41,869 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.01599999999962165}
2025-06-10 08:14:41,869 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "68479c19236b27766bd67453"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T08:14:41.836Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"BCXoLS0gQRSYFjV4iXZUqw==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 3043, "operationId": 3043, "driverConnectionId": 1, "serverConnectionId": 239, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,871 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "68479c19236b27766bd67453"}, "durationMS": 2.0660000000000003, "reply": "{\"cursor\": {\"firstBatch\": [{\"_id\": {\"$oid\": \"684792c37b4935d9033ef467\"}, \"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"dashboard_data\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"about_company\": {\"description\": \"Hitachi Energy India Limited offers products, projects, and services for electricity transmission and related activities in India and internationally. The company is involved in engineering, integration, installation, commissioning, and support of project and services; and design, manufacturing, configuration, and supply of system, equipment, devices, and accessories products. It also manufactures and sells electric motors, generators, transformers, and electricity distribution and control apparatus, as well as related electrical equipment. The company was formerly known as ABB Power Products and Systems India Limited and changed its name to Hitachi Energy India Limited in November 2021. Hitachi Energy India Limited was incorporated in 2019 and is...", "commandName": "find", "databaseName": "alphasage", "requestId": 3043, "operationId": 3043, "driverConnectionId": 1, "serverConnectionId": 239, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,871 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 08:14:41,872 - __main__ - INFO - Found cached dashboard for Hitachi Energy India Ltd. from 2025-06-10 07:34:51.544000
2025-06-10 08:14:41,872 - __main__ - INFO - Returning cached dashboard for Hitachi Energy India Ltd.
2025-06-10 08:14:41,873 - __main__ - INFO - Checking MongoDB for existing dashboard for Reliance Industries Ltd. (RELIANCE.NS)
2025-06-10 08:14:41,873 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479c19236b27766bd67453, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "68479c19236b27766bd67453"}}
2025-06-10 08:14:41,873 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479c19236b27766bd67453, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,873 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,873 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 08:14:41,874 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "68479c19236b27766bd67453"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T08:14:41.873Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"BCXoLS0gQRSYFjV4iXZUqw==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 25961, "operationId": 25961, "driverConnectionId": 1, "serverConnectionId": 239, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,874 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "68479c19236b27766bd67453"}, "durationMS": 1.001, "reply": "{\"cursor\": {\"firstBatch\": [{\"_id\": {\"$oid\": \"684792c57b4935d9033ef468\"}, \"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"dashboard_data\": {\"company_name\": \"Reliance Industries Ltd.\", \"about_company\": {\"description\": \"Reliance Industries Limited engages in hydrocarbon exploration and production, oil and chemicals, textile, retail, digital, material and composites, renewables, and financial services businesses worldwide. It operates through Oil to Chemicals, Oil and Gas, Retail, Digital Services, and Others segments. The company produces and markets petroleum products, such as liquefied petroleum gas, propylene, naphtha, gasoline, jet/aviation turbine fuel, kerosene oil, diesel, sulphur, and petroleum coke. It also provides petrochemicals, including high-density and low-density polyethylene (PE), linear low-density PE, polyester fibers and yarns, polypropylene, polyvinyl chloride, purified terephthalic acid, ethylene glycols and oxide, paraxylene, ortho xylene, benz...", "commandName": "find", "databaseName": "alphasage", "requestId": 25961, "operationId": 25961, "driverConnectionId": 1, "serverConnectionId": 239, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:14:41,875 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "68479c19236b27766bd67453"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 08:14:41,875 - __main__ - INFO - Found cached dashboard for Reliance Industries Ltd. from 2025-06-10 07:34:53.150000
2025-06-10 08:14:41,875 - __main__ - INFO - Returning cached dashboard for Reliance Industries Ltd.
2025-06-10 08:16:43,261 - asyncio - DEBUG - Using proactor: IocpProactor
2025-06-10 08:16:43,285 - pymongo.topology - DEBUG - {"message": "Starting topology monitoring", "topologyId": {"$oid": "68479c93c65531b84dba9d4a"}}
2025-06-10 08:16:43,285 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "68479c93c65531b84dba9d4a"}, "previousDescription": "<TopologyDescription id: 68479c93c65531b84dba9d4a, topology_type: Unknown, servers: []>", "newDescription": "<TopologyDescription id: 68479c93c65531b84dba9d4a, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>"}
2025-06-10 08:16:43,285 - pymongo.topology - DEBUG - {"message": "Starting server monitoring", "topologyId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,286 - pymongo.connection - DEBUG - {"message": "Connection pool created", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,291 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479c93c65531b84dba9d4a, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}}
2025-06-10 08:16:43,291 - pymongo.serverSelection - DEBUG - {"message": "Waiting for suitable server to become available", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479c93c65531b84dba9d4a, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "remainingTimeMS": 30000}
2025-06-10 08:16:43,296 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "68479c93c65531b84dba9d4a"}, "driverConnectionId": 1, "serverHost": "localhost", "serverPort": 27017, "awaited": false}
2025-06-10 08:16:43,298 - pymongo.topology - DEBUG - {"message": "Server heartbeat succeeded", "topologyId": {"$oid": "68479c93c65531b84dba9d4a"}, "driverConnectionId": 1, "serverConnectionId": 240, "serverHost": "localhost", "serverPort": 27017, "awaited": false, "durationMS": 0.0, "reply": "{\"helloOk\": true, \"ismaster\": true, \"topologyVersion\": {\"processId\": {\"$oid\": \"684749947f4860064c1c4649\"}}, \"maxBsonObjectSize\": 16777216, \"maxMessageSizeBytes\": 48000000, \"maxWriteBatchSize\": 100000, \"localTime\": {\"$date\": \"2025-06-10T02:46:43.298Z\"}, \"logicalSessionTimeoutMinutes\": 30, \"connectionId\": 240, \"maxWireVersion\": 21, \"ok\": 1.0}"}
2025-06-10 08:16:43,298 - pymongo.connection - DEBUG - {"message": "Connection pool ready", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,298 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "68479c93c65531b84dba9d4a"}, "previousDescription": "<TopologyDescription id: 68479c93c65531b84dba9d4a, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "newDescription": "<TopologyDescription id: 68479c93c65531b84dba9d4a, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>"}
2025-06-10 08:16:43,298 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479c93c65531b84dba9d4a, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,299 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,299 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "68479c93c65531b84dba9d4a"}, "driverConnectionId": 1, "serverConnectionId": 240, "serverHost": "localhost", "serverPort": 27017, "awaited": true}
2025-06-10 08:16:43,299 - pymongo.connection - DEBUG - {"message": "Connection created", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 08:16:43,303 - pymongo.connection - DEBUG - {"message": "Connection ready", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.014999999999417923}
2025-06-10 08:16:43,303 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.014999999999417923}
2025-06-10 08:16:43,304 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T08:16:43.291Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"OKZhthlHTXCgZTtJjZE1Hg==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 9291, "operationId": 9291, "driverConnectionId": 1, "serverConnectionId": 242, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,305 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "durationMS": 1.02, "reply": "{\"cursor\": {\"firstBatch\": [{\"_id\": {\"$oid\": \"684792c37b4935d9033ef467\"}, \"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"dashboard_data\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"about_company\": {\"description\": \"Hitachi Energy India Limited offers products, projects, and services for electricity transmission and related activities in India and internationally. The company is involved in engineering, integration, installation, commissioning, and support of project and services; and design, manufacturing, configuration, and supply of system, equipment, devices, and accessories products. It also manufactures and sells electric motors, generators, transformers, and electricity distribution and control apparatus, as well as related electrical equipment. The company was formerly known as ABB Power Products and Systems India Limited and changed its name to Hitachi Energy India Limited in November 2021. Hitachi Energy India Limited was incorporated in 2019 and is...", "commandName": "find", "databaseName": "alphasage", "requestId": 9291, "operationId": 9291, "driverConnectionId": 1, "serverConnectionId": 242, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,306 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 08:16:43,308 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479c93c65531b84dba9d4a, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}}
2025-06-10 08:16:43,308 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479c93c65531b84dba9d4a, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0>]>", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,308 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,309 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 08:16:43,309 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T08:16:43.307Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"OKZhthlHTXCgZTtJjZE1Hg==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 25016, "operationId": 25016, "driverConnectionId": 1, "serverConnectionId": 242, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,310 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "durationMS": 1.003, "reply": "{\"cursor\": {\"firstBatch\": [{\"_id\": {\"$oid\": \"684792c57b4935d9033ef468\"}, \"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"dashboard_data\": {\"company_name\": \"Reliance Industries Ltd.\", \"about_company\": {\"description\": \"Reliance Industries Limited engages in hydrocarbon exploration and production, oil and chemicals, textile, retail, digital, material and composites, renewables, and financial services businesses worldwide. It operates through Oil to Chemicals, Oil and Gas, Retail, Digital Services, and Others segments. The company produces and markets petroleum products, such as liquefied petroleum gas, propylene, naphtha, gasoline, jet/aviation turbine fuel, kerosene oil, diesel, sulphur, and petroleum coke. It also provides petrochemicals, including high-density and low-density polyethylene (PE), linear low-density PE, polyester fibers and yarns, polypropylene, polyvinyl chloride, purified terephthalic acid, ethylene glycols and oxide, paraxylene, ortho xylene, benz...", "commandName": "find", "databaseName": "alphasage", "requestId": 25016, "operationId": 25016, "driverConnectionId": 1, "serverConnectionId": 242, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:16:43,310 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "68479c93c65531b84dba9d4a"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 08:17:03,142 - asyncio - DEBUG - Using proactor: IocpProactor
2025-06-10 08:17:03,159 - pymongo.topology - DEBUG - {"message": "Starting topology monitoring", "topologyId": {"$oid": "68479ca774bec90ae2692bec"}}
2025-06-10 08:17:03,159 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "68479ca774bec90ae2692bec"}, "previousDescription": "<TopologyDescription id: 68479ca774bec90ae2692bec, topology_type: Unknown, servers: []>", "newDescription": "<TopologyDescription id: 68479ca774bec90ae2692bec, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>"}
2025-06-10 08:17:03,159 - pymongo.topology - DEBUG - {"message": "Starting server monitoring", "topologyId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,160 - pymongo.connection - DEBUG - {"message": "Connection pool created", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,164 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479ca774bec90ae2692bec, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "clientId": {"$oid": "68479ca774bec90ae2692bec"}}
2025-06-10 08:17:03,164 - pymongo.serverSelection - DEBUG - {"message": "Waiting for suitable server to become available", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479ca774bec90ae2692bec, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "remainingTimeMS": 30000}
2025-06-10 08:17:03,168 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "68479ca774bec90ae2692bec"}, "driverConnectionId": 1, "serverHost": "localhost", "serverPort": 27017, "awaited": false}
2025-06-10 08:17:03,211 - pymongo.topology - DEBUG - {"message": "Server heartbeat succeeded", "topologyId": {"$oid": "68479ca774bec90ae2692bec"}, "driverConnectionId": 1, "serverConnectionId": 243, "serverHost": "localhost", "serverPort": 27017, "awaited": false, "durationMS": 45.9999999984575, "reply": "{\"helloOk\": true, \"ismaster\": true, \"topologyVersion\": {\"processId\": {\"$oid\": \"684749947f4860064c1c4649\"}}, \"maxBsonObjectSize\": 16777216, \"maxMessageSizeBytes\": 48000000, \"maxWriteBatchSize\": 100000, \"localTime\": {\"$date\": \"2025-06-10T02:47:03.211Z\"}, \"logicalSessionTimeoutMinutes\": 30, \"connectionId\": 243, \"maxWireVersion\": 21, \"ok\": 1.0}"}
2025-06-10 08:17:03,212 - pymongo.connection - DEBUG - {"message": "Connection pool ready", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,212 - pymongo.topology - DEBUG - {"message": "Topology description changed", "topologyId": {"$oid": "68479ca774bec90ae2692bec"}, "previousDescription": "<TopologyDescription id: 68479ca774bec90ae2692bec, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "newDescription": "<TopologyDescription id: 68479ca774bec90ae2692bec, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0459999999984575>]>"}
2025-06-10 08:17:03,213 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479ca774bec90ae2692bec, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0459999999984575>]>", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,213 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,213 - pymongo.topology - DEBUG - {"message": "Server heartbeat started", "topologyId": {"$oid": "68479ca774bec90ae2692bec"}, "driverConnectionId": 1, "serverConnectionId": 243, "serverHost": "localhost", "serverPort": 27017, "awaited": true}
2025-06-10 08:17:03,213 - pymongo.connection - DEBUG - {"message": "Connection created", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 08:17:03,217 - pymongo.connection - DEBUG - {"message": "Connection ready", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 08:17:03,217 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 08:17:03,218 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T08:17:03.164Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"zPIEhlvfRcWV5enFziWQQw==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 16281, "operationId": 16281, "driverConnectionId": 1, "serverConnectionId": 245, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,219 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "durationMS": 2.599, "reply": "{\"cursor\": {\"firstBatch\": [{\"_id\": {\"$oid\": \"684792c37b4935d9033ef467\"}, \"company_name\": \"Hitachi Energy India Ltd.\", \"ticker\": \"POWERINDIA.NS\", \"dashboard_data\": {\"company_name\": \"Hitachi Energy India Ltd.\", \"about_company\": {\"description\": \"Hitachi Energy India Limited offers products, projects, and services for electricity transmission and related activities in India and internationally. The company is involved in engineering, integration, installation, commissioning, and support of project and services; and design, manufacturing, configuration, and supply of system, equipment, devices, and accessories products. It also manufactures and sells electric motors, generators, transformers, and electricity distribution and control apparatus, as well as related electrical equipment. The company was formerly known as ABB Power Products and Systems India Limited and changed its name to Hitachi Energy India Limited in November 2021. Hitachi Energy India Limited was incorporated in 2019 and is...", "commandName": "find", "databaseName": "alphasage", "requestId": 16281, "operationId": 16281, "driverConnectionId": 1, "serverConnectionId": 245, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,220 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
2025-06-10 08:17:03,222 - pymongo.serverSelection - DEBUG - {"message": "Server selection started", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479ca774bec90ae2692bec, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0459999999984575>]>", "clientId": {"$oid": "68479ca774bec90ae2692bec"}}
2025-06-10 08:17:03,224 - pymongo.serverSelection - DEBUG - {"message": "Server selection succeeded", "selector": "Primary()", "operation": "find", "topologyDescription": "<TopologyDescription id: 68479ca774bec90ae2692bec, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Standalone, rtt: 0.0459999999984575>]>", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,224 - pymongo.connection - DEBUG - {"message": "Connection checkout started", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,224 - pymongo.connection - DEBUG - {"message": "Connection checked out", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1, "durationMS": 0.0}
2025-06-10 08:17:03,224 - pymongo.command - DEBUG - {"message": "Command started", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "command": "{\"find\": \"dashboards\", \"filter\": {\"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"created_at\": {\"$gte\": {\"$date\": \"2025-06-08T08:17:03.222Z\"}}}, \"sort\": {\"created_at\": -1}, \"limit\": 1, \"singleBatch\": true, \"lsid\": {\"id\": {\"$binary\": {\"base64\": \"zPIEhlvfRcWV5enFziWQQw==\", \"subType\": \"04\"}}}, \"$db\": \"alphasage\"}", "commandName": "find", "databaseName": "alphasage", "requestId": 27567, "operationId": 27567, "driverConnectionId": 1, "serverConnectionId": 245, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,226 - pymongo.command - DEBUG - {"message": "Command succeeded", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "durationMS": 2.018, "reply": "{\"cursor\": {\"firstBatch\": [{\"_id\": {\"$oid\": \"684792c57b4935d9033ef468\"}, \"company_name\": \"Reliance Industries Ltd.\", \"ticker\": \"RELIANCE.NS\", \"dashboard_data\": {\"company_name\": \"Reliance Industries Ltd.\", \"about_company\": {\"description\": \"Reliance Industries Limited engages in hydrocarbon exploration and production, oil and chemicals, textile, retail, digital, material and composites, renewables, and financial services businesses worldwide. It operates through Oil to Chemicals, Oil and Gas, Retail, Digital Services, and Others segments. The company produces and markets petroleum products, such as liquefied petroleum gas, propylene, naphtha, gasoline, jet/aviation turbine fuel, kerosene oil, diesel, sulphur, and petroleum coke. It also provides petrochemicals, including high-density and low-density polyethylene (PE), linear low-density PE, polyester fibers and yarns, polypropylene, polyvinyl chloride, purified terephthalic acid, ethylene glycols and oxide, paraxylene, ortho xylene, benz...", "commandName": "find", "databaseName": "alphasage", "requestId": 27567, "operationId": 27567, "driverConnectionId": 1, "serverConnectionId": 245, "serverHost": "localhost", "serverPort": 27017}
2025-06-10 08:17:03,226 - pymongo.connection - DEBUG - {"message": "Connection checked in", "clientId": {"$oid": "68479ca774bec90ae2692bec"}, "serverHost": "localhost", "serverPort": 27017, "driverConnectionId": 1}
